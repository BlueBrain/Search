{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "03.04.2020\n",
    "- Use 'bert-large-nli-mean-tokens'.\n",
    "\n",
    "06.04.2020\n",
    "- Add the lower ranking of some keywords (like 'diabetes').\n",
    "- Explore how synonyms impact sentence embeddings space search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "Human curated WHO papers + query* on PMC / bioRxiv / medRxiv.\n",
    "\n",
    "**Query**\n",
    "\n",
    "- \"COVID-19\"\n",
    "- OR Coronavirus\n",
    "- OR \"Corona virus\"\n",
    "- OR \"2019-nCoV\"\n",
    "- OR \"SARS-CoV\"\n",
    "- OR \"MERS-CoV\"\n",
    "- OR “Severe Acute Respiratory Syndrome”\n",
    "- OR “Middle East Respiratory Syndrome” "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sqlite3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import sent2vec\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Load USE\n",
    "use_version = 5\n",
    "use = hub.load(f\"https://tfhub.dev/google/universal-sentence-encoder-large/{use_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Load SBERT\n",
    "sbert = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Load BioSentVec\n",
    "bsv = sent2vec.Sent2vecModel()\n",
    "bsv.load_model('BioSentVec_PubMed_MIMICIII-bigram_d700.bin')\n",
    "\n",
    "bsv_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def bsv_preprocess(text):\n",
    "    text = text.replace('/', ' / ')\n",
    "    text = text.replace('.-', ' .- ')\n",
    "    text = text.replace('.', ' . ')\n",
    "    text = text.replace('\\'', ' \\' ')\n",
    "    text = text.lower()\n",
    "    tokens = [token for token in word_tokenize(text)\n",
    "              if token not in punctuation and token not in bsv_stopwords]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentences(sentences, embedding_name, embedding_model):\n",
    "    if embedding_name == 'USE':\n",
    "        return embedding_model(sentences).numpy()\n",
    "    \n",
    "    elif embedding_name == 'SBERT':\n",
    "        return np.stack(embedding_model.encode(sentences), axis=0)\n",
    "    \n",
    "    elif embedding_name == 'BSV':\n",
    "        preprocessed = [bsv_preprocess(x) for x in sentences]\n",
    "        return embedding_model.embed_sentences(preprocessed)\n",
    "        \n",
    "    else:\n",
    "        raise NotImplementedError(f'Embedding {repr(embedding_name)} not '\n",
    "                                  f'available!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_NAMES = ['USE', 'SBERT', 'BSV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('sentence_embeddings/sentence_embeddings.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('../cord19q/articles.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigate():\n",
    "    \n",
    "    def on_clicked(b):\n",
    "        wout.clear_output()\n",
    "        with wout:\n",
    "            print()\n",
    "            t0 = time.time()\n",
    "            \n",
    "            print('Embedding sentence...    ', end=' ')\n",
    "            embedding_query = embed_sentences([wtext.value], wselect_model.value, eval(wselect_model.value.lower()))\n",
    "            print(f'{time.time()-t0:.2f} s.')\n",
    "            \n",
    "            print('Computing similarities...', end=' ')\n",
    "            # For scalability, we will replace this part with FAISS, as in the other part of the code base.\n",
    "            arr = embeddings[wselect_model.value]\n",
    "            uids, embedding_docs = arr[:, 0], arr[:, 1:]\n",
    "            similarities = cosine_similarity(X=embedding_query, Y=embedding_docs).squeeze()\n",
    "            print(f'{time.time()-t0:.2f} s.')\n",
    "            \n",
    "            print('Ranking documents...     ', end=' ')\n",
    "            indices = np.argsort(-similarities)[:wselect_count.value]\n",
    "            print(f'{time.time()-t0:.2f} s.')\n",
    "            \n",
    "            print()\n",
    "            for i, (uid_, sim_) in enumerate(zip(uids[indices], similarities[indices])):\n",
    "                article_sha, text = db.execute('SELECT Article, Text FROM sections WHERE Id = ?', [uid_]).fetchall()[0]\n",
    "                print(f'Rank: {i} --- Section id: {int(uid_):>7,d} --- Similarity: {sim_:.2f}')\n",
    "                print(Color.BLUE + text + Color.END)\n",
    "                article_title = db.execute('SELECT Title FROM articles WHERE Id = ?', [article_sha]).fetchone()[0]\n",
    "                print(Color.GREEN + 'From: ' + article_title + Color.END)\n",
    "                print()\n",
    "    \n",
    "    wselect_model = widgets.ToggleButtons(\n",
    "        options=[ 'USE', 'SBERT', 'BSV'],\n",
    "        description='Model:',\n",
    "        tooltips=['Universal Sentence Encoder', 'Sentence BERT', 'BioSentVec'],\n",
    "    )\n",
    "    \n",
    "    wselect_count = widgets.IntSlider(value=10, min=0, max=100, description='Top N:',)\n",
    "    \n",
    "    wtext = widgets.Textarea(layout=widgets.Layout(width='90%', height='80px'))\n",
    "\n",
    "    button = widgets.Button(description='Investigate!')\n",
    "    button.on_click(on_clicked)\n",
    "    \n",
    "    wout = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "    display(widgets.VBox([wselect_model, wselect_count, wtext, button, wout]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigations\n",
    "\n",
    "- Inhibition of N-glycosylation (using N-glycosylation inhibitors or Lectins) is a potential therapeutic approach for COVID-19 therapy.\n",
    "- Is high blood / plasma sugar level or hyperglycemia associated with higher susceptibility to coronavirus infection or higher virus replication?\n",
    "- Glucose or sugar is a risk factor for COVID-19.\n",
    "- Ketogenic diet is protective against COVID-19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investigate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
