{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of the notebook\n",
    "End to end pipeline for searching articles of interest, extracting entities of interest, building, accessing and deploying a knowled graph and a co-mention graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy\n",
    "import ipywidgets\n",
    "\n",
    "from bbsearch.widgets import ArticleSaver, SearchWidget, MiningWidget, SchemaRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set a Project\n",
    "\n",
    "The user chooses / creates a project to host a KG.\n",
    "\n",
    "* Use the [Nexus web application](https://bbp.epfl.ch/nexus/web) to get a token.\n",
    "* Once a token is obtained then proceed to paste it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "TOKEN = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kgforge.core import KnowledgeGraphForge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a 'forge' to manage (create, access and deploy) the knowledge graph within a given Blue Brain Nexus Project.\n",
    "FORGE_CONFIG_FILE = os.getenv(\"FORGE_CONFIG_FILE\") \n",
    "assert (FORGE_CONFIG_FILE is not None) \n",
    "forge = KnowledgeGraphForge(FORGE_CONFIG_FILE,token=TOKEN, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set topic\n",
    "The user defines a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwt\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_resource=None\n",
    "kg_resource=None\n",
    "agent_username = jwt.decode(TOKEN,  verify=False)['preferred_username']\n",
    "\n",
    "def save_topic(b):\n",
    "    output.clear_output()\n",
    "    output2.clear_output()\n",
    "    output3.clear_output()\n",
    "    topic_to_save = {\n",
    "        'id': str(widget.children[1].children[0].value).replace(' ', '_'),\n",
    "        'type': 'Topic',\n",
    "        'name': widget.children[1].children[0].value,\n",
    "        'field': widget.children[1].children[1].value,\n",
    "        'description': widget.children[1].children[2].value,\n",
    "        'keywords': widget.children[1].children[3].value,\n",
    "        'question':  [widget.children[1].children[i].value for i in range(5,9)]\n",
    "    }\n",
    "    global topic_resource\n",
    "    topic_resource = forge.from_json(topic_to_save)\n",
    "    forge.register(topic_resource)\n",
    "    with output2:\n",
    "        if w1.value == \"\":\n",
    "            print(\"Please provide a topic name\")\n",
    "        else:\n",
    "            print(\"Topic saved!\")\n",
    "            w1.value = \"\"\n",
    "            w2.value = \"\"\n",
    "            w3.value = \"\"\n",
    "            w4.value = \"\"\n",
    "            w5.value = \"\"\n",
    "            w6.value = \"\"\n",
    "            w7.value = \"\"\n",
    "            w8.value = \"\"\n",
    "\n",
    "def get_topics(b):\n",
    "    output.clear_output()\n",
    "    output2.clear_output()\n",
    "    output3.clear_output()\n",
    "    query = f\"\"\"\n",
    "    SELECT ?id ?name ?description ?keywords ?field ?question ?createdAt\n",
    "    WHERE {{\n",
    "        ?id a Topic ;\n",
    "            name ?name ;\n",
    "            description ?description ;\n",
    "            keywords ?keywords ;\n",
    "            field ?field ;\n",
    "            question ?question ;\n",
    "            <https://bluebrain.github.io/nexus/vocabulary/deprecated> false ;\n",
    "            <https://bluebrain.github.io/nexus/vocabulary/createdAt> ?createdAt ;\n",
    "            <https://bluebrain.github.io/nexus/vocabulary/createdBy> <{forge._store.endpoint}/realms/bbp/users/{agent_username}> .\n",
    "    }}\n",
    "    \"\"\"\n",
    "    resources = forge.sparql(query, limit=100)\n",
    "    if len(resources) >= 1:\n",
    "        global topics_df\n",
    "        topics_df = forge.as_dataframe(resources)\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            topics_list = list(set(topics_df.name))\n",
    "            topics_list.sort()\n",
    "            w0.options = [\"\"] + topics_list\n",
    "            w0.value = \"\"\n",
    "            w0.placeholder = \"Select topic\"\n",
    "            w0.observe(topics_change, names='value')\n",
    "            display(w0)\n",
    "            display(s12)\n",
    "    else:\n",
    "        with output:\n",
    "            print(\"No topics found!\")\n",
    "\n",
    "def topics_change(change):\n",
    "    output3.clear_output()\n",
    "    with output:\n",
    "        if len(output.outputs) >= 1:\n",
    "            output.outputs = (output.outputs[0],)\n",
    "        s5.value = \"\"\n",
    "        s6.value = \"\"\n",
    "        s7.value = \"\"\n",
    "        s8.value = \"\"\n",
    "        s9.value = \"\"\n",
    "        s10.value = \"\"\n",
    "        s11.value = \"\"\n",
    "        global topic_resource\n",
    "        if change['new'] != \"\":\n",
    "            topic_resource = forge.retrieve(list(set(topics_df[topics_df.name == change['new']].id))[0])\n",
    "            s5.value = topic_resource.field\n",
    "            s6.value = topic_resource.description\n",
    "            s7.value = topic_resource.keywords\n",
    "            question = topic_resource.question\n",
    "            if isinstance(question, str):\n",
    "                question = [question]\n",
    "            if isinstance(question, list):\n",
    "                for i in range(len(question)):\n",
    "                    sq.children[i].value = question[i]            \n",
    "        display(s12)\n",
    "\n",
    "def update_topic(b):\n",
    "    output2.clear_output()\n",
    "    if w0.value != \"\":\n",
    "        topic_resource.id = forge.as_jsonld(topic_resource, form=\"expanded\")['@id']\n",
    "        topic_resource.field = s5.value\n",
    "        topic_resource.description = s6.value\n",
    "        topic_resource.keywords = s7.value\n",
    "        topic_resource.question = [sq.children[i].value for i in range(0,4)]\n",
    "        forge.update(topic_resource)\n",
    "        with output:\n",
    "            print(\"topic updated!\")\n",
    "        \n",
    "def get_datasets(b):\n",
    "    output3.clear_output()\n",
    "    if w0.value != \"\":\n",
    "        topic_resource_id = forge.as_jsonld(topic_resource, form=\"expanded\")['@id']\n",
    "        query = f\"\"\"\n",
    "            SELECT ?id ?name ?description ?keywords ?field ?question ?createdAt\n",
    "            WHERE {{\n",
    "                ?id a Dataset ;\n",
    "                    name ?name ;\n",
    "                    about <{topic_resource_id}> ;\n",
    "                    <https://bluebrain.github.io/nexus/vocabulary/deprecated> false ;\n",
    "                    <https://bluebrain.github.io/nexus/vocabulary/createdAt> ?createdAt ;\n",
    "                    <https://bluebrain.github.io/nexus/vocabulary/createdBy> <{forge._store.endpoint}/realms/bbp/users/{agent_username}> .\n",
    "            }}\n",
    "            \"\"\"\n",
    "        global kg_resources\n",
    "        kg_resources = forge.sparql(query, limit=100, debug=True)\n",
    "        if len(kg_resources) >= 1:\n",
    "            with output3:\n",
    "                display(s2)\n",
    "                s2.options = [r.name for r in kg_resources]\n",
    "                display(s3)\n",
    "        else:\n",
    "            with output3:\n",
    "                print(\"No datasets found!\")\n",
    "        \n",
    "def download_dataset(b):\n",
    "    resource_id = [r.id for r in kg_resources if r.name == s2.value][0]\n",
    "    global kg_resource\n",
    "    global table_extractions\n",
    "    kg_resource = forge.retrieve(resource_id)\n",
    "    forge.download(kg_resource, \"distribution.contentUrl\", \".\", overwrite=True)\n",
    "    for r in kg_resource.distribution:\n",
    "        if \"curated\" in r.name:\n",
    "            table_extractions = pd.read_csv(f\"./{r.name}\")\n",
    "            if table_extractions is not None:\n",
    "                message = f\"Dataset '{r.name}' with {len(table_extractions)} entities ready to be reused. Its content has been assigned to the variable 'table_extractions'. Please continue with the interactive UI section to visualise this dataset.\"\n",
    "            else:\n",
    "                table_extractions = pd.DataFrame()\n",
    "                message = \"No dataset has been downloaded\"\n",
    "            with output3:\n",
    "                print(message)\n",
    "\n",
    "s0 = ipywidgets.Button(\n",
    "    description= '🔬 List all your topics',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s1 = ipywidgets.Button(\n",
    "    description= \"📃 Show datasets for selected topic\",\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s2 = ipywidgets.RadioButtons(\n",
    "    description='Select:',\n",
    "    disabled=False)\n",
    "s3 = ipywidgets.Button(\n",
    "    description= '📈 Reuse selected dataset',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s4 = ipywidgets.Button(\n",
    "    description= '✏️ Update topic',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s5 = ipywidgets.Text(\n",
    "    description='Field:',\n",
    "    disabled=False)\n",
    "s6 = ipywidgets.Textarea(\n",
    "    description='Description:',\n",
    "    disabled=False)\n",
    "s7 = ipywidgets.Textarea(\n",
    "    description='Keywords:',\n",
    "    disabled=False)\n",
    "s8 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "s9 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "s10 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "s11 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "\n",
    "sq = ipywidgets.VBox(children=[s8, s9, s10, s11])\n",
    "\n",
    "s12 = ipywidgets.VBox(children=[s5, s6, s7, ipywidgets.Label('Questions:'), sq, s4])\n",
    "\n",
    "w0 = ipywidgets.Dropdown(\n",
    "        description='Select topic:',\n",
    "        disabled=False)\n",
    "w1 = ipywidgets.Text(\n",
    "    placeholder='e.g. COVID-19',\n",
    "    description='Topic name:',\n",
    "    disabled=False)\n",
    "w2 = ipywidgets.Text(\n",
    "    placeholder='e.g. Neuroscience',\n",
    "    description='Field:',\n",
    "    disabled=False)\n",
    "w3 = ipywidgets.Textarea(\n",
    "    placeholder='Add a description of your topic',\n",
    "    description='Description:',\n",
    "    disabled=False)\n",
    "w4 = ipywidgets.Textarea(\n",
    "    placeholder='e.g. Coronavirus; COVID-19; SARS; risk factor; glycosylation; sugar; carbohydrates',\n",
    "    description='Keywords:',\n",
    "    disabled=False)\n",
    "w5 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w6 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w7 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w8 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w9 = ipywidgets.Button(\n",
    "    description='Create',\n",
    "    button_style='',\n",
    "    tooltip='Create new topic',\n",
    "    disabled=False)\n",
    "\n",
    "output = ipywidgets.Output()\n",
    "output2 = ipywidgets.Output()\n",
    "output3 = ipywidgets.Output()\n",
    "\n",
    "buttons = ipywidgets.HBox(children=[s0, s1])\n",
    "outputs = ipywidgets.HBox(children=[output, output3])\n",
    "tab1 = ipywidgets.VBox(children=[buttons, outputs])\n",
    "tab2 = ipywidgets.VBox(children=[w1, w2, w3, w4, ipywidgets.Label('Please express your research topic in a few questions:'), w5, w6, w7, w8, w9, output2])\n",
    "widget = ipywidgets.Tab(children=[tab1, tab2])\n",
    "widget.set_title(0, 'Select topic')\n",
    "widget.set_title(1, 'Create topic')\n",
    "\n",
    "w9.on_click(save_topic)\n",
    "s0.on_click(get_topics)\n",
    "s1.on_click(get_datasets)\n",
    "s3.on_click(download_dataset)\n",
    "s4.on_click(update_topic)\n",
    "\n",
    "display(widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import\n",
    "The user loads data from a data source (CORD-19).\n",
    "The loaded data forms the corpus.\n",
    "The user searches the CORPUS in Blue Brain Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search server URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_ENGINE_URL = os.getenv(\"SEARCH_ENGINE_URL\", \"http://dgx1.bbp.epfl.ch:8850\")\n",
    "assert SEARCH_ENGINE_URL is not None\n",
    "\n",
    "response = requests.post(\"{}/help\".format(SEARCH_ENGINE_URL))\n",
    "assert response.ok and response.json()['name'] == 'SearchServer', \"The server is not accessible\"\n",
    "print(f\"This server is using the database: {response.json()['database']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MySQL URL and engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYSQL_DB_URI = os.getenv(\"MYSQL_DB_URI\", \"dgx1.bbp.epfl.ch:8853\")\n",
    "bbs_mysql_engine = sqlalchemy.create_engine(f'mysql+pymysql://guest:guest@{MYSQL_DB_URI}/cord19_v47')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Article saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_saver = ArticleSaver(connection=bbs_mysql_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_widget = SearchWidget(\n",
    "    bbs_search_url=SEARCH_ENGINE_URL,\n",
    "    bbs_mysql_engine=bbs_mysql_engine,\n",
    "    article_saver=article_saver,\n",
    "    results_per_page=3)\n",
    "search_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status of the Article Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_saver.summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set schemas\n",
    "The user defines the KG schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_request = SchemaRequest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['entity_type', 'property', 'property_type', 'property_value_type', 'ontology_source']\n",
    "\n",
    "etypes_sources = [('CELL_COMPARTMENT', None),\n",
    "                  ('CELL_TYPE', None),\n",
    "                  ('CHEMICAL', 'NCIT'), \n",
    "                  ('CONDITION', None),\n",
    "                  ('DISEASE', 'NCIT'),\n",
    "                  ('DRUG', None),\n",
    "                  ('ORGAN', 'NCIT'),\n",
    "                  ('ORGANISM', 'NCIT'),\n",
    "                  ('PATHWAY', 'Reactome'),\n",
    "                  ('PROTEIN', 'NCIT')\n",
    "                 ]\n",
    "schema_request_data = [{'entity_type': etype, 'ontology_source': source} \n",
    "                       for etype, source in etypes_sources]\n",
    "\n",
    "schema_request.schema = pd.DataFrame(schema_request_data, columns=columns)\n",
    "display(schema_request.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a knowledge graph according to schemas\n",
    "The user extracts data from the text of a set of papers using selected Named Entity Recognizers and Relation Extractors from Blue Brain Search.\n",
    "The user can preview the extracted data.\n",
    "The user curates extracted data.\n",
    "The user links the extracted entities and relations to ontologies.\n",
    "The user saves data into Knowledge Graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **input**: raw text\n",
    "- **output**: csv table of extracted entities/relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TEXT = \"\"\"Autophagy maintains tumour growth through circulating\n",
    "arginine. Autophagy captures intracellular components and delivers them to\n",
    "lysosomes, where they are degraded and recycled to sustain metabolism and to\n",
    "enable survival during starvation. Acute, whole-body deletion of the essential \n",
    "autophagy gene Atg7 in adult mice causes a systemic metabolic defect that \n",
    "manifests as starvation intolerance and gradual loss of white adipose tissue, \n",
    "liver glycogen and muscle mass.  Cancer cells also benefit from autophagy. \n",
    "Deletion of essential autophagy genes impairs the metabolism, proliferation, \n",
    "survival and malignancy of spontaneous tumours in models of autochthonous \n",
    "cancer. Acute, systemic deletion of Atg7 or acute, systemic expression of a \n",
    "dominant-negative ATG4b in mice induces greater regression of KRAS-driven \n",
    "cancers than does tumour-specific autophagy deletion, which suggests that host \n",
    "autophagy promotes tumour growth.\n",
    "\"\"\".replace('\\n', ' ').replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_MINING_URL = os.getenv(\"TEXT_MINING_URL\", \"http://dgx1.bbp.epfl.ch:8852\")\n",
    "response = requests.post(TEXT_MINING_URL + \"/help\")\n",
    "assert response.ok and response.json()['name'] == 'MiningServer'\n",
    "print(f\"This server is using the database: {response.json()['database']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mining_widget = MiningWidget(\n",
    "    mining_server_url=TEXT_MINING_URL,\n",
    "    schema_request=schema_request,\n",
    "    article_saver=article_saver,\n",
    "    default_text=DEFAULT_TEXT)\n",
    "mining_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **input**: csv table of extracted entities/relations\n",
    "- **output**: knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrame of extractions\n",
    "table_extractions = mining_widget.get_extracted_table()\n",
    "\n",
    "# Drop duplicates in DataFrame\n",
    "columns_duplicates = table_extractions.columns.tolist()\n",
    "columns_duplicates.remove('entity_type')\n",
    "table_extractions = table_extractions.drop_duplicates(subset=columns_duplicates, keep='first', ignore_index=True)\n",
    "table_extractions = table_extractions.dropna(subset=[\"entity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The table has {table_extractions.shape[0]} rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_server_proxy\n",
    "import jupyter_dash\n",
    "import dash\n",
    "import dash_daq as daq\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_table\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash.comms import _send_jupyter_config_comm_request\n",
    "_send_jupyter_config_comm_request()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JupyterDash.infer_jupyter_proxy_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Setting default term filters: the user can remove them later on in the UI if need be ...\")\n",
    "\n",
    "filtered_table_extractions = table_extractions.copy()\n",
    "filtered_table_extractions[\"paper_id\"] = filtered_table_extractions[\"paper_id\"].transform(lambda x:  str(x).split(\":\")[0])\n",
    "\n",
    "default_term_filters = 'Glucose; Covid-19; SARS-CoV-2; Diabetes; IL-1; ACE2; glycosylation; hyperglycemia; shock; fatigue; CVD; vasoconstriction; lactate; insulin; SP-D; HbA1c; LDH; glycolysis; GLUT; macrophage; lymphocytes; ventilation;SARS; ARDS; Cytokine Storm; pneumonia; multi-organs failure; thrombosis; inflammation; IL-6; CRP; D-Dimer; Ferritin; Lung Disease; Hypertension; Aging; COPD; angiotensin 2 (or angiotensin II or AngII); Obesity; ICU (intensive care unit); ventilation; ketogenic diet'.split(\"; \")\n",
    "default_found_term_filters = set() \n",
    "for term_filter in default_term_filters:\n",
    "    result_df = filtered_table_extractions.loc[filtered_table_extractions[\"entity\"].str.lower().eq(str(term_filter).lower())]\n",
    "    result_df = result_df[\"entity\"].unique()    \n",
    "    if result_df is not None and len(result_df) > 0:\n",
    "        default_found_term_filters.add(tuple(result_df))\n",
    "term_filter_options= [term_filter[0] for term_filter in  default_found_term_filters]\n",
    "\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Computing entity frequencies ...\")\n",
    "\n",
    "\n",
    "\n",
    "def _frequency(group_by, retrieve_key, df, distinct_papers=True, debug=False):\n",
    "    \n",
    "    if debug:\n",
    "        display(df.head(100))\n",
    "    if distinct_papers:\n",
    "        colunm_stats = df[[group_by, retrieve_key]].groupby(group_by)[retrieve_key].unique()\n",
    "    else:\n",
    "        colunm_stats = df[[group_by, retrieve_key]].groupby(group_by)[retrieve_key].count()\n",
    "    if debug:\n",
    "        display(colunm_stats)\n",
    "    \n",
    "    return colunm_stats\n",
    "        \n",
    "entity_stats = _frequency(group_by=\"entity\",retrieve_key=\"paper_id\",df=filtered_table_extractions,distinct_papers=True)\n",
    "\n",
    "entity_frequency = 1\n",
    "\n",
    "\n",
    "row_filtered = [row for row in filtered_table_extractions.itertuples() if len(entity_stats[row.entity]) >= int(entity_frequency)]\n",
    "filtered_table_extractions = pd.DataFrame(row_filtered)\n",
    "curated_table_extractions = filtered_table_extractions.copy()\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "app = JupyterDash('Extracted Entities Curation App')\n",
    "\n",
    "server = app.server\n",
    "\n",
    "from operator import ge, gt, lt, le, eq, ne\n",
    "\n",
    "\n",
    "operators = [['ge ', '>='],\n",
    "             ['le ', '<='],\n",
    "             ['lt ', '<'],\n",
    "             ['gt ', '>'],\n",
    "             ['ne ', '!='],\n",
    "             ['eq ', '='],\n",
    "             ['contains '],\n",
    "             ['datestartswith ']]\n",
    "\n",
    "dropdown_freq_filter_list = [{\"label\":\">\",\"value\":\"gt\"},\n",
    "                             {\"label\":\">=\",\"value\":\"ge\"},\n",
    "                             {\"label\":\"<\",\"value\":\"lt\"},\n",
    "                             {\"label\":\"<=\",\"value\":\"le\"},\n",
    "                             {\"label\":\"=\",\"value\":\"eq\"},\n",
    "                             {\"label\":\"!=\",\"value\":\"ne\"}]\n",
    "\n",
    "def split_filter_part(filter_part):\n",
    "    for operator_type in operators:\n",
    "        for operator in operator_type:\n",
    "            if operator in filter_part:\n",
    "                name_part, value_part = filter_part.split(operator, 1)\n",
    "                name = name_part[name_part.find('{') + 1: name_part.rfind('}')]\n",
    "\n",
    "                value_part = value_part.strip()\n",
    "                v0 = value_part[0]\n",
    "                if (v0 == value_part[-1] and v0 in (\"'\", '\"', '`')):\n",
    "                    value = value_part[1: -1].replace('\\\\' + v0, v0)\n",
    "                else:\n",
    "                    try:\n",
    "                        value = float(value_part)\n",
    "                    except ValueError:\n",
    "                        value = value_part\n",
    "\n",
    "                return name, operator_type[0].strip(), value\n",
    "\n",
    "    return [None] * 3\n",
    "\n",
    "# Define UI layout\n",
    "\n",
    "button_group = dbc.ButtonGroup(\n",
    "    [\n",
    "        dcc.Upload(\n",
    "                id='datatable-upload',\n",
    "                children=html.Div([\n",
    "                    dbc.Button(\"Load a CSV File\", color=\"primary\", className=\"mr-1\",id=\"load_file\"),\n",
    "                    dbc.Tooltip(\n",
    "                        \"Load extracted entities in CSV format\",\n",
    "                        target=\"load_file\",\n",
    "                        placement=\"bottom\",\n",
    "                    )\n",
    "                ]),\n",
    "            className=\"mr-1\"\n",
    "        )\n",
    "    ],\n",
    "     className=\"mr-1\"\n",
    ")\n",
    "\n",
    "buttons = dbc.FormGroup(\n",
    "            [\n",
    "                 button_group\n",
    "            ]\n",
    "        )\n",
    "\n",
    "dropdown = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.InputGroupAddon(\n",
    "            dbc.Button(\"Entity requency\", color=\"primary\"),\n",
    "            addon_type=\"prepend\",\n",
    "            className=\"mr-1\"\n",
    "        ),\n",
    "        dcc.Dropdown(\n",
    "            id='dropdown-freq-filter',\n",
    "            value=\"ge\",\n",
    "            clearable=False,\n",
    "            options = dropdown_freq_filter_list,\n",
    "            \n",
    "            className=\"mr-1\"\n",
    "        ),\n",
    "        daq.NumericInput(\n",
    "            id=\"entityfreqslider\",\n",
    "            min=entity_frequency,  \n",
    "            max=1000,\n",
    "            value=entity_frequency,\n",
    "           className=\"mr-1\"\n",
    "        )\n",
    "    ],\n",
    "    className=\"mr-1\"\n",
    ")\n",
    "\n",
    "\n",
    "term_filters = dbc.FormGroup(\n",
    "    [\n",
    "       \n",
    "        dcc.Dropdown(\n",
    "            id=\"term_filters\",\n",
    "            multi=True,\n",
    "            value=term_filter_options,\n",
    "            className=\"mr-3\"\n",
    "        )\n",
    "        \n",
    "    ],\n",
    "    className=\"mr-1\",\n",
    "    row=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "term_filters = dbc.InputGroup(\n",
    "    [\n",
    "        dbc.InputGroupAddon(\n",
    "            \"Keep\",\n",
    "            addon_type=\"prepend\",\n",
    "        ),\n",
    "         dcc.Dropdown(\n",
    "            id=\"term_filters\",\n",
    "            multi=True,\n",
    "             value=term_filter_options,\n",
    "             style={\n",
    "                 \"width\":\"80%\"\n",
    "             },\n",
    "             placeholder=\"Search for entities to keep\",\n",
    "             \n",
    "        )\n",
    "        \n",
    "    ],\n",
    "    className=\"mb-1\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "reset = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Button(\"Reset\", color=\"primary\", className=\"mr-1\",id='table-reset'),\n",
    "        dbc.Tooltip(\n",
    "            \"Reset table and graph to original extracted entities and default filters\",\n",
    "            target=\"table-reset\",\n",
    "            placement=\"bottom\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "                        \n",
    "\n",
    "form_table = dbc.Form([buttons, dropdown,reset,term_filters],inline=True)\n",
    "\n",
    "app.layout = html.Div(\n",
    "    [\n",
    "       dbc.Row(\n",
    "            dbc.Col(\n",
    "                form_table\n",
    "            )\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            dbc.Col(\n",
    "                dash_table.DataTable(\n",
    "                    id='datatable-upload-container',\n",
    "                    style_cell={\n",
    "                        'whiteSpace': 'normal'\n",
    "                    },\n",
    "\n",
    "                    style_data_conditional=[\n",
    "                        {\n",
    "                            'if': {'row_index': 'odd'},\n",
    "                            'backgroundColor': 'rgb(248, 248, 248)'\n",
    "                        }\n",
    "                    ],\n",
    "                    style_header={\n",
    "                        'backgroundColor': 'rgb(230, 230, 230)',\n",
    "                        'fontWeight': 'bold'\n",
    "                    },\n",
    "\n",
    "                    css=[\n",
    "                        {\n",
    "                            'selector': 'dash-fixed-content',\n",
    "                            'rule': 'height: 100%;'\n",
    "                        }\n",
    "                    ],\n",
    "                    sort_action=\"custom\", #native\n",
    "                    sort_mode=\"multi\",\n",
    "                    column_selectable=\"multi\",\n",
    "                    filter_action=\"custom\",\n",
    "                    filter_query='',\n",
    "                    selected_columns=[],\n",
    "                    page_action=\"custom\", #native\n",
    "                    export_format='csv',\n",
    "                    export_headers='display',\n",
    "                    merge_duplicate_headers=True,\n",
    "                    selected_rows=[],\n",
    "                    page_current=0,\n",
    "                    page_size=10,\n",
    "                    sort_by=[]\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            \n",
    "            dbc.Col(dcc.Graph(id='datatable-upload-Scatter'))\n",
    "           \n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "\n",
    "def parse_contents(contents, filename):\n",
    "    content_type, content_string = contents.split(',')\n",
    "    decoded = base64.b64decode(content_string)\n",
    "    if 'csv' in filename:\n",
    "        return pd.read_csv(\n",
    "            io.StringIO(decoded.decode('utf-8')))\n",
    "\n",
    "@app.callback(\n",
    "    Output('datatable-upload-container', 'style_data_conditional'),\n",
    "    [Input('datatable-upload-container', 'selected_columns')]\n",
    ")\n",
    "def update_styles(selected_columns):\n",
    "    return [{\n",
    "        'if': {'column_id': i},\n",
    "        'background_color': '#D2F3FF'\n",
    "    } for i in selected_columns]\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"term_filters\", \"options\"),\n",
    "    [Input(\"term_filters\", \"search_value\")],\n",
    "    [State(\"term_filters\", \"value\"),\n",
    "    State('datatable-upload-container', 'data')],\n",
    ")\n",
    "def update_filter(search_value, values,data):\n",
    "    \n",
    "   \n",
    "    if not search_value and values is None:\n",
    "        raise PreventUpdate\n",
    "    res = []\n",
    "    if values is not None:\n",
    "        for value in values:\n",
    "            res.append( {\"label\":value,\"value\":value})\n",
    "            \n",
    "    result_df = non_deleted_table_extractions.loc[non_deleted_table_extractions[\"entity\"].str.contains(str(search_value))]\n",
    "    result_df = result_df[\"entity\"].unique()\n",
    "    if result_df is not None:\n",
    "        for result in result_df:\n",
    "            res.append( {\"label\":result,\"value\":result})\n",
    "\n",
    "        return res\n",
    "    else:\n",
    "        raise PreventUpdate\n",
    "\n",
    "\n",
    "@app.callback([Output('entityfreqslider', 'value'),\n",
    "               Output('dropdown-freq-filter', 'value')],\n",
    "              [ Input('table-reset', 'n_clicks')],\n",
    "             [State('entityfreqslider', 'value'),\n",
    "              State('dropdown-freq-filter', 'value')])\n",
    "def reset(reset, entityfreq,freqoperator):\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        button_id = 'No clicks yet'\n",
    "    else:\n",
    "        button_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "                \n",
    "    if button_id == \"table-reset\" or button_id == \"No clicks yet\":\n",
    "        global curated_table_extractions\n",
    "        curated_table_extractions = filtered_table_extractions\n",
    "        global non_deleted_table_extractions\n",
    "        non_deleted_table_extractions = filtered_table_extractions\n",
    "        return [entity_frequency,\"ge\"]\n",
    "    \n",
    "import traceback    \n",
    "\n",
    "def get_freq(row, operator, filter_value, term_filters):\n",
    "    return eval(operator)(len(entity_stats[row['entity']]),int(filter_value)) or str(row['entity']).lower() in term_filters\n",
    "        \n",
    "non_deleted_table_extractions = filtered_table_extractions        \n",
    "@app.callback([\n",
    "               Output('datatable-upload-container', 'data'),\n",
    "               Output('datatable-upload-container', 'columns'),\n",
    "               Output('datatable-upload-container', 'editable'),\n",
    "               Output('datatable-upload-container', 'row_deletable'),\n",
    "               Output('datatable-upload-container', 'page_count')],\n",
    "              [Input('datatable-upload-container', 'page_size'),\n",
    "               Input('datatable-upload-container', 'page_current'),\n",
    "               Input('datatable-upload-container','data_timestamp'),\n",
    "               Input('datatable-upload', 'contents'),\n",
    "               Input('entityfreqslider', 'value'),\n",
    "               Input('dropdown-freq-filter', 'value'),\n",
    "              Input('datatable-upload-container', 'sort_by'),\n",
    "              Input('datatable-upload-container', 'filter_query')],\n",
    "              [State(\"datatable-upload-container\", \"data\"),\n",
    "               State(\"datatable-upload-container\", \"columns\"),\n",
    "              State('datatable-upload', 'filename'),\n",
    "              State('datatable-upload-container', 'derived_viewport_data'),\n",
    "                State(\"term_filters\", \"value\")\n",
    "              ])\n",
    "\n",
    "def update_output(page_size, page_current,ts,upload,entityfreq,\n",
    "                  freqoperator,sort_by,filter_query,data,\n",
    "                  columns, filename,derived_viewport_data, \n",
    "                  term_filters):\n",
    "    try:\n",
    "        ctx = dash.callback_context\n",
    "        if not ctx.triggered:\n",
    "            button_id = 'No clicks yet'\n",
    "        else:\n",
    "            button_id = ctx.triggered[0]['prop_id'].split('.')[0]        \n",
    "        if term_filters is not None:\n",
    "            term_filters = [str(term_filter_value).lower() for term_filter_value in term_filters ]\n",
    "        else:\n",
    "            term_filters = []\n",
    "        if upload is not None:\n",
    "            global curated_table_extractions\n",
    "            curated_table_extractions = parse_contents(upload, filename).copy()\n",
    "            \n",
    "        elif button_id == \"table-reset\":\n",
    "            curated_table_extractions = filtered_table_extractions.to_dict('records')\n",
    "        \n",
    "        elif derived_viewport_data:\n",
    "            \n",
    "            removed = [row for row in derived_viewport_data if row not in data and str(row[\"entity\"]).lower() not in term_filters]\n",
    "            global non_deleted_table_extractions\n",
    "            for row in removed:\n",
    "                curated_table_extractions= curated_table_extractions[curated_table_extractions.entity.str.lower() != str(row[\"entity\"]).lower()]\n",
    "                non_deleted_table_extractions=non_deleted_table_extractions[non_deleted_table_extractions.entity.str.lower() != str(row[\"entity\"]).lower()]\n",
    "\n",
    "        result = curated_table_extractions\n",
    "        columns= [{\"name\": i, \"id\": i, \"clearable\": True, \"selectable\": True, \"renamable\": True, \"hideable\": True, \"deletable\": False} for i in curated_table_extractions.columns ]\n",
    "\n",
    "\n",
    "        if (button_id == \"entityfreqslider\" or button_id==\"dropdown-freq-filter\")  and 'paper_id' in curated_table_extractions:\n",
    "            row_filtered = []\n",
    "           \n",
    "            curated_table_extractions =non_deleted_table_extractions[non_deleted_table_extractions.apply(lambda row: get_freq(row,freqoperator,entityfreq,term_filters), axis=1)]\n",
    "            result = curated_table_extractions\n",
    "        \n",
    "        # Filter by properties\n",
    "\n",
    "        dff = result\n",
    "        if filter_query:\n",
    "            filtering_expressions = filter_query.split(' && ')\n",
    "            for filter_part in filtering_expressions:\n",
    "                col_name, operator, filter_value = split_filter_part(filter_part)\n",
    "\n",
    "                if operator in ('eq', 'ne', 'lt', 'le', 'gt', 'ge'):\n",
    "                    dff = dff.loc[getattr(dff[col_name], operator)(filter_value)]\n",
    "                elif operator == 'contains':\n",
    "                    dff = dff.loc[dff[col_name].str.contains(filter_value)]\n",
    "                elif operator == 'datestartswith':\n",
    "                    dff = dff.loc[dff[col_name].str.startswith(filter_value)]\n",
    "            \n",
    "        # Sorting by properties\n",
    "        if sort_by and len(sort_by):\n",
    "            result_sorted = dff.sort_values(\n",
    "                [col['column_id'] for col in sort_by],\n",
    "                ascending=[\n",
    "                    col['direction'] == 'asc'\n",
    "                    for col in sort_by\n",
    "                ],\n",
    "                inplace=False\n",
    "            )\n",
    "        else:\n",
    "            result_sorted = dff\n",
    "            \n",
    "        result_paginated= result_sorted.iloc[\n",
    "            page_current*page_size:(page_current+ 1)*page_size\n",
    "        ]\n",
    "                \n",
    "        page_count = len(result_sorted) // page_size\n",
    "        \n",
    "        return result_paginated.to_dict('records'), columns, True, True, page_count\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.callback([Output('datatable-upload-Scatter', 'figure')],\n",
    "              [Input('datatable-upload-container', 'data_timestamp'),\n",
    "               Input('datatable-upload-container', 'data')],)\n",
    "def display_graph(dts, rows):\n",
    "    df = curated_table_extractions\n",
    "    \n",
    "    if (df.empty or len(df.columns) < 1):\n",
    "        \n",
    "        scatter = {\n",
    "                'data': [{\n",
    "                    'x': [],\n",
    "                    'y': []\n",
    "                }]\n",
    "            }\n",
    "    else:\n",
    "        if \"paper_id\" in df:\n",
    "            df[\"paper_id\"] = df[\"paper_id\"].transform(lambda x:  str(x).split(\":\")[0])\n",
    "            df_grouped = df[[\"paper_id\",\"entity_type\",\"entity\"]].groupby([\"entity\",\"entity_type\"]).paper_id.nunique().reset_index()\n",
    "            df_grouped = df_grouped.rename(columns={\"paper_id\": \"Frequency\"})\n",
    "            scatter = px.scatter(df_grouped, x=df_grouped.entity, y=df_grouped.Frequency, color=\"entity_type\")\n",
    "    return [scatter]\n",
    "\n",
    "\n",
    "app.width = \"100%\"\n",
    "app.height = \"100%\"\n",
    "app.run_server(mode=\"jupyterlab\",port=8071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pygments import highlight\n",
    "from pygments.lexers import JsonLdLexer, TurtleLexer\n",
    "from pygments.formatters import TerminalFormatter, TerminalTrueColorFormatter\n",
    "import json\n",
    "import uuid\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def pretty_print(a_json):\n",
    "    print(highlight(json.dumps(a_json, indent=2), JsonLdLexer(), TerminalFormatter()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from kgforge.core import Resource\n",
    "from kgforge.specializations.mappings import DictionaryMapping\n",
    "import uuid\n",
    "\n",
    "\n",
    "ANNOTATION_MAPPING_FILE = os.getenv(\"ANNOTATION_MAPPING_FILE\") \n",
    "assert (ANNOTATION_MAPPING_FILE is not None) \n",
    "\n",
    "PROPERTY_MAPPING_FILE = os.getenv(\"PROPERTY_MAPPING_FILE\") \n",
    "assert (PROPERTY_MAPPING_FILE is not None) \n",
    "\n",
    "annotation_maping = DictionaryMapping.load(ANNOTATION_MAPPING_FILE)\n",
    "property_maping = DictionaryMapping.load(PROPERTY_MAPPING_FILE)\n",
    "\n",
    "ressources_json = curated_table_extractions.to_dict('records')\n",
    "ressources_json = [dict(resource_json, **{\"id\":str(uuid.uuid4())}) for resource_json in tqdm(ressources_json)]\n",
    "\n",
    "print(\"Preparing \"+str(len(curated_table_extractions))+\" selected entities for ontology linking ...\")\n",
    "annotations = forge.map(ressources_json,[annotation_maping],na='')\n",
    "ressources_prop_mapped = forge.map(ressources_json,[property_maping],na='')\n",
    "print(\"Done \")\n",
    "\n",
    "import math\n",
    "\n",
    "for i,r in tqdm(enumerate(ressources_json)):\n",
    "    if 'property' in r and not math.isnan(r['property']):\n",
    "        annotations[i].target.selector.value.__setattr__(r['property'], ressources_prop_mapped[i])\n",
    "        annotations[i].body.__setattr__(r['property'], ressources_prop_mapped[i])\n",
    "        \n",
    "print(f'{len(annotations)} annotations created.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from joblib import parallel_backend\n",
    "class Candidate:\n",
    "    \n",
    "    def __init__(self, distance, alias, uid, concept, definition):\n",
    "        self.distance = distance\n",
    "        self.alias = alias\n",
    "        self.uid = uid\n",
    "        self.concept = concept\n",
    "        self.definition = definition\n",
    "    \n",
    "    def __repr__(self):\n",
    "        attrs = (f\"{k}={v!r}\" for k, v in self.__dict__.items())\n",
    "        return f\"Candidate({', '.join(attrs)})\"\n",
    "\n",
    "class EntityLinker:\n",
    "    \n",
    "    def __init__(self, bulk):\n",
    "        self.bulk = bulk\n",
    "        self.ontology = None\n",
    "        self.aliases = None\n",
    "        self.model = None\n",
    "        self.index = None\n",
    "    \n",
    "    def link(self, mentions, threshold=0.8):\n",
    "        selections = self.candidates(mentions, 3)\n",
    "        return [self.disambiguate(cs, m, None, threshold) for m, cs in selections]\n",
    "    \n",
    "    def disambiguate(self, candidates, mention, context, threshold):\n",
    "        # TODO Disambiguation requires the component to be part of the NLP pipeline.        \n",
    "        zeros = [x for x in candidates if x.distance == 0]\n",
    "        if zeros:\n",
    "            chosen = sorted(zeros, key=lambda x: len(x.concept))[0]\n",
    "            return chosen\n",
    "        else:\n",
    "            chosen = sorted(candidates, key=lambda x: x.distance)[0]\n",
    "            return chosen if chosen.distance <= threshold else None\n",
    "    \n",
    "    def candidates(self, mentions, limit):\n",
    "        def _(d, i):\n",
    "            alias, uid = self.aliases[int(i)]\n",
    "            return Candidate(d, alias, uid, *self.ontology[uid])\n",
    "        mentions_index = [(i,str(mention)) for i,mention in enumerate(mentions)]\n",
    "        mentions_labels = {str(mention) for mention in mentions}\n",
    "        embeddings = self.model.transform(mentions_labels)\n",
    "        \n",
    "        if self.bulk:\n",
    "            distances, indexes = self.index.search(embeddings.toarray(), limit)\n",
    "        else:\n",
    "           \n",
    "            distances = None\n",
    "            indexes = None\n",
    "            with parallel_backend('threading', n_jobs=10):\n",
    "                distances, indexes = self.index.kneighbors(embeddings, limit)\n",
    "        results = np.stack((distances, indexes), axis=2)\n",
    "        i_res= {m: [_(d, i) for d, i in rs] for m, rs in zip(mentions_labels, results)}\n",
    "        return [(m, i_res[m]) for i, m in mentions_index]\n",
    "        \n",
    "        \n",
    "    def train(self, ontology, model_params, index_params):\n",
    "        self.ontology = {k: (v[0], v[2]) for k, v in ontology.items()}\n",
    "        self.model = TfidfVectorizer(**model_params)\n",
    "        aliases = [(x, k) for k, v in ontology.items() for x in [v[0], *v[1]]]\n",
    "        embeddings = self.model.fit_transform(x for x, _ in aliases)\n",
    "        flags = np.array(embeddings.sum(axis=1) != 0).reshape(-1)\n",
    "        filtered_embeddings = embeddings[flags]\n",
    "        self.aliases = [t for t, f in zip(aliases, flags) if f]\n",
    "        if self.bulk:\n",
    "            self.index = faiss.IndexFlatL2(filtered_embeddings.shape[1])\n",
    "            self.index.add(filtered_embeddings.toarray())\n",
    "        else:\n",
    "            self.index = NearestNeighbors(**index_params)\n",
    "            self.index.fit(filtered_embeddings)\n",
    "        self._stats()\n",
    "    \n",
    "    def save_pretrained(self, dirpath):\n",
    "        with open(f'{dirpath}/model', 'wb') as f:\n",
    "            pickle.dump(linker.ontology, f)\n",
    "            pickle.dump(linker.aliases, f)\n",
    "            pickle.dump(linker.model, f)\n",
    "            if not self.bulk:\n",
    "                pickle.dump(linker.index, f)\n",
    "        if self.bulk:\n",
    "            faiss.write_index(linker.index, f'{dirpath}/index')\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_pretrained(dirpath, bulk):\n",
    "        linker = EntityLinker(bulk)\n",
    "        with open(f'{dirpath}/model', 'rb') as f:\n",
    "            linker.ontology = pickle.load(f)\n",
    "            linker.aliases = pickle.load(f)\n",
    "            linker.model = pickle.load(f)\n",
    "            if not bulk:\n",
    "                linker.index = pickle.load(f)\n",
    "        if bulk:\n",
    "            linker.index = index\n",
    "        linker._stats()\n",
    "        return linker\n",
    "    \n",
    "    def _stats(self):\n",
    "        ccount = len(self.ontology)\n",
    "        tcount = len(self.aliases)\n",
    "        print(f'INFO   EntityLinker   Links to {ccount} concepts ({tcount} aliases).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ONTOLOGY_LINKING_MODEL_PATH = os.getenv(\"ONTOLOGY_LINKING_MODEL_PATH\")\n",
    "assert (ONTOLOGY_LINKING_MODEL_PATH is not None)\n",
    "linker = EntityLinker.from_pretrained(ONTOLOGY_LINKING_MODEL_PATH, bulk=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from typing import Iterable, Dict, Iterator\n",
    "from copy import deepcopy\n",
    "\n",
    "def enrich_annotations(annotations: Iterable[Dict], linker: EntityLinker) -> Iterator[Dict]:\n",
    "    def _(ann, can):\n",
    "        new = deepcopy(ann)\n",
    "        #pretty_print(ann)\n",
    "        if can:\n",
    "            new.body = {\n",
    "                '@id': can.uid,\n",
    "                '@type': forge.as_json(ann)[\"body\"][\"@type\"],\n",
    "                'label': can.concept,\n",
    "                'definition':can.definition\n",
    "            }\n",
    "        else:\n",
    "            new.body = {\n",
    "                '@id': 'https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/data/entity/'+new.body.id[0],\n",
    "                '@type': forge.as_json(ann)[\"body\"][\"@type\"],\n",
    "                'label': new.body.label\n",
    "            }\n",
    "        return new\n",
    "    mentions = [x.target.selector.value.label for x in annotations]\n",
    "    print(\"Linking \"+str(len(curated_table_extractions))+\" extracted entities to ontology terms ...\")\n",
    "    linked_mentions = linker.link(mentions)\n",
    "    return (_(ann, can) for ann, can in tqdm(zip(annotations, linked_mentions)))\n",
    "\n",
    "enriched_annotations = list(enrich_annotations(annotations, linker))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the knowledge graph\n",
    "Content of the Knowledge Graph is validated. In this version, syntactic validation (i.e. are the identifiers correct, ...) is performed when building the knowledge graph. If the knowledge graph is successfully built then the validation passes. In case of warning (i.e because of a weird character (+,...) in an extracted entity), the user can go back to the curation step and further curate extracted entities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Build knowledge graph from enriched annotations\n",
    "import json\n",
    "from typing import Iterable, Dict\n",
    "from rdflib import Graph\n",
    "\n",
    "def load_knowledge_graph(jsonlds: Iterable[Dict]) -> Graph:\n",
    "    g = Graph()\n",
    "    for x in tqdm(jsonlds):\n",
    "        x = forge.as_jsonld(x, form=\"expanded\")\n",
    "        g.parse(data=json.dumps(x), format='json-ld')\n",
    "    return g\n",
    "\n",
    "print(\"Generating the knowledge graph ...\")\n",
    "knowledge_graph = load_knowledge_graph(enriched_annotations)\n",
    "print(\"Done.\")\n",
    "print(f'The knowledge graph has {len(knowledge_graph)} triples.')\n",
    "\n",
    "content_graph= Graph()\n",
    "import rdflib\n",
    "for o in knowledge_graph.objects(None,rdflib.term.URIRef(\"http://www.w3.org/ns/anno.jsonld/hasBody\")):\n",
    "    for ss, pp, oo in knowledge_graph.triples((rdflib.term.URIRef(o),None,None)):\n",
    "        content_graph.add((ss,pp,oo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct knowledge graph\n",
    "Correction involves going back to the extraction and/or curation steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access the knowledge graph\n",
    "The user can search, visualize, and export the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_digraph\n",
    "import networkx as nx\n",
    "from rdflib.namespace import RDF, RDFS, SKOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Building co-mention graph\")\n",
    "reshaped_enriched_annotations = forge.reshape(enriched_annotations, keep=[\"body\",\"target.selector.exact\",\"target.source\"])\n",
    "\n",
    "enriched_annotations_df = forge.as_dataframe(reshaped_enriched_annotations)\n",
    "\n",
    "def _build_co_mention(group_by, retrieve_key,df):\n",
    "    entity_co_mention = df[[group_by,retrieve_key]].groupby(group_by)\n",
    "    group_keys = list(entity_co_mention.groups.keys())\n",
    "    all_co_mentions = [entity_co_mention.get_group(group_key)[retrieve_key].dropna().unique() for group_key in group_keys]\n",
    "    return entity_co_mention, group_keys,all_co_mentions\n",
    "        \n",
    "enriched_entity_stats = _frequency(group_by=\"body.@id\",retrieve_key=\"target.source\",df=enriched_annotations_df,distinct_papers=True)\n",
    "relation_stats = _frequency(group_by=\"property\",retrieve_key=\"paper_id\",df=curated_table_extractions,distinct_papers=True)\n",
    "\n",
    "entity_co_mention, paper_ids,all_co_mentions = _build_co_mention(group_by=\"target.source\",retrieve_key= \"body.@id\",df=enriched_annotations_df)\n",
    "\n",
    "comention_graph= rdflib.ConjunctiveGraph()\n",
    "\n",
    "import rdflib\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.paths import Path\n",
    "\n",
    "\n",
    "comentioned_dict = {}\n",
    "   \n",
    "for paper_id in paper_ids:\n",
    "    comentioned_entities = entity_co_mention.get_group(paper_id)[\"body.@id\"].dropna().unique()\n",
    "    comentioned_entities = set(comentioned_entities)\n",
    "    for comentioned_entity in  comentioned_entities:\n",
    "        if comentioned_entity not in comentioned_dict:\n",
    "            comentioned_dict[comentioned_entity] = []\n",
    "        comentioned_dict[comentioned_entity].append((paper_id,comentioned_entities))\n",
    "\n",
    "\n",
    "for ss in comentioned_dict.keys():\n",
    "    for aPaper, co_mentioned_entities in comentioned_dict[str(ss)]:\n",
    "        for co_mentioned in co_mentioned_entities:\n",
    "            if ss != co_mentioned:\n",
    "                if (rdflib.term.URIRef(co_mentioned),rdflib.term.URIRef(\"https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/vocab/comention\"),rdflib.term.URIRef(ss), aPaper) not in comention_graph:\n",
    "                    comention_graph.add((rdflib.term.URIRef(ss),rdflib.term.URIRef(\"https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/vocab/comention\"),rdflib.term.URIRef(co_mentioned),aPaper))\n",
    "                    \n",
    "print(\"Done ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_digraph\n",
    "import base64\n",
    "import io\n",
    "import dash\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_table\n",
    "import pandas as pd\n",
    "import dash_cytoscape as cyto\n",
    "\n",
    "cyto.load_extra_layouts()\n",
    "def build_cytoscape_elements(comention_graph, content_graph, graph_type=\"comention\"):\n",
    "    elements = []\n",
    "    \n",
    "    G = rdflib_to_networkx_digraph(comention_graph) if graph_type ==\"comention\" else rdflib_to_networkx_digraph(content_graph)\n",
    "    \n",
    "    def addNode(id, node_type,label=None, label_size=10, label_color=\"black\", radius=30, node_color='grey',frequency=1, definition=\"\",papers=[]):\n",
    "\n",
    "        actualLabel = None\n",
    "        if label is not None:\n",
    "            actualLabel = label.lower()\n",
    "        else:\n",
    "            actualLabel = str(id).lower().split(\"/\")[-1].split(\"#\")[-1]\n",
    "\n",
    "        elements.append({\n",
    "            \"data\": { \n",
    "                \"id\": str(id).lower(),\n",
    "                \"frequency\":frequency,\n",
    "                \"definition\":definition,\n",
    "                \"papers\":papers,\n",
    "                \"type\":node_type\n",
    "            },\n",
    "            \"style\": {\n",
    "                \"label\": actualLabel,\n",
    "                \"width\": radius,\n",
    "                \"height\": radius\n",
    "            }\n",
    "        })\n",
    "        \n",
    "    \n",
    "    def addEdge(id, from_id, to_id, label=None, label_size=10, label_color=\"black\", thickness=2, edge_color=\"grey\", edge_style=\"solid\",frequency=1,papers=[]):\n",
    "        \n",
    "        if thickness == 0:\n",
    "            thickness = 2\n",
    "        elements.append({\n",
    "            \"data\": { \n",
    "                \"id\": str(id),\n",
    "                \"source\": str(from_id).lower(),\n",
    "                \"target\": str(to_id).lower(),\n",
    "                \"frequency\":frequency,\n",
    "                \"papers\":papers\n",
    "            },\n",
    "            \"style\": {\n",
    "               \"label\": label if label else '',\n",
    "                \"width\": thickness\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        \n",
    "\n",
    "    for node, node_attrs in G.nodes(data=True):\n",
    "        if (str(node).startswith(\"http\")) and not (str(node).startswith('https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/schemas/')):\n",
    "            node_label = content_graph.label(node,str(node).split(\"/\")[-1].split(\"#\")[-1])\n",
    "            node_type = content_graph.value(node,RDF.type, default=\"\",any=True).split(\"/\")[-1].split(\"#\")[-1]\n",
    "            node_definition = content_graph.value(node,SKOS.definition, default=\"\", any=True)\n",
    "    \n",
    "            node_radius = 5\n",
    "            frequency=1\n",
    "            \n",
    "     \n",
    "            node_papers = enriched_entity_stats[str(node)]\n",
    "            frequency = len(node_papers)\n",
    "            if frequency >= 1:\n",
    "                node_radius = frequency * node_radius\n",
    "                addNode(str(node), node_type,label=node_label,radius=node_radius, frequency=frequency,node_color=\"lightblue\", label_color='blue',definition=node_definition, papers = node_papers)\n",
    "       \n",
    "    \n",
    "    \n",
    "    for source, target, edge_attrs in G.edges(data=True):\n",
    "        if not 'value' in edge_attrs and not 'width' in edge_attrs and 'weight' in edge_attrs:\n",
    "            edge_attrs['value'] = edge_attrs['weight']\n",
    "        if 'triples' in edge_attrs:\n",
    "            edge_attrs['title'] = edge_attrs['triples'][0][1]\n",
    "        edge_id = str(source).lower().replace(\" \",\"_\")+\"_\"+str(target).lower()\n",
    "        edge_label = str(edge_attrs['title']).split(\"/\")[-1].split(\"#\")[-1]\n",
    "        \n",
    "        if edge_label != \"label\" and edge_label != \"definition\" and edge_label != \"type\":\n",
    "            thickness = 2\n",
    "            edge_papers = set()\n",
    "            \n",
    "            if graph_type == \"comention\":\n",
    "                for q in comention_graph.quads((rdflib.term.URIRef(source),rdflib.term.URIRef('https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/vocab/comention'),rdflib.term.URIRef(target),None)):\n",
    "                    edge_papers.add(q[3].identifier)\n",
    "                for q in comention_graph.quads((rdflib.term.URIRef(target),rdflib.term.URIRef('https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/vocab/comention'),rdflib.term.URIRef(source),None)):\n",
    "                    edge_papers.add(q[3].identifier)\n",
    "            else:\n",
    "                edge_papers = relation_stats[edge_labelge]\n",
    "                \n",
    "            thickness = thickness * len(edge_papers)\n",
    "          \n",
    "            if len(edge_papers) >= 1:\n",
    "                addEdge(\n",
    "                        id = edge_id, \n",
    "                        from_id = str(source), \n",
    "                        to_id = str(target), \n",
    "                        label=None if graph_type == \"comention\" else edge_label,\n",
    "                        label_size=6,\n",
    "                        thickness=thickness, \n",
    "                         edge_color=\"lightgrey\",\n",
    "                        frequency=len(edge_papers),\n",
    "                        papers = list(edge_papers)\n",
    "                       )\n",
    "  \n",
    "    return elements, G\n",
    "\n",
    "print(\"Generating Knowledge Graph and Co-mention visualisation data ...\")\n",
    "comention_graph_cyto_elements, G = build_cytoscape_elements(comention_graph, content_graph, graph_type=\"comention\")\n",
    "knowledge_graph_cyto_elements, G = build_cytoscape_elements(comention_graph, content_graph, graph_type=\"kg\")\n",
    "\n",
    "comention_graph_cyto_elements_dict = {elt['data']['id']:elt for elt in comention_graph_cyto_elements}\n",
    "knowledge_graph_cyto_elements_dict= {elt['data']['id']:elt for elt in knowledge_graph_cyto_elements}\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################# Graph LAYOUT Definition ################################\n",
    "\n",
    "node_shape_option_list = ['ellipse',\n",
    "                                'triangle',\n",
    "                                'rectangle',\n",
    "                                'diamond',\n",
    "                                'pentagon',\n",
    "                                'hexagon',\n",
    "                                'heptagon',\n",
    "                                'octagon',\n",
    "                                'star',\n",
    "                                'polygon']\n",
    "\n",
    "dropdown_download_option_list = [\n",
    "                                    'jpg',\n",
    "                                    'png',\n",
    "                                    'svg'\n",
    "                                ]\n",
    "\n",
    "graph_layout_option_list = ['random',\n",
    "                                'grid',\n",
    "                                'circle',\n",
    "                                'concentric',\n",
    "                                'breadthfirst',\n",
    "                                'cose',\n",
    "                                'cose-bilkent',\n",
    "                                'dagre',\n",
    "                                'cola',\n",
    "                                'klay',\n",
    "                                'spread',\n",
    "                                'euler']\n",
    "\n",
    "graph_type_option_list = ['Knowledge Graph', 'Co-mention Graph']\n",
    "\n",
    "\n",
    "button_group = dbc.InputGroup(\n",
    "    [\n",
    "                        dbc.Button(\"Reset\", color=\"primary\", className=\"mr-1\",id='bt-reset'),\n",
    "                        dbc.Button(\"Remove Selected Node\", color=\"primary\", className=\"mr-1\",id='remove-button'),\n",
    "                        dbc.DropdownMenu(\n",
    "                            [\n",
    "                             dbc.DropdownMenuItem(\"png\", id=\"png-menu\"),\n",
    "                                dbc.DropdownMenuItem(divider=True),\n",
    "                             dbc.DropdownMenuItem(\"jpg\", id=\"jpg-menu\"),\n",
    "                                 dbc.DropdownMenuItem(divider=True),\n",
    "                             dbc.DropdownMenuItem(\"svg\", id=\"svg-menu\")\n",
    "                            ],\n",
    "                            label=\"Download\",\n",
    "                            id='dropdown-download',\n",
    "                            \n",
    "                            color=\"primary\",\n",
    "                            group=True,\n",
    "                            className=\"mr-1\"\n",
    "                        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "buttons = dbc.FormGroup(\n",
    "            [\n",
    "                 button_group\n",
    "            ],className=\"mr-1\"\n",
    "        )\n",
    "\n",
    "radios_input = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Label(\"Display\", html_for=\"showgraph\", width=3),\n",
    "        dbc.Col(\n",
    "            dbc.RadioItems(\n",
    "                id=\"showgraph\",\n",
    "                value='Co-mention Graph',\n",
    "                options=[{'label': val.capitalize(), 'value': val} for val in graph_type_option_list]\n",
    "            ), width=9\n",
    "        )\n",
    "    ],\n",
    "    row=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_group = dbc.InputGroup(\n",
    "    [\n",
    "        dbc.InputGroupAddon(\n",
    "            \"Search\",\n",
    "            addon_type=\"prepend\",\n",
    "        ),\n",
    "         dcc.Dropdown(\n",
    "            id=\"searchdropdown\",\n",
    "            multi=True,\n",
    "             style={\n",
    "                 \"width\":\"80%\"\n",
    "             }\n",
    "             \n",
    "        )\n",
    "        \n",
    "    ],\n",
    "    className=\"mb-3\"\n",
    ")\n",
    "\n",
    "\n",
    "search = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Label(\"Search\", html_for=\"searchdropdown\", width=3),\n",
    "        dbc.Col(dcc.Dropdown(\n",
    "            id=\"searchdropdown\",\n",
    "            multi=True\n",
    "        ), width=9)\n",
    "        \n",
    "    ],\n",
    "    \n",
    "    row=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "node_slider = dbc.InputGroup(\n",
    "    [\n",
    "        dbc.InputGroupAddon(\n",
    "            dbc.Button(\"Node frequency\", color=\"primary\"),\n",
    "            addon_type=\"prepend\",\n",
    "            className=\"mr-1\"\n",
    "        ),\n",
    "        dcc.Dropdown(\n",
    "            id='node-freq-filter',\n",
    "            value=\"ge\",\n",
    "            clearable=False,\n",
    "            options = dropdown_freq_filter_list,\n",
    "            \n",
    "            className=\"mr-1\"\n",
    "        ),\n",
    "        daq.NumericInput(\n",
    "            id=\"nodefreqslider\",\n",
    "            min=1,  \n",
    "            max=10000,\n",
    "            value=1,\n",
    "           className=\"mr-1\"\n",
    "        )\n",
    "        \n",
    "       \n",
    "    ],\n",
    "    className=\"mb-3\"\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "item_details = dbc.FormGroup(\n",
    "    [\n",
    "        \n",
    "        html.Div(id=\"modal\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "item_details_card = dbc.Card(\n",
    "                        dbc.CardBody(\n",
    "                            [\n",
    "                                html.H5(\"therapeutic insulin\", className=\"card-title\"),\n",
    "                                html.H6(\"PROTEIN\", className=\"card-subtitle\"),\n",
    "                                html.P(\n",
    "                                    \"A synthetic or animal-derived form of insulin used in the treatment of diabetes mellitus. Therapeutic insulin is formulated to be short-, intermediate- and long-acting in order to individualize an insulin regimen according to individual differences in glucose and insulin metabolism. Therapeutic insulin may be derived from porcine, bovine or recombinant sources. Endogenous human insulin, a pancreatic hormone composed of two polypeptide chains, is important for the normal metabolism of carbohydrates, proteins and fats and has anabolic effects on many types of tissues.\",\n",
    "                                    className=\"card-text\"\n",
    "                                ),\n",
    "                                dbc.Button(\"See more\", color=\"primary\", id =\"see-more-card\")\n",
    "                            ],\n",
    "                            id = \"item-card-body\"\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "form = dbc.Form([button_group, radios_input,search,node_slider,item_details_card])\n",
    "\n",
    "\n",
    "\n",
    "graph_layout = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Label(\"Layout\", html_for=\"searchdropdown\", width=3),\n",
    "        dbc.Col(dcc.Dropdown(\n",
    "            id ='dropdown-layout',\n",
    "            options = [{'label': val.capitalize(), 'value': val} for val in graph_layout_option_list],\n",
    "            value='circle',\n",
    "            clearable=False\n",
    "        ), width=9)\n",
    "        \n",
    "    ],\n",
    "    row=True\n",
    ")\n",
    "\n",
    "node_shape = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Label(\"Node Shape\", html_for=\"dropdown-node-shape\", width=3),\n",
    "        dbc.Col(dcc.Dropdown(\n",
    "            id='dropdown-node-shape',\n",
    "            value='ellipse',\n",
    "            clearable=False,\n",
    "            options = [{'label': val.capitalize(), 'value': val} for val in node_shape_option_list]\n",
    "        ), width=9)\n",
    "        \n",
    "    ],\n",
    "    row=True\n",
    ")\n",
    "\n",
    "link_color_picker = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Col(daq.ColorPicker(\n",
    "          id='input-follower-color',\n",
    "          value=dict(hex='#a0b3dc'),\n",
    "          label=\"Edge Color\"\n",
    "        ))    \n",
    "    ],\n",
    "    row=True\n",
    ")\n",
    "\n",
    "\n",
    "conf_form =dbc.Form([graph_layout,node_shape,link_color_picker])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import dash\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "\n",
    "\n",
    "import dash_cytoscape as cyto\n",
    "\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "def load_json(st):\n",
    "    if 'http' in st:\n",
    "        return requests.get(st).json()\n",
    "    else:\n",
    "        with open(st, 'rb') as f:\n",
    "            x = json.load(f)\n",
    "        return x\n",
    "    \n",
    "# Load extra layouts\n",
    "cyto.load_extra_layouts()\n",
    "app_tab =  JupyterDash(\"allvis\")\n",
    "\n",
    "app_tab.add_bootstrap_links = True\n",
    "app_tab.external_stylesheets=dbc.themes.CYBORG\n",
    "\n",
    "server = app_tab.server\n",
    "\n",
    "\n",
    "CONTENT_STYLE = {\n",
    "    \n",
    "    \"width\": \"70%\",\n",
    "    \"top\": \"0px\",\n",
    "    \"left\":\"0px\",\n",
    "    \"bottom\": \"0px\",\n",
    "    \"position\": \"fixed\",\n",
    "\n",
    "    }\n",
    "\n",
    "colors = {\n",
    "    \"CHEMICAL\":\"green\",\n",
    "    \"PROTEIN\":\"#469d8c\",\n",
    "    \"DISEASE\":\"#dceef1\",\n",
    "    \"CELL_TYPE\":\"#f1d2b5\"\n",
    "}\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "cystoscape_STYLE_stylesheet = [\n",
    "    {\n",
    "        \"selector\":'cytoscape',\n",
    "        \"style\": {\n",
    "            \"width\": \"100%\",\n",
    "            \"height\": \"100%\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"selector\": 'node[type = \"CHEMICAL\"]',\n",
    "        \"style\": {\"background-color\": colors[\"CHEMICAL\"]},\n",
    "    },{\n",
    "        \"selector\": 'node',\n",
    "        'style': {\n",
    "            \"font-size\": 100,\n",
    "            \"font-weight\":\"bold\",\n",
    "            \"text-valign\": \"center\",\n",
    "            \"text-halign\": \"center\",\n",
    "            \"text-outline-color\": \"#000000\",\n",
    "            \"text-outline-width\": \"2px\",\n",
    "            \"color\": \"black\",\n",
    "            \"overlay-padding\": \"6px\",\n",
    "            \"z-index\": \"10\"\n",
    "        }\n",
    "    },{\n",
    "        \"selector\": 'edge',\n",
    "        \"style\": {\n",
    "            'curve-style': 'bezier',\n",
    "            'line-color': '#D5DAE6'\n",
    "        }\n",
    "    },{\n",
    "        \"selector\": 'node[type = \"PROTEIN\"]',\n",
    "        \"style\": {\"background-color\": colors[\"PROTEIN\"]},\n",
    "    },{\n",
    "        \"selector\": 'node[type = \"DISEASE\"]',\n",
    "        \"style\": {\"background-color\": colors[\"DISEASE\"]},\n",
    "    },{\n",
    "        \"selector\": 'node[type = \"CELL_TYPE\"]',\n",
    "        \"style\": {\"background-color\": colors[\"CELL_TYPE\"]},\n",
    "    }]\n",
    "  \n",
    "\n",
    "\n",
    "app_tab.layout  = html.Div(  \n",
    "    [\n",
    "         dcc.Store(id='memory',data={\"removed\":[]}),\n",
    "       \n",
    "    dbc.Row(\n",
    "            [\n",
    "                dbc.Col(\n",
    "                \n",
    "                html.Div( style=CONTENT_STYLE, children=[\n",
    "                    cyto.Cytoscape(\n",
    "                        id='cytoscape',\n",
    "                        elements=comention_graph_cyto_elements,\n",
    "                        stylesheet=cystoscape_STYLE_stylesheet,\n",
    "                        style= {\n",
    "                                \"width\": \"100%\",\n",
    "                                \"height\": \"100%\"\n",
    "                        }\n",
    "                    )\n",
    "                ]),\n",
    "                    width=8\n",
    "                ),\n",
    "                dbc.Col(\n",
    "                    \n",
    "                    html.Div( children=[\n",
    "                        dbc.Tabs(id='tabs', children=[\n",
    "                            dbc.Tab(label='Details', label_style={\"color\": \"#00AEF9\", \"border-radius\":\"4px\"},children=[\n",
    "                                \n",
    "                                dbc.Card(\n",
    "                                    dbc.CardBody(\n",
    "                                        [\n",
    "                                            form\n",
    "                                        ]\n",
    "                                    )\n",
    "                                )\n",
    "                                \n",
    "                                \n",
    "                            ]),\n",
    "                            dbc.Tab(label='Graph Layout and Shape', label_style={\"color\": \"#00AEF9\"}, children=[\n",
    "                                dbc.Card(\n",
    "                                    dbc.CardBody(\n",
    "                                        [\n",
    "                                            conf_form\n",
    "                                        ]\n",
    "                                    )\n",
    "                                )\n",
    "                            ])\n",
    "                        ]),\n",
    "                    ]),\n",
    "                    width=4\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "# ############################## CALLBACKS ####################################\n",
    "\n",
    "\n",
    "@app_tab.callback(\n",
    "    Output(\"modal-body-scroll\", \"is_open\"),\n",
    "    [\n",
    "        Input(\"open-body-scroll\", \"n_clicks\"),\n",
    "        Input(\"close-body-scroll\", \"n_clicks\"),\n",
    "    ],\n",
    "    [State(\"modal-body-scroll\", \"is_open\")],\n",
    ")\n",
    "def toggle_modal(n1, n2, is_open):\n",
    "    if n1 or n2:\n",
    "        return not is_open\n",
    "    return is_open\n",
    "\n",
    "\n",
    "@app_tab.callback(\n",
    "    Output(\"searchdropdown\", \"options\"),\n",
    "    [Input(\"searchdropdown\", \"search_value\")],\n",
    "    [State(\"searchdropdown\", \"value\"),\n",
    "    State('cytoscape', 'elements')],\n",
    ")\n",
    "def update_multi_options(search_value, value,elements):\n",
    "    \n",
    "    if not search_value:\n",
    "        raise PreventUpdate\n",
    "    \n",
    "\n",
    "    res = []\n",
    "    for ele_data in elements:\n",
    "        \n",
    "        if 'label' in ele_data['style']:\n",
    "            label =ele_data['style']['label']\n",
    "           \n",
    "            if (search_value in label) or (label in search_value) or ele_data['data']['id'] in (value or []) :\n",
    "\n",
    "                #ele_data[\"selected\"]=True\n",
    "                res.append( {\"label\":ele_data['style']['label'],\"value\":ele_data['data']['id']})\n",
    "  \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "@app_tab.callback(Output('nodefreqslider', 'value'),\n",
    "              [Input('bt-reset', 'n_clicks')],[State('nodefreqslider', 'value')])\n",
    "def display_freq_node(resetbt, nodefreqslider):\n",
    "    \n",
    "    \n",
    "    ctx = dash.callback_context\n",
    "\n",
    "    if not ctx.triggered:\n",
    "        button_id = 'No clicks yet'\n",
    "    else:\n",
    "        button_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "        \n",
    "    if button_id == 'bt-reset':\n",
    "        return 1\n",
    "\n",
    "@app_tab.callback(\n",
    "    [\n",
    "        Output('cytoscape', 'generateImage')\n",
    "    ],\n",
    "    [\n",
    "        Input('jpg-menu', 'n_clicks'),\n",
    "        Input('svg-menu', 'n_clicks'),\n",
    "        Input('png-menu', 'n_clicks')\n",
    "    ]\n",
    ")\n",
    "def download_image(jpg_menu,svg_menu,png_menu):\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        button_id = 'No clicks yet'\n",
    "    else:\n",
    "        button_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "    ftype  = None\n",
    "    if button_id == \"png-menu\":\n",
    "        ftype = \"png\"\n",
    "    if button_id == \"jpg-menu\":\n",
    "        ftype = \"jpg\"\n",
    "    if button_id == \"svg-menu\":\n",
    "        ftype = \"svg\"\n",
    "    return [{\n",
    "        'type': ftype,\n",
    "        'action': \"download\"\n",
    "    }]\n",
    "\n",
    "removed = set()\n",
    "from sqlalchemy.sql import select\n",
    "from sqlalchemy.sql import and_, or_, not_\n",
    "\n",
    "def list_papers (papers):\n",
    "    META_DATA = sqlalchemy.MetaData(bind=engine, reflect=True)\n",
    "    articles = META_DATA.tables[\"articles\"]\n",
    "    clauses = or_( *[articles.c.article_id==x for x in papers] )\n",
    "    s = select([articles.c.title,articles.c.authors,articles.c.abstract,articles.c.doi,articles.c.url,articles.c.journal,articles.c.pmcid,articles.c.pubmed_id,articles.c.publish_time]).where(\n",
    "       clauses\n",
    "       )\n",
    "    result = engine.execute(s)\n",
    "    results = []\n",
    "    for row in result:\n",
    "        results.append(row)\n",
    "    return results\n",
    "\n",
    "@app_tab.callback(\n",
    "    [\n",
    "        Output('cytoscape', 'zoom'),\n",
    "        Output('cytoscape', 'elements')\n",
    "    ],\n",
    "    [\n",
    "        Input('bt-reset', 'n_clicks'),\n",
    "        Input('remove-button', 'n_clicks'),\n",
    "        Input('showgraph', 'value'),\n",
    "        Input('nodefreqslider', 'value'),\n",
    "        Input('node-freq-filter', 'value'),\n",
    "        Input(\"searchdropdown\", \"value\")\n",
    "        \n",
    "     ],\n",
    "     [\n",
    "        State('cytoscape', 'elements'),\n",
    "        State('cytoscape', 'selectedNodeData'),\n",
    "        State('cytoscape', 'selectedEdgeData'),\n",
    "        State('cytoscape', 'tapNodeData'),\n",
    "        State('cytoscape', 'zoom'),\n",
    "         State('nodefreqslider', 'value')\n",
    "        \n",
    "      ]\n",
    ")\n",
    "\n",
    "def reset_layout(resetbt, removebt, val, nodefreqslider, node_freq_operator,searchvalues,cytoelements, data, edge,tappednode,zoom,nodefreqsliderstate):\n",
    "    global removed \n",
    "    elements = cytoelements\n",
    "    elements_dict  = {elt['data']['id']:elt for elt in cytoelements}\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        button_id = 'No clicks yet'\n",
    "    else:\n",
    "        button_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "    if button_id == 'showgraph':\n",
    "        if val == 'Knowledge Graph':\n",
    "            elements = knowledge_graph_cyto_elements\n",
    "            elements_dict = knowledge_graph_cyto_elements_dict\n",
    "        if val == 'Co-mention Graph':\n",
    "            elements = comention_graph_cyto_elements\n",
    "            elements_dict = comention_graph_cyto_elements_dict\n",
    "\n",
    "    if searchvalues is not None:\n",
    "        for searchvalue in searchvalues:\n",
    "            search_node = elements_dict[searchvalue]\n",
    "            search_node[\"selected\"]=True\n",
    "    \n",
    "    if nodefreqslider == 1:\n",
    "        if val == 'Knowledge Graph':\n",
    "            elements = knowledge_graph_cyto_elements\n",
    "            elements_dict = knowledge_graph_cyto_elements_dict\n",
    "        if val == 'Co-mention Graph':\n",
    "            elements = comention_graph_cyto_elements\n",
    "            elements_dict = comention_graph_cyto_elements_dict\n",
    "        zoom =1\n",
    "        global removed\n",
    "        removed = set()\n",
    "\n",
    "    if button_id == 'remove-button':\n",
    "        if elements and data:\n",
    "            ids_to_remove = {ele_data['id'] for ele_data in data}\n",
    "        if elements and edge:\n",
    "            ids_to_remove = {ele_data['id'] for ele_data in edge}\n",
    "            \n",
    "        elements = [ele for ele in elements if ele['data']['id'] not in ids_to_remove]\n",
    "\n",
    "        removed.update(ids_to_remove)\n",
    "\n",
    "   \n",
    "    if elements and (nodefreqslider is not None and button_id == 'nodefreqslider') :\n",
    "        \n",
    "        if val == 'Knowledge Graph':\n",
    "            elements = knowledge_graph_cyto_elements\n",
    "        if val == 'Co-mention Graph':\n",
    "            elements = comention_graph_cyto_elements\n",
    "       \n",
    "        ids_to_remove = [ele_data['data']['id'] for ele_data in elements if 'source' not in ele_data[\"data\"] and ele_data[\"data\"][\"id\"] not in removed and 'frequency' in ele_data['data'] and ele_data['data']['frequency'] is not None and not eval(node_freq_operator)(int(ele_data['data']['frequency']), int(nodefreqslider))]\n",
    "       \n",
    "        elements = [ele for ele in elements if ele['data']['id'] not in ids_to_remove]\n",
    "  \n",
    "    return zoom, elements\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app_tab.callback([Output('item-card-body', 'children')],\n",
    "                  [Input('cytoscape', 'tapNode'),Input('cytoscape', 'tapEdge')],\n",
    "                  [State('cytoscape', 'selectedNodeData'),State('cytoscape', 'selectedEdgeData')])\n",
    "def display_tap_node(datanode, dataedge,statedatanode,statedataedge):\n",
    "        \n",
    "\n",
    "    papers = []\n",
    "    res = []\n",
    "    modal_button = None\n",
    "    if datanode and statedatanode:\n",
    "        definition = \"\"\n",
    "        if 'definition' in str(datanode['data']):\n",
    "            definition = str(datanode['data']['definition'])\n",
    "        label = str(datanode['style']['label'])\n",
    "        _type = str(datanode['data']['type'])\n",
    "        frequency = str(datanode['data']['frequency'])\n",
    "        res.append([\n",
    "            html.H5(label, className=\"card-title\"),\n",
    "            html.H6(_type, className=\"card-subtitle\"),\n",
    "            html.P(\n",
    "                definition,\n",
    "                className=\"card-text\"\n",
    "            )\n",
    "            \n",
    "        ])\n",
    "        label = \"'\"+label+\"' mentioned in \"+frequency+\" papers\"\n",
    "        modal_button = dbc.Button(label, id=\"open-body-scroll\",color=\"primary\")\n",
    "        \n",
    "        papers= datanode['data']['papers']\n",
    "\n",
    "        \n",
    "    if dataedge and statedataedge:\n",
    "        label = str(dataedge['style']['label'])\n",
    "        \n",
    "        source_node = comention_graph_cyto_elements_dict[ dataedge['data']['source']]\n",
    "        source_label = source_node['style']['label']\n",
    "        target_node = comention_graph_cyto_elements_dict[ dataedge['data']['target']]\n",
    "        target_label = target_node['style']['label']\n",
    "        frequency = str(dataedge['data']['frequency'])\n",
    "        mention_label= ''' '%s' mentioned in %s papers with '%s' ''' % (source_label, frequency, target_label) \n",
    "        label = mention_label if str(dataedge['style']['label']) == \"\" else str(dataedge['style']['label']) \n",
    "        modal_button= dbc.Button(label, id=\"open-body-scroll\",color=\"primary\")\n",
    "    \n",
    "        papers= dataedge['data']['papers']\n",
    "       \n",
    "    if len(papers) > 0:\n",
    "        papers_in_kg = list_papers(papers)\n",
    "\n",
    "       \n",
    "        rows = []\n",
    "        \n",
    "        if papers_in_kg:\n",
    "            for paper in papers_in_kg:\n",
    "                title = paper[0] if paper[0] else ''\n",
    "                authors = paper[1] if paper[1] else ''\n",
    "                abstract = paper[2] if paper[2] else ''\n",
    "                journal = paper[5] if paper[5] else ''\n",
    "                url = paper[4] if paper[4] else ''\n",
    "                publish_time = str(paper[8]) if paper[8] else ''\n",
    "\n",
    "                abstract = (abstract[:500] + '...') if abstract and len(abstract) > 500 else abstract\n",
    "                \n",
    "                paper_card = dbc.Card(\n",
    "                                    dbc.CardBody(\n",
    "                                        [\n",
    "                                            html.H4(title, className=\"card-title\"),\n",
    "                                            html.H5(authors, className=\"card-subtitle\"),\n",
    "                                            \n",
    "                                            html.H6(journal+\"( \"+publish_time+\" )\", className=\"card-subtitle\"),\n",
    "                                            html.P(\n",
    "                                                abstract,\n",
    "                                                className=\"card-text\"\n",
    "                                            ),\n",
    "                                            dbc.Button(\"View the paper\", href=url,target=\"_blank\",color=\"primary\"),\n",
    "                                        ]\n",
    "                                    )\n",
    "                                )\n",
    "                rows.append(paper_card)\n",
    "\n",
    "            cards = dbc.Row(rows)        \n",
    "\n",
    "            modal = html.Div(\n",
    "            [\n",
    "                modal_button,\n",
    "\n",
    "                dbc.Modal(\n",
    "                    [\n",
    "                        dbc.ModalHeader(label),\n",
    "                        dbc.ModalBody(cards),            \n",
    "                        dbc.ModalFooter(\n",
    "                            dbc.Button(\n",
    "                                \"Close\", id=\"close-body-scroll\", className=\"ml-auto\"\n",
    "                            )\n",
    "                        ),\n",
    "                    ],\n",
    "                    id=\"modal-body-scroll\",\n",
    "                    scrollable=True,\n",
    "                    size=\"lg\"\n",
    "                ),\n",
    "            ]\n",
    "            )\n",
    "            if len(res) > 0:\n",
    "                res[0].append(modal)\n",
    "            else:\n",
    "                res.append(modal)\n",
    "    else:\n",
    "        \n",
    "        res = [html.H5(\"Select an item for details\", className=\"card-title\")]\n",
    "    \n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "@app_tab.callback(Output('cytoscape', 'layout'),\n",
    "              [Input('dropdown-layout', 'value')])\n",
    "def update_cytoscape_layout(layout):\n",
    "    return {\n",
    "        'name': layout,\n",
    "        'showlegend':True\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "@app_tab.callback(Output('cytoscape', 'stylesheet'),\n",
    "                  [Input('cytoscape', 'tapNode'),\n",
    "                   Input('cytoscape', 'selectedNodeData'),\n",
    "                   Input('input-follower-color', 'value'),\n",
    "                   Input('dropdown-node-shape', 'value'),\n",
    "                   Input('showgraph', 'value')],\n",
    "                   [State('cytoscape', 'stylesheet')])\n",
    "def generate_stylesheet(node, selectedNodes,follower_color, node_shape, graphtype, original_stylesheet):\n",
    "    if not graphtype or not node:\n",
    "        return original_stylesheet\n",
    "    \n",
    "    \n",
    "    focus_nodes = []\n",
    "    \n",
    "    if selectedNodes:\n",
    "        \n",
    "        for selectedNode in selectedNodes:\n",
    "            focus_nodes.append(selectedNode)\n",
    "            \n",
    "    if node is not None:\n",
    "        focus_nodes.append(node)\n",
    "\n",
    "    stylesheet  = original_stylesheet\n",
    "    for focus_node in focus_nodes:      \n",
    "        node_style = [\n",
    "                    {\n",
    "            \"selector\": 'node',\n",
    "            'style': {\n",
    "\n",
    "                'shape': node_shape,\n",
    "                 \"font-size\": 100\n",
    "\n",
    "            }\n",
    "                    }, {\n",
    "              \"selector\": \"node:selected\",\n",
    "              \"style\": {\n",
    "                \"border-width\": \"50px\",\n",
    "                \"border-color\": \"#AAD8FF\",\n",
    "                \"border-opacity\": \"0.5\"\n",
    "              }\n",
    "            }, \n",
    "            {\n",
    "        \"selector\": 'edge',\n",
    "        \"style\": {\n",
    "            'curve-style': 'bezier',\n",
    "            'line-color': '#D5DAE6'\n",
    "        }\n",
    "    },{\n",
    "            \"selector\": 'node[id = \"{}\"]'.format(focus_node['data']['id'] if \"data\" in focus_node else focus_node['id']),\n",
    "            \"style\": {\n",
    "                \"border-width\": \"50px\",\n",
    "                \"border-color\": \"#AAD8FF\",\n",
    "                \"border-opacity\": \"0.5\",\n",
    "                \"text-opacity\": 1,\n",
    "                \"font-size\": 100,\n",
    "                'z-index': 9999\n",
    "            }\n",
    "        }]\n",
    "        for style in node_style:\n",
    "            stylesheet.append(style)\n",
    "        \n",
    "        \n",
    "        if \"edgesData\" in focus_node:\n",
    "            for edge in focus_node['edgesData']:\n",
    "                if edge['source'] == focus_node['data']['id'] if \"data\" in focus_node else focus_node['id']:\n",
    "                    stylesheet.append({\n",
    "                        \"selector\": 'node[id = \"{}\"]'.format(edge['target']),\n",
    "                        \"style\": {\n",
    "                            #'background-color': following_color,\n",
    "                            'opacity': 0.9\n",
    "                        }\n",
    "                    })\n",
    "                    stylesheet.append({\n",
    "                        \"selector\": 'edge[id= \"{}\"]'.format(edge['id']),\n",
    "                        \"style\": {\n",
    "                            \"mid-target-arrow-color\": follower_color['hex'],\n",
    "                            #\"mid-target-arrow-shape\": \"vee\",\n",
    "                            \"line-color\": follower_color['hex'],\n",
    "                            'opacity': 0.9,\n",
    "                            'z-index': 5000\n",
    "                        }\n",
    "                    })\n",
    "                #print(follower_color)\n",
    "                if edge['target'] == focus_node['data']['id'] if \"data\" in focus_node else focus_node['id']:\n",
    "                    stylesheet.append({\n",
    "                        \"selector\": 'node[id = \"{}\"]'.format(edge['source']),\n",
    "                        \"style\": {\n",
    "                           # 'background-color': follower_color,\n",
    "                            'opacity': 0.9,\n",
    "                            'z-index': 9999\n",
    "                        }\n",
    "                    })\n",
    "                    stylesheet.append({\n",
    "                        \"selector\": 'edge[id= \"{}\"]'.format(edge['id']),\n",
    "                        \"style\": {\n",
    "                            \"mid-target-arrow-color\": follower_color['hex'],\n",
    "                            \"line-color\": follower_color['hex'],\n",
    "                            'opacity': 1,\n",
    "                            'z-index': 5000\n",
    "                        }\n",
    "                    })\n",
    "   \n",
    "    return stylesheet\n",
    "\n",
    "\n",
    "app_tab.config['suppress_callback_exceptions']=True\n",
    "app_tab.width = \"100%\"\n",
    "app_tab.height = \"800px\"\n",
    "app_tab.run_server(mode=\"jupyterlab\", port=\"8072\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version the knowledge graph\n",
    "The user can save a knowledge graph with a version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Temporally save the knowledge graph locally\n",
    "kg_ttl = knowledge_graph.serialize(format=\"turtle\",auto_compact=True)\n",
    "kg_ttl_filename = \"./kg_%s.ttl\" % (timestr)\n",
    "with open(kg_ttl_filename, 'wb') as outfile:\n",
    "        outfile.write(kg_ttl)\n",
    "\n",
    "        \n",
    "# Temporally save the extracted entities csv file locally\n",
    "table_extractions_filename = \"./table_extractions_%s.csv\" % (timestr)\n",
    "table_extractions.to_csv(table_extractions_filename)\n",
    "\n",
    "\n",
    "# Temporally save the curated list of extracted entities csv file locally\n",
    "curated_table_extractions_filename = \"./curated_table_extractions_%s.csv\" % (timestr)\n",
    "curated_table_extractions.to_csv(curated_table_extractions_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwt\n",
    "from kgforge.core import Resource\n",
    "from kgforge.specializations.resources import Dataset\n",
    "\n",
    "agent = jwt.decode(TOKEN,  verify=False)\n",
    "\n",
    "agent = forge.reshape(forge.from_json(agent), keep=[\"name\",\"email\",\"sub\",\"preferred_username\"])\n",
    "agent.id = agent.sub\n",
    "agent.type = \"Person\"\n",
    "\n",
    "dataset = Dataset(forge,name=\"A dataset\", about=topic_resource.name)\n",
    "dataset.add_distribution(kg_ttl_filename, content_type=\"application/x-turtle\")\n",
    "dataset.add_distribution(table_extractions_filename, content_type=\"application/csv\")\n",
    "dataset.add_distribution(curated_table_extractions_filename, content_type=\"application/csv\")\n",
    "dataset.add_contribution(agent)\n",
    "dataset.contribution.hadRole= \"Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = agent.preferred_username+\"_\"+timestr\n",
    "\n",
    "def register_dataset(b):\n",
    "    output4.clear_output()\n",
    "    output5.clear_output()\n",
    "    dataset.name = t1.value\n",
    "    dataset.description = t2.value\n",
    "    forge.register(dataset)\n",
    "    if dataset._last_action.succeeded == True:\n",
    "        with output4:\n",
    "            print(\"Dataset registered!\")\n",
    "    else:\n",
    "        with output4:\n",
    "            print(dataset._last_action.message)\n",
    "\n",
    "def version_dataset(b):\n",
    "    output5.clear_output()\n",
    "    version = t3.value\n",
    "    forge.tag(dataset,version)\n",
    "    if dataset._last_action.succeeded == True:\n",
    "        with output5:\n",
    "            print(f\"Tagged with: {str(version)}\")\n",
    "    \n",
    "output4 = ipywidgets.Output()\n",
    "output5 = ipywidgets.Output()\n",
    "\n",
    "b1 = ipywidgets.Button(\n",
    "    description= '💾  Register Dataset',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "\n",
    "b2 = ipywidgets.Button(\n",
    "    description= '🔖 Tag Dataset',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "\n",
    "t1 = ipywidgets.Text(\n",
    "    placeholder='Add a name for your dataset',\n",
    "    description='Name:',\n",
    "    disabled=False)\n",
    "\n",
    "t2 = ipywidgets.Textarea(\n",
    "    placeholder='Add a description of your dataset',\n",
    "    description='Description:',\n",
    "    disabled=False)\n",
    "\n",
    "t3 = ipywidgets.Text(\n",
    "    description='Tag:',\n",
    "    value=version,\n",
    "    disabled=False)\n",
    "\n",
    "b1.on_click(register_dataset)\n",
    "b2.on_click(version_dataset)\n",
    "\n",
    "save_widget = ipywidgets.VBox(children=[t1, t2, b1, output4, t3, b2, output5])\n",
    "\n",
    "display(save_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}