{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of the notebook\n",
    "End to end pipeline for searching articles of interest, extracting entities of interest, building, accessing and deploying a knowled graph and a co-mention graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy\n",
    "import ipywidgets\n",
    "\n",
    "import bbsearch as bbs\n",
    "from bbsearch.remote_searcher import RemoteSearcher\n",
    "from bbsearch.widgets import ArticleSaver, SearchWidget, MiningWidget, SchemaRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set a Project\n",
    "\n",
    "The user chooses / creates a project to host a KG.\n",
    "\n",
    "* Use the [Nexus web application](https://bbp.epfl.ch/nexus/web) to get a token.\n",
    "* Once a token is obtained then proceed to paste it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "TOKEN = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kgforge.core import KnowledgeGraphForge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a 'forge' to manage (create, access and deploy) the knowledge graph within a given Blue Brain Nexus Project.\n",
    "FORGE_CONFIG_FILE = os.getenv(\"FORGE_CONFIG_FILE\") \n",
    "assert (FORGE_CONFIG_FILE is not None) \n",
    "forge = KnowledgeGraphForge(FORGE_CONFIG_FILE,token=TOKEN, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set topic\n",
    "The user defines a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwt\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5ec981b5a940e789b9d49167593ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HBox(children=(Button(description='🔬 List all your topics', layout=Layout(height=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_resource=None\n",
    "kg_resource=None\n",
    "agent_username = jwt.decode(TOKEN,  verify=False)['preferred_username']\n",
    "\n",
    "def save_topic(b):\n",
    "    output.clear_output()\n",
    "    output2.clear_output()\n",
    "    output3.clear_output()\n",
    "    topic_to_save = {\n",
    "        'id': str(widget.children[1].children[0].value).replace(' ', '_'),\n",
    "        'type': 'Topic',\n",
    "        'name': widget.children[1].children[0].value,\n",
    "        'field': widget.children[1].children[1].value,\n",
    "        'description': widget.children[1].children[2].value,\n",
    "        'keywords': widget.children[1].children[3].value,\n",
    "        'question':  [widget.children[1].children[i].value for i in range(5,9)]\n",
    "    }\n",
    "    global topic_resource\n",
    "    topic_resource = forge.from_json(topic_to_save)\n",
    "    forge.register(topic_resource)\n",
    "    with output2:\n",
    "        if w1.value == \"\":\n",
    "            print(\"Please provide a topic name\")\n",
    "        else:\n",
    "            print(\"Topic saved!\")\n",
    "            w1.value = \"\"\n",
    "            w2.value = \"\"\n",
    "            w3.value = \"\"\n",
    "            w4.value = \"\"\n",
    "            w5.value = \"\"\n",
    "            w6.value = \"\"\n",
    "            w7.value = \"\"\n",
    "            w8.value = \"\"\n",
    "\n",
    "def get_topics(b):\n",
    "    output.clear_output()\n",
    "    output2.clear_output()\n",
    "    output3.clear_output()\n",
    "    query = f\"\"\"\n",
    "    SELECT ?id ?name ?description ?keywords ?field ?question ?createdAt\n",
    "    WHERE {{\n",
    "        ?id a Topic ;\n",
    "            name ?name ;\n",
    "            description ?description ;\n",
    "            keywords ?keywords ;\n",
    "            field ?field ;\n",
    "            question ?question ;\n",
    "            <https://bluebrain.github.io/nexus/vocabulary/deprecated> false ;\n",
    "            <https://bluebrain.github.io/nexus/vocabulary/createdAt> ?createdAt ;\n",
    "            <https://bluebrain.github.io/nexus/vocabulary/createdBy> <{forge._store.endpoint}/realms/bbp/users/{agent_username}> .\n",
    "    }}\n",
    "    \"\"\"\n",
    "    resources = forge.sparql(query, limit=100)\n",
    "    if len(resources) >= 1:\n",
    "        global topics_df\n",
    "        topics_df = forge.as_dataframe(resources)\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            topics_list = list(set(topics_df.name))\n",
    "            topics_list.sort()\n",
    "            w0.options = [\"\"] + topics_list\n",
    "            w0.value = \"\"\n",
    "            w0.placeholder = \"Select topic\"\n",
    "            w0.observe(topics_change, names='value')\n",
    "            display(w0)\n",
    "            display(s12)\n",
    "    else:\n",
    "        with output:\n",
    "            print(\"No topics found!\")\n",
    "\n",
    "def topics_change(change):\n",
    "    output3.clear_output()\n",
    "    with output:\n",
    "        if len(output.outputs) >= 1:\n",
    "            output.outputs = (output.outputs[0],)\n",
    "        s5.value = \"\"\n",
    "        s6.value = \"\"\n",
    "        s7.value = \"\"\n",
    "        s8.value = \"\"\n",
    "        s9.value = \"\"\n",
    "        s10.value = \"\"\n",
    "        s11.value = \"\"\n",
    "        global topic_resource\n",
    "        if change['new'] != \"\":\n",
    "            topic_resource = forge.retrieve(list(set(topics_df[topics_df.name == change['new']].id))[0])\n",
    "            s5.value = topic_resource.field\n",
    "            s6.value = topic_resource.description\n",
    "            s7.value = topic_resource.keywords\n",
    "            question = topic_resource.question\n",
    "            if isinstance(question, str):\n",
    "                question = [question]\n",
    "            if isinstance(question, list):\n",
    "                for i in range(len(question)):\n",
    "                    sq.children[i].value = question[i]            \n",
    "        display(s12)\n",
    "\n",
    "def update_topic(b):\n",
    "    output2.clear_output()\n",
    "    if w0.value != \"\":\n",
    "        topic_resource.id = forge.as_jsonld(topic_resource, form=\"expanded\")['@id']\n",
    "        topic_resource.field = s5.value\n",
    "        topic_resource.description = s6.value\n",
    "        topic_resource.keywords = s7.value\n",
    "        topic_resource.question = [sq.children[i].value for i in range(0,4)]\n",
    "        forge.update(topic_resource)\n",
    "        with output:\n",
    "            print(\"topic updated!\")\n",
    "        \n",
    "def get_datasets(b):\n",
    "    output3.clear_output()\n",
    "    if w0.value != \"\":\n",
    "        topic_resource_id = forge.as_jsonld(topic_resource, form=\"expanded\")['@id']\n",
    "        query = f\"\"\"\n",
    "            SELECT ?id ?name ?description ?keywords ?field ?question ?createdAt\n",
    "            WHERE {{\n",
    "                ?id a Dataset ;\n",
    "                    name ?name ;\n",
    "                    about <{topic_resource_id}> ;\n",
    "                    <https://bluebrain.github.io/nexus/vocabulary/deprecated> false ;\n",
    "                    <https://bluebrain.github.io/nexus/vocabulary/createdAt> ?createdAt ;\n",
    "                    <https://bluebrain.github.io/nexus/vocabulary/createdBy> <{forge._store.endpoint}/realms/bbp/users/{agent_username}> .\n",
    "            }}\n",
    "            \"\"\"\n",
    "        global kg_resources\n",
    "        kg_resources = forge.sparql(query, limit=100, debug=True)\n",
    "        if len(kg_resources) >= 1:\n",
    "            with output3:\n",
    "                display(s2)\n",
    "                s2.options = [r.name for r in kg_resources]\n",
    "                display(s3)\n",
    "        else:\n",
    "            with output3:\n",
    "                print(\"No datasets found!\")\n",
    "        \n",
    "def download_dataset(b):\n",
    "    resource_id = [r.id for r in kg_resources if r.name == s2.value][0]\n",
    "    global kg_resource\n",
    "    global table_extractions\n",
    "    kg_resource = forge.retrieve(resource_id)\n",
    "    forge.download(kg_resource, \"distribution.contentUrl\", \"/tmp/\", overwrite=True)\n",
    "    for r in kg_resource.distribution:\n",
    "        if \"curated\" in r.name:\n",
    "            table_extractions = pd.read_csv(f\"/tmp/{r.name}\")\n",
    "            if table_extractions is not None:\n",
    "                message = f\"Dataset '{r.name}' with {len(table_extractions)} entities ready to be reused. Its content has been assigned to the variable 'table_extractions'. Please continue with the interactive UI section to visualise this dataset.\"\n",
    "            else:\n",
    "                table_extractions = pd.DataFrame()\n",
    "                message = \"No dataset has been downloaded\"\n",
    "            with output3:\n",
    "                print(message)\n",
    "\n",
    "s0 = ipywidgets.Button(\n",
    "    description= '🔬 List all your topics',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s1 = ipywidgets.Button(\n",
    "    description= \"📃 Show datasets for selected topic\",\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s2 = ipywidgets.RadioButtons(\n",
    "    description='Select:',\n",
    "    disabled=False)\n",
    "s3 = ipywidgets.Button(\n",
    "    description= '📈 Reuse selected dataset',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s4 = ipywidgets.Button(\n",
    "    description= '✏️ Update topic',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s5 = ipywidgets.Text(\n",
    "    description='Field:',\n",
    "    disabled=False)\n",
    "s6 = ipywidgets.Textarea(\n",
    "    description='Description:',\n",
    "    disabled=False)\n",
    "s7 = ipywidgets.Textarea(\n",
    "    description='Keywords:',\n",
    "    disabled=False)\n",
    "s8 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "s9 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "s10 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "s11 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "\n",
    "sq = ipywidgets.VBox(children=[s8, s9, s10, s11])\n",
    "\n",
    "s12 = ipywidgets.VBox(children=[s5, s6, s7, ipywidgets.Label('Questions:'), sq, s4])\n",
    "\n",
    "w0 = ipywidgets.Dropdown(\n",
    "        description='Select topic:',\n",
    "        disabled=False)\n",
    "w1 = ipywidgets.Text(\n",
    "    placeholder='e.g. COVID-19',\n",
    "    description='Topic name:',\n",
    "    disabled=False)\n",
    "w2 = ipywidgets.Text(\n",
    "    placeholder='e.g. Neuroscience',\n",
    "    description='Field:',\n",
    "    disabled=False)\n",
    "w3 = ipywidgets.Textarea(\n",
    "    placeholder='Add a description of your topic',\n",
    "    description='Description:',\n",
    "    disabled=False)\n",
    "w4 = ipywidgets.Textarea(\n",
    "    placeholder='e.g. Coronavirus; COVID-19; SARS; risk factor; glycosylation; sugar; carbohydrates',\n",
    "    description='Keywords:',\n",
    "    disabled=False)\n",
    "w5 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w6 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w7 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w8 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w9 = ipywidgets.Button(\n",
    "    description='Create',\n",
    "    button_style='',\n",
    "    tooltip='Create new topic',\n",
    "    disabled=False)\n",
    "\n",
    "output = ipywidgets.Output()\n",
    "output2 = ipywidgets.Output()\n",
    "output3 = ipywidgets.Output()\n",
    "\n",
    "buttons = ipywidgets.HBox(children=[s0, s1])\n",
    "outputs = ipywidgets.HBox(children=[output, output3])\n",
    "tab1 = ipywidgets.VBox(children=[buttons, outputs])\n",
    "tab2 = ipywidgets.VBox(children=[w1, w2, w3, w4, ipywidgets.Label('Please express your research topic in a few questions:'), w5, w6, w7, w8, w9, output2])\n",
    "widget = ipywidgets.Tab(children=[tab1, tab2])\n",
    "widget.set_title(0, 'Select topic')\n",
    "widget.set_title(1, 'Create topic')\n",
    "\n",
    "w9.on_click(save_topic)\n",
    "s0.on_click(get_topics)\n",
    "s1.on_click(get_datasets)\n",
    "s3.on_click(download_dataset)\n",
    "s4.on_click(update_topic)\n",
    "\n",
    "display(widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import\n",
    "The user loads data from a data source (CORD-19).\n",
    "The loaded data forms the corpus.\n",
    "The user searches the CORPUS in Blue Brain Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_ENGINE_URL = os.getenv(\"SEARCH_ENGINE_URL\", \"http://dgx1.bbp.epfl.ch:8850\")\n",
    "assert SEARCH_ENGINE_URL is not None\n",
    "\n",
    "response = requests.post(\"{}/help\".format(SEARCH_ENGINE_URL))\n",
    "assert response.ok and response.json()['name'] == 'SearchServer', \"The server is not accessible\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBS_DATA_PATH = os.getenv(\"BBS_DATA_PATH\", \"/raid/sync/proj115/bbs_data/\")\n",
    "BBS_DATA_PATH = pathlib.Path(BBS_DATA_PATH)\n",
    "trained_models_path = BBS_DATA_PATH / 'trained_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYSQL_DB_URI = os.getenv(\"MYSQL_DB_URI\", \"dgx1.bbp.epfl.ch:8853\")\n",
    "searcher = RemoteSearcher(SEARCH_ENGINE_URL)\n",
    "engine = sqlalchemy.create_engine(f'mysql+pymysql://guest:guest@{MYSQL_DB_URI}/cord19_v35')\n",
    "article_saver = ArticleSaver(connection=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_widget = SearchWidget(\n",
    "    searcher=searcher,\n",
    "    connection=engine,\n",
    "    article_saver=article_saver,\n",
    "    results_per_page=3)\n",
    "search_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status of the Article Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_saver.summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set schemas\n",
    "The user defines the KG schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_request = SchemaRequest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['entity_type', 'property', 'property_type', 'property_value_type', 'ontology_source']\n",
    "\n",
    "etypes_sources = [('CELL_TYPE', None), \n",
    "                  ('CHEMICAL', 'NCIT'), \n",
    "                  ('CONDITION', None),\n",
    "                  ('DISEASE', 'NCIT'),\n",
    "                  ('ORGAN', 'NCIT'),\n",
    "                  ('ORGANISM', 'NCIT'),\n",
    "                  ('PATHWAY', 'Reactome'),\n",
    "                  ('PROTEIN', 'NCIT')\n",
    "                 ]\n",
    "schema_request_data = [{'entity_type': etype, 'ontology_source': source} \n",
    "                       for etype, source in etypes_sources]\n",
    "\n",
    "schema_request.schema = pd.DataFrame(schema_request_data, columns=columns)\n",
    "display(schema_request.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a knowledge graph according to schemas\n",
    "The user extracts data from the text of a set of papers using selected Named Entity Recognizers and Relation Extractors from Blue Brain Search.\n",
    "The user can preview the extracted data.\n",
    "The user curates extracted data.\n",
    "The user links the extracted entities and relations to ontologies.\n",
    "The user saves data into Knowledge Graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **input**: raw text\n",
    "- **output**: csv table of extracted entities/relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TEXT = \"\"\"Autophagy maintains tumour growth through circulating\n",
    "arginine. Autophagy captures intracellular components and delivers them to\n",
    "lysosomes, where they are degraded and recycled to sustain metabolism and to\n",
    "enable survival during starvation. Acute, whole-body deletion of the essential \n",
    "autophagy gene Atg7 in adult mice causes a systemic metabolic defect that \n",
    "manifests as starvation intolerance and gradual loss of white adipose tissue, \n",
    "liver glycogen and muscle mass.  Cancer cells also benefit from autophagy. \n",
    "Deletion of essential autophagy genes impairs the metabolism, proliferation, \n",
    "survival and malignancy of spontaneous tumours in models of autochthonous \n",
    "cancer. Acute, systemic deletion of Atg7 or acute, systemic expression of a \n",
    "dominant-negative ATG4b in mice induces greater regression of KRAS-driven \n",
    "cancers than does tumour-specific autophagy deletion, which suggests that host \n",
    "autophagy promotes tumour growth.\n",
    "\"\"\".replace('\\n', ' ').replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_MINING_URL = os.getenv(\"TEXT_MINING_URL\", \"http://dgx1.bbp.epfl.ch:8852\")\n",
    "response = requests.post(TEXT_MINING_URL + \"/help\")\n",
    "assert response.ok and response.json()['name'] == 'MiningServer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mining_widget = MiningWidget(\n",
    "    mining_server_url=TEXT_MINING_URL,\n",
    "    schema_request=schema_request,\n",
    "    article_saver=article_saver,\n",
    "    default_text=DEFAULT_TEXT)\n",
    "mining_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **input**: csv table of extracted entities/relations\n",
    "- **output**: knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrame of extractions\n",
    "table_extractions = mining_widget.get_extracted_table()\n",
    "\n",
    "# Drop duplicates in DataFrame\n",
    "columns_duplicates = table_extractions.columns.tolist()\n",
    "columns_duplicates.remove('entity_type')\n",
    "table_extractions = table_extractions.drop_duplicates(subset=columns_duplicates, keep='first', ignore_index=True)\n",
    "table_extractions = table_extractions.dropna(subset=[\"entity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The table has {table_extractions.shape[0]} rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_extractions = pd.read_csv(\"./glucose_in_COVID-19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_server_proxy\n",
    "import jupyter_dash\n",
    "import dash\n",
    "import dash_daq as daq\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_table\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash.comms import _send_jupyter_config_comm_request\n",
    "_send_jupyter_config_comm_request()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JupyterDash.infer_jupyter_proxy_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Setting default term filters: the user can remove them later on in the UI if need be ...\")\n",
    "\n",
    "filtered_table_extractions = table_extractions.copy()\n",
    "filtered_table_extractions[\"paper_id\"] = filtered_table_extractions[\"paper_id\"].transform(lambda x:  str(x).split(\":\")[0])\n",
    "\n",
    "\n",
    "default_term_filters = 'Glucose; Covid-19; SARS-CoV-2; Diabetes; IL-1; ACE2; glycosylation; hyperglycemia; shock; fatigue; CVD; vasoconstriction; lactate; insulin; SP-D; HbA1c; LDH; glycolysis; GLUT; macrophage; lymphocytes; ventilation;SARS; ARDS; Cytokine Storm; pneumonia; multi-organs failure; thrombosis; inflammation; IL-6; CRP; D-Dimer; Ferritin; Lung Disease; Hypertension; Aging; COPD; angiotensin 2 (or angiotensin II or AngII); Obesity; ICU (intensive care unit); ventilation; ketogenic diet'.split(\"; \")\n",
    "\n",
    "default_found_term_filters = set() \n",
    "for term_filter in default_term_filters:\n",
    "    result_df = filtered_table_extractions.loc[filtered_table_extractions[\"entity\"].str.lower().eq(str(term_filter).lower())]\n",
    "    result_df = result_df[\"entity\"].unique()    \n",
    "    if result_df is not None and len(result_df) > 0:\n",
    "        default_found_term_filters.add(tuple(result_df))\n",
    "term_filter_options= [term_filter[0] for term_filter in  default_found_term_filters]\n",
    "\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Computing entity frequencies ...\")\n",
    "\n",
    "\n",
    "\n",
    "def _frequency(group_by, retrieve_key, df, distinct_papers=True, debug=False):\n",
    "    \n",
    "    if debug:\n",
    "        display(df.head(100))\n",
    "    if distinct_papers:\n",
    "        colunm_stats = df[[group_by, retrieve_key]].groupby(group_by)[retrieve_key].unique()\n",
    "    else:\n",
    "        colunm_stats = df[[group_by, retrieve_key]].groupby(group_by)[retrieve_key].count()\n",
    "    if debug:\n",
    "        display(colunm_stats)\n",
    "    \n",
    "    return colunm_stats\n",
    "        \n",
    "entity_stats = _frequency(group_by=\"entity\",retrieve_key=\"paper_id\",df=filtered_table_extractions,distinct_papers=True)\n",
    "\n",
    "entity_frequency = 1\n",
    "\n",
    "curated_table_extractions = filtered_table_extractions.copy()\n",
    "linked_mention_df_unique = pd.read_csv(\"/gpfs/bbp.cscs.ch/project/proj116/linked_mention_df_unique_with_type.csv\")\n",
    "linked_mention_df_unique = linked_mention_df_unique.set_index('mention')\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "app = JupyterDash('Extracted Entities Curation App')\n",
    "\n",
    "server = app.server\n",
    "\n",
    "from operator import ge, gt, lt, le, eq, ne\n",
    "\n",
    "\n",
    "operators = [['ge ', '>='],\n",
    "             ['le ', '<='],\n",
    "             ['lt ', '<'],\n",
    "             ['gt ', '>'],\n",
    "             ['ne ', '!='],\n",
    "             ['eq ', '='],\n",
    "             ['contains '],\n",
    "             ['datestartswith ']]\n",
    "\n",
    "dropdown_freq_filter_list = [{\"label\":\">\",\"value\":\"gt\"},\n",
    "                             {\"label\":\">=\",\"value\":\"ge\"},\n",
    "                             {\"label\":\"<\",\"value\":\"lt\"},\n",
    "                             {\"label\":\"<=\",\"value\":\"le\"},\n",
    "                             {\"label\":\"=\",\"value\":\"eq\"},\n",
    "                             {\"label\":\"!=\",\"value\":\"ne\"}]\n",
    "\n",
    "def split_filter_part(filter_part):\n",
    "    for operator_type in operators:\n",
    "        for operator in operator_type:\n",
    "            if operator in filter_part:\n",
    "                name_part, value_part = filter_part.split(operator, 1)\n",
    "                name = name_part[name_part.find('{') + 1: name_part.rfind('}')]\n",
    "\n",
    "                value_part = value_part.strip()\n",
    "                v0 = value_part[0]\n",
    "                if (v0 == value_part[-1] and v0 in (\"'\", '\"', '`')):\n",
    "                    value = value_part[1: -1].replace('\\\\' + v0, v0)\n",
    "                else:\n",
    "                    try:\n",
    "                        value = float(value_part)\n",
    "                    except ValueError:\n",
    "                        value = value_part\n",
    "\n",
    "                return name, operator_type[0].strip(), value\n",
    "\n",
    "    return [None] * 3\n",
    "\n",
    "# Define UI layout\n",
    "\n",
    "button_group = dbc.ButtonGroup(\n",
    "    [\n",
    "        dcc.Upload(\n",
    "                id='datatable-upload',\n",
    "                children=html.Div([\n",
    "                    dbc.Button(\"Load a CSV File\", color=\"primary\", className=\"mr-1\",id=\"load_file\"),\n",
    "                    dbc.Tooltip(\n",
    "                        \"Load extracted entities in CSV format\",\n",
    "                        target=\"load_file\",\n",
    "                        placement=\"bottom\",\n",
    "                    )\n",
    "                ]),\n",
    "            className=\"mr-1\"\n",
    "        )\n",
    "    ],\n",
    "     className=\"mr-1\"\n",
    ")\n",
    "\n",
    "buttons = dbc.FormGroup(\n",
    "            [\n",
    "                 button_group\n",
    "            ]\n",
    "        )\n",
    "\n",
    "dropdown = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.InputGroupAddon(\n",
    "            dbc.Button(\"Entity Frequency\", color=\"primary\", id=\"entity_frequency\"),\n",
    "            addon_type=\"prepend\",\n",
    "            className=\"mr-1\"\n",
    "        ),\n",
    "        dbc.Tooltip(\n",
    "            \"Select an operator and a frequency threshold\",\n",
    "            target=\"entity_frequency\",\n",
    "            placement=\"bottom\",\n",
    "        ),\n",
    "        dcc.Dropdown(\n",
    "            id='dropdown-freq-filter',\n",
    "            value=\"ge\",\n",
    "            clearable=False,\n",
    "            options = dropdown_freq_filter_list,\n",
    "            \n",
    "            className=\"mr-1\"\n",
    "        ),\n",
    "        daq.NumericInput(\n",
    "            id=\"entityfreqslider\",\n",
    "            min=entity_frequency,  \n",
    "            max=1000,\n",
    "            value=entity_frequency,\n",
    "           className=\"mr-1\"\n",
    "        )\n",
    "    ],\n",
    "    className=\"mr-1\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "term_filters = dbc.InputGroup(\n",
    "    [\n",
    "        dbc.InputGroupAddon(\n",
    "            \"Keep\",\n",
    "            addon_type=\"prepend\",\n",
    "        ),\n",
    "         dcc.Dropdown(\n",
    "            id=\"term_filters\",\n",
    "            multi=True,\n",
    "             value=term_filter_options,\n",
    "             style={\n",
    "                 \"width\":\"80%\"\n",
    "             },\n",
    "             placeholder=\"Search for entities to keep\",\n",
    "             \n",
    "        )\n",
    "        \n",
    "    ],\n",
    "    className=\"mb-1\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "reset = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Button(\"Reset\", color=\"primary\", className=\"mr-1\",id='table-reset'),\n",
    "        dbc.Tooltip(\n",
    "            \"Reset table and graph to original extracted entities and default filters\",\n",
    "            target=\"table-reset\",\n",
    "            placement=\"bottom\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "link_ontology = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Button(\"Link to NCIT ontology\", color=\"primary\", className=\"mr-1\",id='link_ontology', disabled=True),\n",
    "        dbc.Tooltip(\n",
    "            \"Click to apply ontology linking\",\n",
    "            target=\"link_ontology\",\n",
    "            placement=\"bottom\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "                        \n",
    "\n",
    "form_table = dbc.Form([buttons, dropdown,reset,link_ontology,term_filters],inline=True)\n",
    "\n",
    "columns= [{\"name\": i, \"id\": i, \"clearable\": True, \"selectable\": True, \"renamable\": False, \"hideable\": True, \"deletable\": False} for i in filtered_table_extractions.columns ]\n",
    "\n",
    "app.layout = html.Div(\n",
    "    [\n",
    "       dbc.Row(\n",
    "            dbc.Col(\n",
    "                form_table\n",
    "            )\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            dbc.Col(\n",
    "                dash_table.DataTable(\n",
    "                    id='datatable-upload-container',\n",
    "                    columns=columns,\n",
    "                    style_cell={\n",
    "                        'whiteSpace': 'normal'\n",
    "                    },\n",
    "\n",
    "                    style_data_conditional=[\n",
    "                        {\n",
    "                            'if': {'row_index': 'odd'},\n",
    "                            'backgroundColor': 'rgb(248, 248, 248)'\n",
    "                        }\n",
    "                    ],\n",
    "                    style_header={\n",
    "                        'backgroundColor': 'rgb(230, 230, 230)',\n",
    "                        'fontWeight': 'bold'\n",
    "                    },\n",
    "\n",
    "                    css=[\n",
    "                        {\n",
    "                            'selector': 'dash-fixed-content',\n",
    "                            'rule': 'height: 100%;'\n",
    "                        }\n",
    "                    ],\n",
    "                    sort_action=\"custom\", #native\n",
    "                    sort_mode=\"multi\",\n",
    "                    column_selectable=\"multi\",\n",
    "                    filter_action=\"custom\",\n",
    "                    filter_query='',\n",
    "                    selected_columns=[],\n",
    "                    page_action=\"custom\", #native\n",
    "                    export_format='csv',\n",
    "                    export_headers='display',\n",
    "                    merge_duplicate_headers=True,\n",
    "                    selected_rows=[],\n",
    "                    page_current=0,\n",
    "                    page_size=10,\n",
    "                    sort_by=[]\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            \n",
    "            dbc.Col(dcc.Graph(id='datatable-upload-Scatter'))\n",
    "           \n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "\n",
    "def parse_contents(contents, filename):\n",
    "    content_type, content_string = contents.split(',')\n",
    "    decoded = base64.b64decode(content_string)\n",
    "    if 'csv' in filename:\n",
    "        return pd.read_csv(\n",
    "            io.StringIO(decoded.decode('utf-8')))\n",
    "\n",
    "@app.callback(\n",
    "    Output('datatable-upload-container', 'style_data_conditional'),\n",
    "    [Input('datatable-upload-container', 'selected_columns')]\n",
    ")\n",
    "def update_styles(selected_columns):\n",
    "    return [{\n",
    "        'if': {'column_id': i},\n",
    "        'background_color': '#D2F3FF'\n",
    "    } for i in selected_columns]\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"term_filters\", \"options\"),\n",
    "    [Input(\"term_filters\", \"search_value\"),Input('link_ontology', 'n_clicks')],\n",
    "    [State(\"term_filters\", \"value\"),\n",
    "    State('datatable-upload-container', 'data')],\n",
    ")\n",
    "def update_filter(search_value, click_link_ontology, values,data):\n",
    "    \n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        button_id = 'No clicks yet'\n",
    "    else:\n",
    "        button_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "                        \n",
    "    if not search_value and values is None:\n",
    "        raise PreventUpdate\n",
    "    \n",
    "    res = []\n",
    "        \n",
    "    if values is not None:\n",
    "        if button_id == \"link_ontology\":\n",
    "            for value in values:\n",
    "                vals = linked_mention_df_unique.loc[linked_mention_df_unique['mention'].str.lower() == str(value).lower()]\n",
    "                \n",
    "                vals = vals.concept.str.lower().unique()\n",
    "                res.append( {\"label\":vals[0],\"value\":vals[0]})\n",
    "        else:\n",
    "            for value in values:      \n",
    "                res.append( {\"label\":value,\"value\":value})\n",
    "    \n",
    "    if search_value is not None:\n",
    "        result_df = non_deleted_table_extractions.loc[non_deleted_table_extractions[\"entity\"].str.contains(str(search_value))]\n",
    "        result_df = result_df[\"entity\"].unique()\n",
    "        if result_df is not None:\n",
    "            for result in result_df:\n",
    "                res.append( {\"label\":result,\"value\":result})\n",
    "    return res\n",
    "    \n",
    "\n",
    "\n",
    "@app.callback([Output('entityfreqslider', 'value'),\n",
    "               Output('dropdown-freq-filter', 'value')],\n",
    "              [ Input('table-reset', 'n_clicks')],\n",
    "             [State('entityfreqslider', 'value'),\n",
    "              State('dropdown-freq-filter', 'value')])\n",
    "def reset(reset, entityfreq,freqoperator):\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        button_id = 'No clicks yet'\n",
    "    else:\n",
    "        button_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "                \n",
    "    if button_id == \"table-reset\" or button_id == \"No clicks yet\":\n",
    "        global curated_table_extractions\n",
    "        curated_table_extractions = filtered_table_extractions\n",
    "        global non_deleted_table_extractions\n",
    "        non_deleted_table_extractions = filtered_table_extractions\n",
    "        return [entity_frequency,\"ge\"]\n",
    "    \n",
    "import traceback    \n",
    "\n",
    "non_deleted_table_extractions = filtered_table_extractions        \n",
    "\n",
    "\n",
    "def get_freq(row, operator, filter_value, term_filters):\n",
    "    return eval(operator)(len(entity_stats[row['entity']]),int(filter_value)) or str(row['entity']).lower() in term_filters\n",
    "import math\n",
    "def link_ontology():\n",
    "    \n",
    "    filtered_table_extractions_linked = pd.merge(left=linked_mention_df_unique,\n",
    "                                                 right=non_deleted_table_extractions,\n",
    "                                                 how=\"left\",left_on=linked_mention_df_unique[\"mention\"].str.lower(),\n",
    "                                                 right_on=non_deleted_table_extractions[\"entity\"].str.lower())\n",
    "    filtered_table_extractions_linked.dropna(subset=['paper_id'], inplace=True)\n",
    "    filtered_table_extractions_linked[\"entity\"] = filtered_table_extractions_linked.apply(lambda row: row.concept if pd.notnull(row.concept) else row.entity, axis = 1)\n",
    "    \n",
    "        \n",
    "    return filtered_table_extractions_linked\n",
    "    \n",
    "@app.callback([\n",
    "               Output('datatable-upload-container', 'data'),\n",
    "               Output('datatable-upload-container', 'columns'),\n",
    "               Output('datatable-upload-container', 'editable'),\n",
    "               Output('datatable-upload-container', 'row_deletable'),\n",
    "               Output('datatable-upload-container', 'page_count')],\n",
    "              [Input('datatable-upload-container', 'page_size'),\n",
    "               Input('datatable-upload-container', 'page_current'),\n",
    "               Input('datatable-upload-container','data_timestamp'),\n",
    "               Input('datatable-upload', 'contents'),\n",
    "               Input('entityfreqslider', 'value'),\n",
    "               Input('dropdown-freq-filter', 'value'),\n",
    "              Input('datatable-upload-container', 'sort_by'),\n",
    "              Input('datatable-upload-container', 'filter_query'),\n",
    "              Input('link_ontology', 'n_clicks')],\n",
    "              [State(\"datatable-upload-container\", \"data\"),\n",
    "               State(\"datatable-upload-container\", \"columns\"),\n",
    "              State('datatable-upload', 'filename'),\n",
    "              State('datatable-upload-container', 'derived_viewport_data'),\n",
    "                State(\"term_filters\", \"value\")\n",
    "              ])\n",
    "\n",
    "def update_output(page_size, page_current,ts,upload,entityfreq,\n",
    "                  freqoperator,sort_by,filter_query,click_link_ontology,data,\n",
    "                  columns, filename,derived_viewport_data, \n",
    "                  term_filters):\n",
    "    try:\n",
    "        ctx = dash.callback_context\n",
    "        if not ctx.triggered:\n",
    "            button_id = 'No clicks yet'\n",
    "        else:\n",
    "            button_id = ctx.triggered[0]['prop_id'].split('.')[0]       \n",
    "            \n",
    "        if term_filters is not None:\n",
    "            term_filters = [str(term_filter_value).lower() for term_filter_value in term_filters ]\n",
    "        else:\n",
    "            term_filters = []\n",
    "        if upload is not None:\n",
    "            global curated_table_extractions\n",
    "            curated_table_extractions = parse_contents(upload, filename).copy()\n",
    "            \n",
    "        elif button_id == \"table-reset\":\n",
    "            curated_table_extractions = filtered_table_extractions\n",
    "        \n",
    "        elif button_id == \"link_ontology\":\n",
    "            curated_table_extractions = link_ontology()\n",
    "            \n",
    "            \n",
    "        elif derived_viewport_data:\n",
    "            \n",
    "            removed = [row for row in derived_viewport_data if row not in data and str(row[\"entity\"]).lower() not in term_filters]\n",
    "            global non_deleted_table_extractions\n",
    "            for row in removed:\n",
    "                curated_table_extractions= curated_table_extractions[curated_table_extractions.entity.str.lower() != str(row[\"entity\"]).lower()]\n",
    "                non_deleted_table_extractions=non_deleted_table_extractions[non_deleted_table_extractions.entity.str.lower() != str(row[\"entity\"]).lower()]\n",
    "\n",
    "        result = curated_table_extractions\n",
    "\n",
    "\n",
    "        if (button_id == \"entityfreqslider\" or button_id==\"dropdown-freq-filter\")  and 'paper_id' in curated_table_extractions:\n",
    "            row_filtered = []\n",
    "           \n",
    "            curated_table_extractions =non_deleted_table_extractions[non_deleted_table_extractions.apply(lambda row: get_freq(row,freqoperator,entityfreq,term_filters), axis=1)]\n",
    "            result = curated_table_extractions\n",
    "        \n",
    "        # Filter by properties\n",
    "\n",
    "        dff = result\n",
    "        if filter_query:\n",
    "            filtering_expressions = filter_query.split(' && ')\n",
    "            for filter_part in filtering_expressions:\n",
    "                col_name, operator, filter_value = split_filter_part(filter_part)\n",
    "\n",
    "                if operator in ('eq', 'ne', 'lt', 'le', 'gt', 'ge'):\n",
    "                    dff = dff.loc[getattr(dff[col_name], operator)(filter_value)]\n",
    "                elif operator == 'contains':\n",
    "                   dff = dff.loc[dff[col_name].str.contains(filter_value)]\n",
    "                elif operator == 'datestartswith':\n",
    "                    dff = dff.loc[dff[col_name].str.startswith(filter_value)]\n",
    "            \n",
    "        # Sorting by properties\n",
    "        if sort_by and len(sort_by):\n",
    "            result_sorted = dff.sort_values(\n",
    "                [col['column_id'] for col in sort_by],\n",
    "                ascending=[\n",
    "                    col['direction'] == 'asc'\n",
    "                    for col in sort_by\n",
    "                ],\n",
    "                inplace=False\n",
    "            )\n",
    "        else:\n",
    "            result_sorted = dff\n",
    "            \n",
    "        result_paginated= result_sorted.iloc[\n",
    "            page_current*page_size:(page_current+ 1)*page_size\n",
    "        ]\n",
    "                \n",
    "        page_count = len(result_sorted) // page_size\n",
    "        \n",
    "        return result_paginated.to_dict('records'), columns, True, True, page_count\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.callback([Output('datatable-upload-Scatter', 'figure')],\n",
    "              [Input('datatable-upload-container', 'data_timestamp'),\n",
    "               Input('datatable-upload-container', 'data')],)\n",
    "def display_graph(dts, rows):\n",
    "    df = curated_table_extractions\n",
    "    \n",
    "    if (df.empty or len(df.columns) < 1):\n",
    "        \n",
    "        scatter = {\n",
    "                'data': [{\n",
    "                    'x': [],\n",
    "                    'y': []\n",
    "                }]\n",
    "            }\n",
    "    else:\n",
    "        if \"paper_id\" in df:\n",
    "            df[\"paper_id\"] = df[\"paper_id\"].transform(lambda x:  str(x).split(\":\")[0])\n",
    "            df_grouped = df[[\"paper_id\",\"entity_type\",\"entity\"]].groupby([\"entity\",\"entity_type\"]).paper_id.nunique().reset_index()\n",
    "            df_grouped = df_grouped.rename(columns={\"paper_id\": \"Frequency\"})\n",
    "            scatter = px.scatter(df_grouped, x=df_grouped.entity, y=df_grouped.Frequency, color=\"entity_type\")\n",
    "    return [scatter]\n",
    "\n",
    "\n",
    "width = \"100%\"\n",
    "height = \"100%\"\n",
    "app.run_server(mode=\"jupyterlab\",width=width,port=8071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pygments import highlight\n",
    "from pygments.lexers import JsonLdLexer, TurtleLexer\n",
    "from pygments.formatters import TerminalFormatter, TerminalTrueColorFormatter\n",
    "import json\n",
    "import uuid\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def pretty_print(a_json):\n",
    "    print(highlight(json.dumps(a_json, indent=2), JsonLdLexer(), TerminalFormatter()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from kgforge.core import Resource\n",
    "from kgforge.specializations.mappings import DictionaryMapping\n",
    "import uuid\n",
    "\n",
    "\n",
    "ANNOTATION_MAPPING_FILE = os.getenv(\"ANNOTATION_MAPPING_FILE\") \n",
    "assert (ANNOTATION_MAPPING_FILE is not None) \n",
    "\n",
    "PROPERTY_MAPPING_FILE = os.getenv(\"PROPERTY_MAPPING_FILE\") \n",
    "assert (PROPERTY_MAPPING_FILE is not None) \n",
    "\n",
    "annotation_maping = DictionaryMapping.load(ANNOTATION_MAPPING_FILE)\n",
    "property_maping = DictionaryMapping.load(PROPERTY_MAPPING_FILE)\n",
    "\n",
    "ressources_json = curated_table_extractions.to_dict('records')\n",
    "ressources_json = [dict(resource_json, **{\"id\":str(uuid.uuid4())}) for resource_json in tqdm(ressources_json)]\n",
    "\n",
    "print(\"Preparing \"+str(len(curated_table_extractions))+\" selected entities for ontology linking ...\")\n",
    "annotations = forge.map(ressources_json,[annotation_maping],na='')\n",
    "ressources_prop_mapped = forge.map(ressources_json,[property_maping],na='')\n",
    "print(\"Done \")\n",
    "\n",
    "import math\n",
    "\n",
    "for i,r in tqdm(enumerate(ressources_json)):\n",
    "    if 'property' in r and not math.isnan(r['property']):\n",
    "        annotations[i].target.selector.value.__setattr__(r['property'], ressources_prop_mapped[i])\n",
    "        annotations[i].body.__setattr__(r['property'], ressources_prop_mapped[i])\n",
    "        \n",
    "print(f'{len(annotations)} annotations created.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from joblib import parallel_backend\n",
    "class Candidate:\n",
    "    \n",
    "    def __init__(self, distance, alias, uid, concept, definition,mention):\n",
    "        self.distance = distance\n",
    "        self.alias = alias\n",
    "        self.uid = uid\n",
    "        self.concept = concept\n",
    "        self.definition = definition\n",
    "        self.mention = mention\n",
    "    \n",
    "    def __repr__(self):\n",
    "        attrs = (f\"{k}={v!r}\" for k, v in self.__dict__.items())\n",
    "        return f\"Candidate({', '.join(attrs)})\"\n",
    "\n",
    "class EntityLinker:\n",
    "    \n",
    "    def __init__(self, bulk):\n",
    "        self.bulk = bulk\n",
    "        self.ontology = None\n",
    "        self.aliases = None\n",
    "        self.model = None\n",
    "        self.index = None\n",
    "    \n",
    "    def link(self, mentions, threshold=0.8):\n",
    "        selections = self.candidates(mentions, 3)\n",
    "        return [self.disambiguate(cs, m, None, threshold) for m, cs in selections]\n",
    "    \n",
    "    def disambiguate(self, candidates, mention, context, threshold):\n",
    "        # TODO Disambiguation requires the component to be part of the NLP pipeline.        \n",
    "        zeros = [x for x in candidates if x.distance == 0]\n",
    "        if zeros:\n",
    "            chosen = sorted(zeros, key=lambda x: len(x.concept))[0]\n",
    "            return chosen\n",
    "        else:\n",
    "            chosen = sorted(candidates, key=lambda x: x.distance)[0]\n",
    "            return chosen if chosen.distance <= threshold else None\n",
    "    \n",
    "    def candidates(self, mentions, limit):\n",
    "        def _(d, i,m):\n",
    "            alias, uid = self.aliases[int(i)]\n",
    "            return Candidate(d, alias, uid, *self.ontology[uid], mention=m)\n",
    "        mentions_index = [(i,str(mention)) for i,mention in enumerate(mentions)]\n",
    "        mentions_labels = {str(mention) for mention in mentions}\n",
    "        embeddings = self.model.transform(mentions_labels)\n",
    "        \n",
    "        if self.bulk:\n",
    "            distances, indexes = self.index.search(embeddings.toarray(), limit)\n",
    "        else:\n",
    "           \n",
    "            distances = None\n",
    "            indexes = None\n",
    "            with parallel_backend('threading', n_jobs=10):\n",
    "                distances, indexes = self.index.kneighbors(embeddings, limit)\n",
    "        results = np.stack((distances, indexes), axis=2)\n",
    "        i_res= {m: [_(d, i,m) for d, i in rs] for m, rs in zip(mentions_labels, results)}\n",
    "        return [(m, i_res[m]) for i, m in mentions_index]\n",
    "        \n",
    "        \n",
    "    def train(self, ontology, model_params, index_params):\n",
    "        self.ontology = {k: (v[0], v[2]) for k, v in ontology.items()}\n",
    "        self.model = TfidfVectorizer(**model_params)\n",
    "        aliases = [(x, k) for k, v in ontology.items() for x in [v[0], *v[1]]]\n",
    "        embeddings = self.model.fit_transform(x for x, _ in aliases)\n",
    "        flags = np.array(embeddings.sum(axis=1) != 0).reshape(-1)\n",
    "        filtered_embeddings = embeddings[flags]\n",
    "        self.aliases = [t for t, f in zip(aliases, flags) if f]\n",
    "        if self.bulk:\n",
    "            self.index = faiss.IndexFlatL2(filtered_embeddings.shape[1])\n",
    "            self.index.add(filtered_embeddings.toarray())\n",
    "        else:\n",
    "            self.index = NearestNeighbors(**index_params)\n",
    "            self.index.fit(filtered_embeddings)\n",
    "        self._stats()\n",
    "    \n",
    "    def save_pretrained(self, dirpath):\n",
    "        with open(f'{dirpath}/model', 'wb') as f:\n",
    "            pickle.dump(linker.ontology, f)\n",
    "            pickle.dump(linker.aliases, f)\n",
    "            pickle.dump(linker.model, f)\n",
    "            if not self.bulk:\n",
    "                pickle.dump(linker.index, f)\n",
    "        if self.bulk:\n",
    "            faiss.write_index(linker.index, f'{dirpath}/index')\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_pretrained(dirpath, bulk):\n",
    "        linker = EntityLinker(bulk)\n",
    "        with open(f'{dirpath}/model', 'rb') as f:\n",
    "            linker.ontology = pickle.load(f)\n",
    "            linker.aliases = pickle.load(f)\n",
    "            linker.model = pickle.load(f)\n",
    "            if not bulk:\n",
    "                linker.index = pickle.load(f)\n",
    "        if bulk:\n",
    "            linker.index = index\n",
    "        linker._stats()\n",
    "        return linker\n",
    "    \n",
    "    def _stats(self):\n",
    "        ccount = len(self.ontology)\n",
    "        tcount = len(self.aliases)\n",
    "        print(f'INFO   EntityLinker   Links to {ccount} concepts ({tcount} aliases).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ONTOLOGY_LINKING_MODEL_PATH = os.getenv(\"ONTOLOGY_LINKING_MODEL_PATH\")\n",
    "assert (ONTOLOGY_LINKING_MODEL_PATH is not None)\n",
    "linker = EntityLinker.from_pretrained(ONTOLOGY_LINKING_MODEL_PATH, bulk=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "from typing import Iterable, Dict, Iterator\n",
    "from copy import deepcopy\n",
    "\n",
    "synonyms_to_merge ={\n",
    "    \"lactate dehydrogenase\": [\"ldh\", \"lactate dehydrogenase\"],\n",
    "    \"covid-19\": [\"covid-19\", \"covid\"],\n",
    "    \"sars-cov-2\": [\n",
    "        \"sars-cov-2\",\n",
    "        \"sars-cov-2 virus\",\n",
    "        \"sars-cov.\",\n",
    "        \"sars-cov-2 infection\"\n",
    "    ],\n",
    "    \"sp-d\": [\n",
    "        \"human surfactant protein d\",\n",
    "        \"lung surfactant protein d\",\n",
    "        \"pulmonary surfactant protein d\",\n",
    "        \"sp-d\",\n",
    "        \"sp-d surfactant protein d\",\n",
    "        \"spd\",\n",
    "        \"surfactant protein d\",\n",
    "        \"surfactant protein sp-d\",\n",
    "        \"surfactant protein-d\",\n",
    "        \"surfactant protein d measurement\"\n",
    "    ],\n",
    "    \"angiotensin-converting enzyme 2\": [\"angiotensin-converting enzyme 2\", \"ace-2\", \"ace2\"],\n",
    "    \"tumor necrosis factor\": [\"tnf\", \"tumor necrosis factor\"],\n",
    "    \"interleukin-6\": [\"interleukin-6\", \"il-6\"],\n",
    "    \"interleukin-1\": [\"interleukin-1\", \"il-1\"],\n",
    "    \"thrombin\": [\"thrombin\"],\n",
    "    \"renal failure\": [\n",
    "        \"renal failure\",\n",
    "        \"kidney failure\",\n",
    "        \"acute renal failure\",\n",
    "        \"acute kidney failure\"\n",
    "    ],\n",
    "    \"cardiac failure\": [\n",
    "        \"cardiac failure\",\n",
    "        \"heart failure\",\n",
    "        \"acute cardiac failure\",\n",
    "        \"acute heart failure\"\n",
    "    ],\n",
    "    \"lung failure\": [\n",
    "        \"pulmonary failure\",\n",
    "        \"acute pulmonary failure\",\n",
    "        \"lung failure\",\n",
    "        \"acute lung failure\",\n",
    "    ],\n",
    "    \"liver failure\": [\n",
    "        \"liver failure\",\n",
    "        \"acute liver failure\"\n",
    "    ],\n",
    "    \"organ failure\": [\n",
    "        \"organ failure\",\n",
    "        \"acute organ failure\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "concepts_mappings = {\n",
    "    \"family history of stroke\": (\"Stroke\", \"http://purl.obolibrary.org/obo/NCIT_C3390\",\"A sudden loss of neurological function secondary to hemorrhage or ischemia in the brain parenchyma due to a vascular event.\"),\n",
    "    \"therapeutic insulin\": (\"Insulin\", \"http://purl.obolibrary.org/obo/NCIT_C2271\",\"Insulin (51 aa, ; 6 kDa) is encoded by the human INS gene. This protein is involved in the direct regulation of glucose metabolism.\"),\n",
    "    \"angiotensin-converting enzyme 2\": (\"Angiotensin-Converting Enzyme 2\", \"http://purl.obolibrary.org/obo/NCIT_C102530\",\"Angiotensin-converting enzyme 2 (805 aa, ; 92 kDa) is encoded by the human ACE2 gene. This protein plays a role in both vasodilation and protein cleavage.\"),\n",
    "    \"sars-cov-2\":('SARS Coronavirus 2','http://purl.obolibrary.org/obo/NCIT_C169076','A positive-sense single-stranded RNA virus in the genus Betacoronavirus. It is the causative agent of the 2019-2020 severe acute respiratory syndrome outbreak.'),\n",
    "    \"renal failure\":('Renal Failure','http://purl.obolibrary.org/obo/NCIT_C4376','An acute or chronic condition that is characterized by the inability of the kidneys to adequately filter the blood.'),\n",
    "    \"liver failure\":('Liver Failure','http://purl.obolibrary.org/obo/NCIT_C26922','A disorder characterized by the inability of the liver to metabolize chemicals in the body. Causes include cirrhosis and drug-induced hepatotoxicity. Signs and symptoms include jaundice and encephalopathy. Laboratory test results reveal abnormal plasma levels of ammonia, bilirubin, lactic dehydrogenase, and alkaline phosphatase.'),\n",
    "    \"cardiac failure\":('Cardiac Failure','http://purl.obolibrary.org/obo/NCIT_C50577','Inability of the heart to pump blood at an adequate rate to meet tissue metabolic requirements. Clinical symptoms of heart failure include: unusual dyspnea on light exertion, recurrent dyspnea occurring in the supine position, fluid retention or rales, jugular venous distension, pulmonary edema on physical exam, or pulmonary edema on chest x-ray presumed to be cardiac dysfunction.'),\n",
    "    \"sp-d\":('sp-d','http://purl.obolibrary.org/obo/NCIT_C99071','Deficiency of surfactant protein D. When present in normal amounts, this protein offers protection against pulmonary infection and inflammation.'),\n",
    "    \"lactate dehydrogenase\":('Lactate Dehydrogenase','http://purl.obolibrary.org/obo/NCIT_C25184','A family of homotetrameric cytoplasmic enzymes involved in the conversion of L-lactate and NAD to pyruvate and NADH in the final step of anaerobic glycolysis. In vertebrates, genes for three different subunits (LDH-A, LDH-B and LDH-C) exist.'),\n",
    "    \"covid-19\":('COVID-19 Infection','http://purl.obolibrary.org/obo/NCIT_C171133','An acute infection of the respiratory tract that is caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Based on currently available information, SARS-CoV-2 is thought to mainly spread from person to person through respiratory droplets. Typically, there is a two- to 14-day incubation period and infected persons can present with no symptoms or mild to severe fever, dry cough, fatigue, and difficulty breathing. Dysgeusia, anosmia, and gastrointestinal and flu-like symptoms have also been reported. Older adults and persons of any age who have serious underlying medical conditions may be of higher risk for severe illness, including secondary infections, respiratory failure, and multi-organ dysfunction.'),\n",
    "    \"tumor necrosis factor\":('Tumor Necrosis Factor','http://purl.obolibrary.org/obo/NCIT_C1941','A recombinant therapeutic agent which is chemically identical to or similar to one of a number of endogenous tumor necrosis factor (TNF) proteins. TNF family cytokines bind to and activate specific cell-surface receptors, thereby mediating inflammatory processes, cell proliferation, immunity, angiogenesis, and tumor cell cytotoxicity. One primary antitumor effect of TNFs involves stimulation of T cell-mediated antitumor cytotoxicity.'),\n",
    "    \"interleukin-6\":('Interleukin-6','http://purl.obolibrary.org/obo/NCIT_C20451','Interleukin-6 (212 aa, ; 24 kDa) is encoded by the human IL6 gene. This protein is involved in signaling affecting a wide variety of cell types including monocytes, lymphocytes, hepatocytes and nerve cells.'),\n",
    "    \"interleukin-1\":('Interleukin-1','http://purl.obolibrary.org/obo/NCIT_C20506','Interleukin-1 (endogenous pyrogen), produced primarily by monocytes, is an important pro-inflammatory cytokine that mediates the acute phase host response. The biologic activities of IL1 are properties of a protein derived from a larger precursor. Inflammation causes induction of COX2, leading to release of prostanoids, which sensitize peripheral nociceptor terminals and produce local pain hypersensitivity. Inflammation also generates sensitivity in neighboring tissue, muscle and joint pain, fever, lethargy, and anorexia. COX2 induction in regions of the CNS is mediated by IL1B. Interleukin-1-beta also stimulates bone resorption. IL1RN is a competitive inhibitor of IL1B. Mature IL1-beta levels are a sensitive and specific indicator of caspase-1 activation.')\n",
    "}\n",
    "\n",
    "\n",
    "def enrich_annotations(annotations: Iterable[Dict], linker: EntityLinker) -> Iterator[Dict]:\n",
    "    def _(ann, can):\n",
    "        new = deepcopy(ann)\n",
    "        if can:\n",
    "            concept_name = can.concept\n",
    "            concept_definition = can.definition\n",
    "            concept_uid = can.uid\n",
    "            synonym_map = [key for key, value in synonyms_to_merge.items() if concept_name in value ]\n",
    "            if synonym_map and len(synonym_map) > 0:\n",
    "                concept_name = synonym_map[0]\n",
    "            if str(concept_name).lower() in concepts_mappings:\n",
    "                concept_mapping = concepts_mappings[str(concept_name).lower()]\n",
    "                concept_name = concept_mapping[0]\n",
    "                concept_uid =  concept_mapping[1]\n",
    "                concept_definition = concept_mapping[2]\n",
    "            new.body = {\n",
    "                '@id': concept_uid,\n",
    "                '@type': forge.as_json(ann)[\"body\"][\"@type\"],\n",
    "                'label': concept_name,\n",
    "                'definition':concept_definition\n",
    "            }\n",
    "        else:\n",
    "            \n",
    "            new.body = {\n",
    "                '@id': 'https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/data/entity/'+new.body.id[0],\n",
    "                '@type': forge.as_json(ann)[\"body\"][\"@type\"],\n",
    "                'label': new.body.label\n",
    "            }\n",
    "        return new\n",
    "    mentions = [x.target.selector.value.label for x in annotations]\n",
    "    print(\"Linking \"+str(len(curated_table_extractions))+\" extracted entities to ontology terms ...\")\n",
    "    linked_mentions = linker.link(mentions)\n",
    "    return (_(ann, can) for ann, can in tqdm(zip(annotations, linked_mentions)))\n",
    "\n",
    "enriched_annotations = list(enrich_annotations(annotations, linker))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the knowledge graph\n",
    "Content of the Knowledge Graph is validated. In this version, syntactic validation (i.e. are the identifiers correct, ...) is performed when building the knowledge graph. If the knowledge graph is successfully built then the validation passes. In case of warning (i.e because of a weird character (+,...) in an extracted entity), the user can go back to the curation step and further curate extracted entities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Build knowledge graph from enriched annotations\n",
    "import json\n",
    "from typing import Iterable, Dict\n",
    "from rdflib import Graph\n",
    "\n",
    "\n",
    "def load_knowledge_graph(jsonlds: Iterable[Dict]) -> Graph:\n",
    "    g = Graph()\n",
    "    for x in tqdm(jsonlds):\n",
    "        x = forge.as_jsonld(x, form=\"expanded\")\n",
    "        g.parse(data=json.dumps(x), format='json-ld')\n",
    "    return g\n",
    "\n",
    "print(\"Generating the knowledge graph ...\")\n",
    "knowledge_graph = load_knowledge_graph(enriched_annotations)\n",
    "\n",
    "content_graph= Graph()\n",
    "import rdflib\n",
    "for o in knowledge_graph.objects(None,rdflib.term.URIRef(\"http://www.w3.org/ns/anno.jsonld/hasBody\")):\n",
    "    for ss, pp, oo in knowledge_graph.triples((rdflib.term.URIRef(o),None,None)):\n",
    "        content_graph.add((ss,pp,oo))\n",
    "print(\"Done.\")\n",
    "print(f'The knowledge graph has {len(knowledge_graph)} triples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct knowledge graph\n",
    "Correction involves going back to the extraction and/or curation steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access the knowledge graph\n",
    "The user can search, visualize, and export the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_digraph\n",
    "import networkx as nx\n",
    "from rdflib.namespace import RDF, RDFS, SKOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Building co-mention graph...\")\n",
    "reshaped_enriched_annotations = forge.reshape(enriched_annotations, keep=[\"body\",\"target.selector.exact\",\"target.source\"])\n",
    "\n",
    "enriched_annotations_df = forge.as_dataframe(reshaped_enriched_annotations)\n",
    "\n",
    "def _build_co_mention(group_by, retrieve_key,df):\n",
    "    entity_co_mention = df[[group_by,retrieve_key]].groupby(group_by)\n",
    "    group_keys = list(entity_co_mention.groups.keys())\n",
    "    all_co_mentions = [entity_co_mention.get_group(group_key)[retrieve_key].dropna().unique() for group_key in group_keys]\n",
    "    return entity_co_mention, group_keys,all_co_mentions\n",
    "        \n",
    "enriched_entity_stats = _frequency(group_by=\"body.@id\",retrieve_key=\"target.source\",df=enriched_annotations_df,distinct_papers=True)\n",
    "relation_stats = _frequency(group_by=\"property\",retrieve_key=\"paper_id\",df=curated_table_extractions,distinct_papers=True)\n",
    "\n",
    "entity_co_mention, paper_ids,all_co_mentions = _build_co_mention(group_by=\"target.source\",retrieve_key= \"body.@id\",df=enriched_annotations_df)\n",
    "\n",
    "comention_graph= rdflib.ConjunctiveGraph()\n",
    "\n",
    "import rdflib\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.paths import Path\n",
    "\n",
    "\n",
    "comentioned_dict = {}\n",
    "   \n",
    "for paper_id in paper_ids:\n",
    "    comentioned_entities = entity_co_mention.get_group(paper_id)[\"body.@id\"].dropna().unique()\n",
    "    comentioned_entities = set(comentioned_entities)\n",
    "    for comentioned_entity in  comentioned_entities:\n",
    "        if comentioned_entity not in comentioned_dict:\n",
    "            comentioned_dict[comentioned_entity] = []\n",
    "        comentioned_dict[comentioned_entity].append((paper_id,comentioned_entities))\n",
    "\n",
    "\n",
    "for ss in comentioned_dict.keys():\n",
    "    for aPaper, co_mentioned_entities in comentioned_dict[str(ss)]:\n",
    "        for co_mentioned in co_mentioned_entities:\n",
    "            if ss != co_mentioned:\n",
    "                if (rdflib.term.URIRef(co_mentioned),rdflib.term.URIRef(\"https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/vocab/comention\"),rdflib.term.URIRef(ss), aPaper) not in comention_graph:\n",
    "                    comention_graph.add((rdflib.term.URIRef(ss),rdflib.term.URIRef(\"https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/vocab/comention\"),rdflib.term.URIRef(co_mentioned),aPaper))\n",
    "                    \n",
    "print(\"Done ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec922c4fb4794cc89051e13b8147efbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Done\n",
      "CPU times: user 54.4 s, sys: 2.41 s, total: 56.8 s\n",
      "Wall time: 56.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Loading precomputed paths for 3000 thousands extracted entities...\")\n",
    "\n",
    "\n",
    "def get_cumulative_weight(graph, path, weight=\"ppmi\"):\n",
    "    result = 0\n",
    "    for i in range(1, len(path)):\n",
    "        source = path[i - 1]\n",
    "        target = path[i]\n",
    "        result += graph.edges[source, target][weight]\n",
    "    return result\n",
    "\n",
    "def get_all_paths(graph, input_source, input_target, path_condition=None, weight=\"ppmi\"):\n",
    "\n",
    "    backup_edge = None\n",
    "    path_ranking = {}\n",
    "\n",
    "    if (input_source, input_target) in graph.edges():\n",
    "        backup_edge  = {**graph.edges[input_source, input_target]}\n",
    "        graph.remove_edge(input_source, input_target)\n",
    "    try:\n",
    "        shortest_paths = list(\n",
    "            nx.all_shortest_paths(graph, input_source,\n",
    "                                  input_target))\n",
    "        path_ranking = {}\n",
    "        for p in shortest_paths:\n",
    "            if path_condition is None or path_condition(p):\n",
    "                path_ranking[tuple(p[1:-1])] = get_cumulative_weight(graph, p, weight=weight)\n",
    "        return(path_ranking)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "    if backup_edge is not None:\n",
    "        graph.add_edge(input_source, input_target, **backup_edge)\n",
    "\n",
    "    return path_ranking\n",
    "\n",
    "def top_n(data_dict, n):\n",
    "    print(data_dict)\n",
    "    df = pd.DataFrame(dict(data_dict).items(), columns=[\"id\", \"value\"])\n",
    "    display(df)\n",
    "    df = df.nlargest(n, columns=[\"value\"])\n",
    "    return(list(df[\"id\"]))\n",
    "\n",
    "\n",
    "\n",
    "def pretty_print_paths(paths):\n",
    "    a = paths[0][0]\n",
    "    b = paths[0][-1]\n",
    "    a_repr = \"{} <-> \".format(a)\n",
    "    b_repr = \" <-> {}\".format(b)\n",
    "    path_repr = [\n",
    "        \" <-> \".join(p[1:-1])\n",
    "        for p in paths\n",
    "    ]\n",
    "    print(\"{}{}{}\".format(\n",
    "        a_repr, \" \" * max(len(p) for p in path_repr), b_repr))\n",
    "    for p in path_repr:\n",
    "        print(\"{}{}\".format(\" \" * len(a_repr), p))\n",
    "        \n",
    "\n",
    "def top_n_paths(graph, a, b, n, path_condition=None, pretty_print=False,\n",
    "                pretty_repr=False, weight=\"ppmi\",\n",
    "                strategy=\"naive\"):\n",
    "    paths = []\n",
    "    if strategy == \"naive\":\n",
    "        path_ranks = get_all_paths(graph, a, b, path_condition=path_condition, weight=weight)\n",
    "        path_ranks = {\n",
    "            tuple([a] + [el for el in p] + [b]): r for p, r in path_ranks.items()\n",
    "        }\n",
    "        if len(path_ranks) > 0:\n",
    "            paths = top_n(path_ranks, n)\n",
    "        \n",
    "    elif strategy == \"yen\":\n",
    "        generator = nx.shortest_simple_paths(\n",
    "            graph, a, b, weight=\"distance_{}\".format(weight))\n",
    "        i = 0\n",
    "        paths = []\n",
    "        for path in generator:\n",
    "            paths.append(path)\n",
    "            i += 1\n",
    "            if i == n:\n",
    "                break\n",
    "            \n",
    "    if pretty_print or pretty_repr:\n",
    "        r = pretty_print_paths(paths, as_repr=pretty_repr)\n",
    "        return paths, r\n",
    "    return paths\n",
    "\n",
    "def spanning_tree_path(spanning_tree, a, b, pretty_print=False):\n",
    "    path = list(nx.shortest_path(spanning_tree, a, b))\n",
    "    if pretty_print:\n",
    "        print(\" -> \".join(path))\n",
    "    return path\n",
    "\n",
    "def top_n_tripaths(graph, a, b, c, n, intersecting=True, pretty_print=False, \n",
    "                   pretty_repr=False, weight=\"ppmi\", strategy=\"naive\"):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def non_intersecting(path, reference_paths):\n",
    "        core = set(path[1:-1])\n",
    "        for p in reference_paths:\n",
    "            if len(set(p[1:-1]).intersection(core)) > 0:\n",
    "                return False\n",
    "        return True\n",
    "            \n",
    "    a_b_paths = top_n_paths(graph, a, b, n, weight=weight,\n",
    "            strategy=strategy)\n",
    "    if not intersecting:\n",
    "        b_c_paths = top_n_paths(\n",
    "            graph, b, c, n,\n",
    "            path_condition=lambda x: non_intersecting(x, a_b_paths),\n",
    "            weight=weight,\n",
    "            strategy=strategy)\n",
    "        \n",
    "    else:\n",
    "        b_c_paths = top_n_paths(\n",
    "            graph, b, c, n,\n",
    "            weight=weight,\n",
    "            strategy=strategy)\n",
    "        \n",
    "    path_ranking = {}\n",
    "    \n",
    "    if pretty_print:\n",
    "        a_b_paths_repr = [\n",
    "            \" -> \".join(p[1:-1]) for p in a_b_paths\n",
    "        ]\n",
    "\n",
    "        b_c_paths_repr = [\n",
    "            \" -> \".join(p[1:-1]) for p in b_c_paths\n",
    "        ]\n",
    "\n",
    "        max_left = max([len(el) for el in a_b_paths_repr])\n",
    "        max_right = max([len(el) for el in b_c_paths_repr])\n",
    "\n",
    "        a_repr = \"{} ->\".format(a)\n",
    "        b_repr = \"-> {} ->\".format(b)\n",
    "        c_repr = \"-> {}\".format(c)\n",
    "        print(\"{}{}{}{}{}\".format(\n",
    "            a_repr,\n",
    "            \" \" * max_left,\n",
    "            b_repr,\n",
    "            \" \" * max_right,\n",
    "            c_repr))\n",
    "        for i in range(n):\n",
    "            if i == len(a_repr):\n",
    "                break\n",
    "            print(\" \" * len(a_repr), a_b_paths_repr[i], \" \" * (max_left - len(a_b_paths_repr[i]) + len(b_repr)), b_c_paths_repr[i])\n",
    "    return (a_b_paths, b_c_paths)\n",
    "\n",
    "factors = [\"paper\", \"section\", \"paragraph\"]\n",
    "weights = [\"npmi\", \"ppmi\"]\n",
    "trees = {}\n",
    "\n",
    "precomputed_nodes_df = {}\n",
    "precomputed_edges_df = {}\n",
    "# open graphs if they where already generated\n",
    "graphs = {}\n",
    "for factor in tqdm(factors):\n",
    "    with open(\"/gpfs/bbp.cscs.ch/project/proj116/network_analytics/data/graphs/{}_3000_edge_list.pkl\".format(factor), \"rb\") as f:\n",
    "        edges = pickle.load(f)\n",
    "    precomputed_edges_df[factor] = edges\n",
    "\n",
    "    graph = nx.from_pandas_edgelist(\n",
    "        edges,\n",
    "         edge_attr=[\n",
    "            \"frequency\",\n",
    "            \"ppmi\",\n",
    "            \"npmi\",\n",
    "            \"distance_ppmi\",\n",
    "            \"distance_npmi\"\n",
    "\n",
    "         ])\n",
    "    with open(\"/gpfs/bbp.cscs.ch/project/proj116/network_analytics/data/graphs/{}_3000_node_list.pkl\".format(factor), \"rb\") as f:\n",
    "        nodes = pickle.load(f)\n",
    "    nx.set_node_attributes(graph, nodes.to_dict(\"index\"))\n",
    "    precomputed_nodes_df[factor] = nodes\n",
    "    graphs[factor] = graph\n",
    "    \n",
    "    trees[factor] = {}\n",
    "    for w in tqdm(weights):\n",
    "        with open(\"/gpfs/bbp.cscs.ch/project/proj116/network_analytics/data/graphs/{}_3000_{}_spanning_tree.pkl\".format(factor, w), \"rb\") as f:\n",
    "            tree_edges = pickle.load(f)\n",
    "        tree_edges = tree_edges.rename(columns={\"Source\": \"source\", \"Target\": \"target\"})\n",
    "        tree_edges[w] = edges[w]\n",
    "        tree = nx.from_pandas_edgelist(tree_edges)\n",
    "        trees[factor][w] = tree\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_digraph\n",
    "import base64\n",
    "import io\n",
    "import dash\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_table\n",
    "import pandas as pd\n",
    "import dash_cytoscape as cyto\n",
    "\n",
    "cyto.load_extra_layouts()\n",
    "\n",
    "def create_edge(id, from_id, to_id, label=None, label_size=10, label_color=\"black\", thickness=2, edge_color=\"grey\", edge_style=\"solid\",frequency=1,papers=[]):\n",
    "\n",
    "        if thickness == 0:\n",
    "            thickness = 2\n",
    "        return {\n",
    "            \"data\": { \n",
    "                \"id\": str(id),\n",
    "                \"source\": str(from_id).lower(),\n",
    "                \"target\": str(to_id).lower(),\n",
    "                \"frequency\":frequency,\n",
    "                \n",
    "                \"papers\":papers\n",
    "            },\n",
    "            \"style\": {\n",
    "               \"label\": label if label else '',\n",
    "                \"width\": thickness\n",
    "            }\n",
    "        }\n",
    "\n",
    "def create_node(id, node_type=None,label=None, label_size=10, label_color=\"black\", radius=30, node_color='grey',frequency={}, definition=\"\",papers=[]):\n",
    "\n",
    "        actualLabel = None\n",
    "        if label is not None:\n",
    "            actualLabel = label.lower()\n",
    "        else:\n",
    "            actualLabel = str(id).lower().split(\"/\")[-1].split(\"#\")[-1]\n",
    "        frequency_raw = frequency['frequency'] if 'frequency' in frequency else 1\n",
    "        return {\n",
    "            \"data\": { \n",
    "                \"id\": str(id).lower(),\n",
    "                \"frequency\":frequency_raw,\n",
    "                \"degree_frequency\":frequency['degree_frequency'] if 'degree_frequency' in frequency else frequency_raw,\n",
    "                \"pagerank_frequency\":frequency['pagerank_frequency'] if 'pagerank_frequency' in frequency else frequency_raw,\n",
    "                \"definition\":definition,\n",
    "                \"papers\":papers,\n",
    "                \"type\":node_type\n",
    "            },\n",
    "            \"style\": {\n",
    "                \"label\": actualLabel\n",
    "\n",
    "            }\n",
    "        }\n",
    "    \n",
    "def build_cytoscape_elements(comention_graph, content_graph, paper_precomputed_nodes, paper_precomputed_edges, graph_type=\"comention\"):\n",
    "    elements = []\n",
    "    \n",
    "    G = rdflib_to_networkx_digraph(comention_graph) if graph_type ==\"comention\" else rdflib_to_networkx_digraph(content_graph)\n",
    "    \n",
    "    def addNode(node):\n",
    "        \n",
    "        if (str(node).startswith(\"http\")) and not (str(node).startswith('https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/schemas/')):\n",
    "            node_label = content_graph.label(node,str(node).split(\"/\")[-1].split(\"#\")[-1])\n",
    "            node_type = content_graph.value(node,RDF.type, default=\"\",any=True).split(\"/\")[-1].split(\"#\")[-1]\n",
    "            node_definition = content_graph.value(node,SKOS.definition, default=\"\", any=True)\n",
    "    \n",
    "            frequency={\n",
    "                'frequency':1\n",
    "            }\n",
    "            \n",
    "            \n",
    "     \n",
    "            node_papers = enriched_entity_stats[str(node)]\n",
    "            frequency['frequency']=len(node_papers)\n",
    "            node_radius = len(node_papers)\n",
    "            \n",
    "            try:\n",
    "                result_df = precomputed_nodes_df['paper'].loc[str(node_label).lower()]\n",
    "                pagerank_frequency = (result_df.pagerank_frequency / precomputed_nodes_df['paper'].pagerank_frequency.max()) * 100\n",
    "                degree_frequency = (result_df.degree_frequency / precomputed_nodes_df['paper'].degree_frequency.max()) * 100\n",
    "                frequency['degree_frequency']=degree_frequency\n",
    "                node_radius = frequency['degree_frequency']\n",
    "                frequency['pagerank_frequency']=pagerank_frequency\n",
    "\n",
    "            except Exception as e:\n",
    "\n",
    "                frequency['frequency']=len(node_papers)\n",
    "            if frequency['frequency'] >= 1:\n",
    "                \n",
    "                element = create_node(str(node), node_type,label=str(node_label),radius=node_radius, frequency=frequency,node_color=\"lightblue\", label_color='blue',definition=str(node_definition), papers = node_papers)\n",
    "                elements.append(element)\n",
    "\n",
    "    \n",
    "    def addEdge(id, from_id, to_id, label=None, label_size=10, label_color=\"black\", thickness=2, edge_color=\"grey\", edge_style=\"solid\",frequency=1,papers=[]):\n",
    "        element = create_edge(id, from_id, to_id, label, label_size, label_color, thickness, edge_color, edge_style,frequency,papers)\n",
    "        elements.append(element)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    for node, node_attrs in tqdm(G.nodes(data=True)):\n",
    "        addNode(node)\n",
    "                 \n",
    "    for source, target, edge_attrs in tqdm(G.edges(data=True)):\n",
    "        if not 'value' in edge_attrs and not 'width' in edge_attrs and 'weight' in edge_attrs:\n",
    "            edge_attrs['value'] = edge_attrs['weight']\n",
    "        if 'triples' in edge_attrs:\n",
    "            edge_attrs['title'] = edge_attrs['triples'][0][1]\n",
    "        edge_id = str(source).lower().replace(\" \",\"_\")+\"_\"+str(target).lower()\n",
    "        edge_label = str(edge_attrs['title']).split(\"/\")[-1].split(\"#\")[-1]\n",
    "        if edge_label != \"label\" and edge_label != \"definition\" and edge_label != \"type\":\n",
    "            edge_papers = set()\n",
    "            \n",
    "            if graph_type == \"comention\":\n",
    "                for q in comention_graph.quads((rdflib.term.URIRef(source),rdflib.term.URIRef('https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/vocab/comention'),rdflib.term.URIRef(target),None)):\n",
    "                    edge_papers.add(q[3].identifier)\n",
    "                for q in comention_graph.quads((rdflib.term.URIRef(target),rdflib.term.URIRef('https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/vocab/comention'),rdflib.term.URIRef(source),None)):\n",
    "                    edge_papers.add(q[3].identifier)\n",
    "            else:\n",
    "                edge_papers = relation_stats[edge_labelge]\n",
    "            \n",
    "            frequency = len(edge_papers)+2\n",
    "            source_label = str(content_graph.label(source,str(node).split(\"/\")[-1].split(\"#\")[-1]))\n",
    "            target_label = str(content_graph.label(target,str(node).split(\"/\")[-1].split(\"#\")[-1]))\n",
    "            try:\n",
    "                \n",
    "\n",
    "                result_df = precomputed_edges_df['paper'].loc[str(source_label+target_label).lower()]\n",
    "                if len(result_df) > 0:\n",
    "                    frequency = result_df.frequency\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            try:\n",
    "                result_df = precomputed_edges_df['paper'].loc[str(target_label+source_label).lower()]\n",
    "                if len(result_df) > 0:\n",
    "                    frequency = result_df.frequency\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            thickness = (frequency / precomputed_edges_df['paper'].frequency.max()) * 100\n",
    "          \n",
    "            if len(edge_papers) >= 1:\n",
    "                addEdge(\n",
    "                        id = edge_id, \n",
    "                        from_id = str(source), \n",
    "                        to_id = str(target), \n",
    "                        label=None if graph_type == \"comention\" else edge_label,\n",
    "                        label_size=6,\n",
    "                        thickness=thickness, \n",
    "                         edge_color=\"lightgrey\",\n",
    "                        frequency=len(edge_papers),\n",
    "                        papers = list(edge_papers)\n",
    "                       )\n",
    "  \n",
    "    return elements, G\n",
    "print(\"Generating Knowledge Graph and Co-mention visualisation data ...\")\n",
    "comention_graph_cyto_elements, G = build_cytoscape_elements(comention_graph, content_graph, precomputed_nodes_df[\"paper\"], precomputed_edges_df[\"paper\"], graph_type=\"comention\")\n",
    "knowledge_graph_cyto_elements, G = build_cytoscape_elements(comention_graph, content_graph, precomputed_nodes_df[\"paper\"], precomputed_edges_df[\"paper\"], graph_type=\"kg\")\n",
    "\n",
    "comention_graph_cyto_elements_dict = {elt['data']['id']:elt for elt in comention_graph_cyto_elements}\n",
    "comention_graph_cyto_elements_label_dict = {str(elt['style']['label']).lower():elt for elt in comention_graph_cyto_elements}\n",
    "knowledge_graph_cyto_elements_dict= {elt['data']['id']:elt for elt in knowledge_graph_cyto_elements}\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################# Graph LAYOUT Definition ################################\n",
    "\n",
    "node_shape_option_list = ['ellipse',\n",
    "                                'triangle',\n",
    "                                'rectangle',\n",
    "                                'diamond',\n",
    "                                'pentagon',\n",
    "                                'hexagon',\n",
    "                                'heptagon',\n",
    "                                'octagon',\n",
    "                                'star',\n",
    "                                'polygon']\n",
    "\n",
    "dropdown_download_option_list = [\n",
    "                                    'jpg',\n",
    "                                    'png',\n",
    "                                    'svg'\n",
    "                                ]\n",
    "\n",
    "graph_layout_option_list = ['preset',\n",
    "                            'random',\n",
    "                            'grid',\n",
    "                            'circle',\n",
    "                            'concentric',\n",
    "                            'breadthfirst',\n",
    "                            'cose',\n",
    "                            'cose-bilkent',\n",
    "                            'dagre',\n",
    "                            'cola',\n",
    "                            'klay',\n",
    "                            'spread',\n",
    "                            'euler']\n",
    "\n",
    "node_frequency_type = [\n",
    "    \"Degree Frequency\",\n",
    "    \"PageRank Frequency\"\n",
    "]\n",
    "\n",
    "graph_type_option_list = ['Knowledge Graph', 'Co-mention Graph']\n",
    "\n",
    "\n",
    "button_group = dbc.InputGroup(\n",
    "    [\n",
    "                        dbc.Button(\"Reset\", color=\"primary\", className=\"mr-1\",id='bt-reset'),\n",
    "                        dbc.Tooltip(\n",
    "                            \"Reset the display to default valuess\",\n",
    "                            target=\"bt-reset\",\n",
    "                            placement=\"bottom\",\n",
    "                        ),\n",
    "                        dbc.Button(\"Remove Selected Node\", color=\"primary\", className=\"mr-1\",id='remove-button'),\n",
    "                        dbc.DropdownMenu(\n",
    "                            [\n",
    "                             dbc.DropdownMenuItem(\"png\", id=\"png-menu\"),\n",
    "                                dbc.DropdownMenuItem(divider=True),\n",
    "                             dbc.DropdownMenuItem(\"jpg\", id=\"jpg-menu\"),\n",
    "                                 dbc.DropdownMenuItem(divider=True),\n",
    "                             dbc.DropdownMenuItem(\"svg\", id=\"svg-menu\")\n",
    "                            ],\n",
    "                            label=\"Download\",\n",
    "                            id='dropdown-download',\n",
    "                            \n",
    "                            color=\"primary\",\n",
    "                            group=True,\n",
    "                            className=\"mr-1\"\n",
    "                        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "buttons = dbc.FormGroup(\n",
    "            [\n",
    "                 button_group\n",
    "            ],className=\"mr-1\"\n",
    "        )\n",
    "\n",
    "graph_type_radio = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Label(\"Display\", html_for=\"showgraph\", width=3),\n",
    "        dbc.Col(\n",
    "            dbc.RadioItems(\n",
    "                id=\"showgraph\",\n",
    "                value='Co-mention Graph',\n",
    "                options=[{'label': val.capitalize(), 'value': val} for val in graph_type_option_list],\n",
    "                inline=True\n",
    "            ), width=9\n",
    "        )\n",
    "    ],\n",
    "    row=True\n",
    ")\n",
    "\n",
    "scope_option_list = ['Paper', 'Section', \"Paragraph\"]\n",
    "\n",
    "scope_radio = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Label(\"Scope\", html_for=\"graphscope\", width=3),\n",
    "        dbc.Col(\n",
    "            dbc.RadioItems(\n",
    "                id=\"graphscope\",\n",
    "                value='Paper',\n",
    "                options=[{'label': val.capitalize(), 'value': val} for val in scope_option_list],\n",
    "                inline=True\n",
    "            ), width=9\n",
    "        )\n",
    "    ],\n",
    "    row=True\n",
    ")\n",
    "\n",
    "group_option_list = ['None','Type', 'Mutual Information']\n",
    "\n",
    "group_radio = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Label(\"Group By\", html_for=\"graphgroup\", width=3),\n",
    "        dbc.Col(\n",
    "            dbc.RadioItems(\n",
    "                id=\"graphgroup\",\n",
    "                value='None',\n",
    "                options=[{'label': val.capitalize(), 'value': val} for val in group_option_list],\n",
    "                inline=True\n",
    "            ), width=9\n",
    "        )\n",
    "    ],\n",
    "    row=True\n",
    ")\n",
    "\n",
    "\n",
    "input_group = dbc.InputGroup(\n",
    "    [\n",
    "        dbc.InputGroupAddon(\n",
    "            \"Search\",\n",
    "            addon_type=\"prepend\",\n",
    "        ),\n",
    "         dcc.Dropdown(\n",
    "            id=\"searchdropdown\",\n",
    "            multi=True,\n",
    "             style={\n",
    "                 \"width\":\"80%\"\n",
    "             }\n",
    "             \n",
    "        )\n",
    "        \n",
    "    ],\n",
    "    className=\"mb-3\"\n",
    ")\n",
    "\n",
    "\n",
    "search = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Label(\"Search\", html_for=\"searchdropdown\", width=3),\n",
    "        dbc.Col(dcc.Dropdown(\n",
    "            id=\"searchdropdown\",\n",
    "            multi=True\n",
    "        ), width=9)\n",
    "        \n",
    "    ],\n",
    "    \n",
    "    row=True\n",
    ")\n",
    "\n",
    "dropdown_menu_items = [\n",
    "    dbc.DropdownMenuItem(\"Degree Frequency\",   id=\"dropdown-menu-freq-degree_frequency\"),\n",
    "    dbc.DropdownMenuItem(\"PageRank Frequency\", id=\"dropdown-menu-freq-pagerank_frequency\")\n",
    "]\n",
    "\n",
    "\n",
    "freq_input_group = dbc.InputGroup(\n",
    "    [\n",
    "        dbc.InputGroupAddon(\n",
    "            \"Node Frequency\",\n",
    "            addon_type=\"prepend\",\n",
    "        ),\n",
    "         dcc.Dropdown(\n",
    "            id=\"node_freq_type\",\n",
    "             value=\"degree_frequency\",\n",
    "             options=[{'label': val, 'value': val.lower().replace(\" \",\"_\")} for val in node_frequency_type],\n",
    "             style={\n",
    "                 \"width\":\"80%\"\n",
    "             }\n",
    "        )\n",
    "    ],\n",
    "    className=\"mb-1\"\n",
    ")\n",
    "\n",
    "\n",
    "node_slider = dbc.InputGroup(\n",
    "    [\n",
    "        freq_input_group,\n",
    "        dcc.Dropdown(\n",
    "            id='node-freq-filter',\n",
    "            value=\"ge\",\n",
    "            clearable=False,\n",
    "            options = dropdown_freq_filter_list,\n",
    "            \n",
    "            className=\"mr-1\"\n",
    "        ),\n",
    "        daq.NumericInput(\n",
    "            id=\"nodefreqslider\",\n",
    "            min=1,  \n",
    "            max=10000,\n",
    "            value=1,\n",
    "           className=\"mr-1\"\n",
    "        )\n",
    "        \n",
    "       \n",
    "    ],\n",
    "    className=\"mb-3\"\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "item_details = dbc.FormGroup(\n",
    "    [\n",
    "        \n",
    "        html.Div(id=\"modal\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "item_details_card = dbc.Card(\n",
    "                        dbc.CardBody(\n",
    "                            [\n",
    "                                html.H5(\"\", className=\"card-title\"),\n",
    "                                html.H6(\"\", className=\"card-subtitle\"),\n",
    "                                html.P(\n",
    "                                    \"\",\n",
    "                                    className=\"card-text\"\n",
    "                                ),\n",
    "                                dbc.Button(\"\", color=\"primary\", id =\"see-more-card\")\n",
    "                            ],\n",
    "                            id = \"item-card-body\"\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "form = dbc.Form([button_group, graph_type_radio, search, node_slider, item_details_card])\n",
    "\n",
    "\n",
    "path_from = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Label(\"From\", html_for=\"searchpathfrom\", width=3),\n",
    "        dbc.Col(dcc.Dropdown(\n",
    "            id=\"searchpathfrom\"\n",
    "        ), width=9)\n",
    "        \n",
    "    ],\n",
    "    \n",
    "    row=True\n",
    ")\n",
    "\n",
    "path_to = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Label(\"To\", html_for=\"searchpathto\", width=3),\n",
    "        dbc.Col(dcc.Dropdown(\n",
    "            id=\"searchpathto\"\n",
    "        ), width=9)\n",
    "        \n",
    "    ],\n",
    "    \n",
    "    row=True\n",
    ")\n",
    "\n",
    "path_condition = dbc.FormGroup(\n",
    "            [\n",
    "                dbc.Label(\"Constraints\"),\n",
    "                dbc.FormGroup(\n",
    "                    [\n",
    "                        dbc.Label(\"Traverse\", html_for=\"searchnodetotraverse\", width=3),\n",
    "                        dbc.Col(dcc.Dropdown(\n",
    "                            id=\"searchnodetotraverse\",\n",
    "                            disabled=True,\n",
    "                        ), width=9)\n",
    "\n",
    "                    ],\n",
    "                    row=True\n",
    "                ),\n",
    "                dbc.FormGroup(\n",
    "                    [\n",
    "                        dbc.Label(\"Allow Overlap\", html_for=\"searchpathoverlap\", width=3),\n",
    "                        dbc.Col(\n",
    "                            dbc.Checklist(\n",
    "                                options=[\n",
    "                                    {\"label\": \"Yes\", \"value\": 1,\"disabled\":True}\n",
    "                                ],\n",
    "                                value=1,\n",
    "                                id=\"searchpathoverlap\",\n",
    "                                \n",
    "                                switch=True,\n",
    "                            ),\n",
    "                            \n",
    "                            width=9)\n",
    "\n",
    "                    ],\n",
    "                    row=True\n",
    "                ),\n",
    "                dbc.FormGroup(\n",
    "                    [\n",
    "                        dbc.Label(\"Top N\", html_for=\"searchpathlimit\", width=3),\n",
    "                        dbc.Col(\n",
    "                            daq.NumericInput(\n",
    "                                id=\"searchpathlimit\",\n",
    "                                min=10,  \n",
    "                                max=20,\n",
    "                                value=10,\n",
    "                               className=\"mr-1\"\n",
    "                            ),\n",
    "                            width=9\n",
    "                        )\n",
    "\n",
    "                    ],\n",
    "                    row=True\n",
    "                )\n",
    "            ]\n",
    ")\n",
    "\n",
    "search_path = dbc.InputGroup(\n",
    "    [\n",
    "                        dbc.Button(\"Find Paths\", color=\"primary\", className=\"mr-1\",id='bt-path'),\n",
    "                        dbc.Tooltip(\n",
    "                            \"Find paths between selected entities\",\n",
    "                            target=\"bt-path\",\n",
    "                            placement=\"bottom\",\n",
    "                        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "form_path_finder = dbc.Form([path_from,path_to,path_condition,search_path])\n",
    "\n",
    "graph_layout = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Label(\"Layout\", html_for=\"searchdropdown\", width=3),\n",
    "        dbc.Col(dcc.Dropdown(\n",
    "            id ='dropdown-layout',\n",
    "            options = [{'label': val.capitalize(), 'value': val} for val in graph_layout_option_list],\n",
    "            value='cola',\n",
    "            clearable=False\n",
    "        ), width=9)\n",
    "        \n",
    "    ],\n",
    "    row=True\n",
    ")\n",
    "\n",
    "node_shape = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Label(\"Node Shape\", html_for=\"dropdown-node-shape\", width=3),\n",
    "        dbc.Col(dcc.Dropdown(\n",
    "            id='dropdown-node-shape',\n",
    "            value='ellipse',\n",
    "            clearable=False,\n",
    "            options = [{'label': val.capitalize(), 'value': val} for val in node_shape_option_list]\n",
    "        ), width=9)\n",
    "        \n",
    "    ],\n",
    "    row=True\n",
    ")\n",
    "\n",
    "link_color_picker = dbc.FormGroup(\n",
    "    [\n",
    "        dbc.Col(daq.ColorPicker(\n",
    "          id='input-follower-color',\n",
    "          value=dict(hex='#a0b3dc'),\n",
    "          label=\"Edge Color\"\n",
    "        ))    \n",
    "    ],\n",
    "    row=True\n",
    ")\n",
    "\n",
    "\n",
    "conf_form =dbc.Form([graph_layout,node_shape,link_color_picker])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import dash\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "\n",
    "\n",
    "import dash_cytoscape as cyto\n",
    "\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "def load_json(st):\n",
    "    if 'http' in st:\n",
    "        return requests.get(st).json()\n",
    "    else:\n",
    "        with open(st, 'rb') as f:\n",
    "            x = json.load(f)\n",
    "        return x\n",
    "    \n",
    "# Load extra layouts\n",
    "cyto.load_extra_layouts()\n",
    "app_tab =  JupyterDash(\"allvis\")\n",
    "\n",
    "app_tab.add_bootstrap_links = True\n",
    "app_tab.external_stylesheets=dbc.themes.CYBORG\n",
    "\n",
    "server = app_tab.server\n",
    "\n",
    "\n",
    "CONTENT_STYLE = {\n",
    "    \n",
    "    \"width\": \"70%\",\n",
    "    \"top\": \"0px\",\n",
    "    \"left\":\"0px\",\n",
    "    \"bottom\": \"0px\",\n",
    "    \"position\": \"fixed\",\n",
    "\n",
    "    }\n",
    "\n",
    "colors = {\n",
    "    \"CHEMICAL\":\"green\",\n",
    "    \"PROTEIN\":\"#469d8c\",\n",
    "    \"DISEASE\":\"#dceef1\",\n",
    "    \"CELL_TYPE\":\"#f1d2b5\"\n",
    "}\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "cystoscape_STYLE_stylesheet = [\n",
    "    {\n",
    "        \"selector\":'cytoscape',\n",
    "        \"style\": {\n",
    "            \"width\": \"100%\",\n",
    "            \"height\": \"100%\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"selector\": 'node[type = \"CHEMICAL\"]',\n",
    "        \"style\": {\"background-color\": colors[\"CHEMICAL\"]},\n",
    "    },{\n",
    "        \"selector\": 'node',\n",
    "        'style': {\n",
    "            \"font-size\": 20,\n",
    "            #\"font-weight\":\"bold\",\n",
    "            \"text-valign\": \"center\",\n",
    "            \"text-halign\": \"center\",\n",
    "            #\"text-outline-color\": \"#000000\",\n",
    "            #\"text-outline-width\": \"2px\",\n",
    "           \n",
    "            \"color\": \"black\",\n",
    "            \"overlay-padding\": \"6px\",\n",
    "            \"z-index\": \"10\"\n",
    "        }\n",
    "    },{\n",
    "        \"selector\": 'edge',\n",
    "        \"style\": {\n",
    "            'curve-style': 'bezier',\n",
    "            'line-color': '#D5DAE6'\n",
    "        }\n",
    "    },{\n",
    "        \"selector\": 'node[type = \"PROTEIN\"]',\n",
    "        \"style\": {\"background-color\": colors[\"PROTEIN\"]},\n",
    "    },{\n",
    "        \"selector\": 'node[type = \"DISEASE\"]',\n",
    "        \"style\": {\"background-color\": colors[\"DISEASE\"]},\n",
    "    },{\n",
    "        \"selector\": 'node[type = \"CELL_TYPE\"]',\n",
    "        \"style\": {\"background-color\": colors[\"CELL_TYPE\"]},\n",
    "    }]\n",
    "\n",
    "app_tab.layout  = html.Div(  \n",
    "    [\n",
    "         dcc.Store(id='memory',data={\"removed\":[]}),\n",
    "       \n",
    "    dbc.Row(\n",
    "            [\n",
    "                dbc.Col(\n",
    "                \n",
    "                html.Div( style=CONTENT_STYLE, children=[\n",
    "                    cyto.Cytoscape(\n",
    "                                        id='cytoscape',\n",
    "                                        elements=comention_graph_cyto_elements,\n",
    "                                        \n",
    "                                        stylesheet = cystoscape_STYLE_stylesheet,\n",
    "                                        style= {\n",
    "                                                \"width\": \"100%\",\n",
    "                                                \"height\": \"100%\"\n",
    "                                        }\n",
    "                                    )\n",
    "                ]),\n",
    "                    width=8\n",
    "                ),\n",
    "                dbc.Col(\n",
    "                    \n",
    "                    html.Div( children=[\n",
    "                        dbc.Tabs(id='tabs', children=[\n",
    "                            dbc.Tab(label='Details', label_style={\"color\": \"#00AEF9\", \"border-radius\":\"4px\"},children=[\n",
    "                                \n",
    "                                dbc.Card(\n",
    "                                    dbc.CardBody(\n",
    "                                        [\n",
    "                                            form\n",
    "                                        ]\n",
    "                                    )\n",
    "                                )\n",
    "                                \n",
    "                                \n",
    "                            ]),\n",
    "                            dbc.Tab(label='Graph Layout and Shape', label_style={\"color\": \"#00AEF9\"}, children=[\n",
    "                                dbc.Card(\n",
    "                                    dbc.CardBody(\n",
    "                                        [\n",
    "                                            conf_form\n",
    "                                        ]\n",
    "                                    )\n",
    "                                )\n",
    "                            ]),\n",
    "                            dbc.Tab(label='Path Finder', label_style={\"color\": \"#00AEF9\"}, children=[\n",
    "                                dbc.Card(\n",
    "                                    dbc.CardBody(\n",
    "                                        [\n",
    "                                            form_path_finder\n",
    "                                        ]\n",
    "                                    )\n",
    "                                )\n",
    "                            ])\n",
    "                        ]),\n",
    "                    ]\n",
    "                            ),\n",
    "                    width=4\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "# ############################## CALLBACKS ####################################\n",
    "\n",
    "\n",
    "@app_tab.callback(\n",
    "    Output(\"modal-body-scroll\", \"is_open\"),\n",
    "    [\n",
    "        Input(\"open-body-scroll\", \"n_clicks\"),\n",
    "        Input(\"close-body-scroll\", \"n_clicks\"),\n",
    "    ],\n",
    "    [State(\"modal-body-scroll\", \"is_open\")],\n",
    ")\n",
    "def toggle_modal(n1, n2, is_open):\n",
    "    if n1 or n2:\n",
    "        return not is_open\n",
    "    return is_open\n",
    "\n",
    "\n",
    "@app_tab.callback(\n",
    "    Output(\"searchdropdown\", \"options\"),\n",
    "    [Input(\"searchdropdown\", \"search_value\")],\n",
    "    [State(\"searchdropdown\", \"value\"),\n",
    "    State('cytoscape', 'elements')],\n",
    ")\n",
    "def update_multi_options(search_value, value,elements):\n",
    "    \n",
    "    if not search_value:\n",
    "        raise PreventUpdate\n",
    "    \n",
    "\n",
    "    res = []\n",
    "    for ele_data in elements:\n",
    "        \n",
    "        if 'label' in ele_data['style']:\n",
    "            label =ele_data['style']['label']\n",
    "            if (search_value in label) or (label in search_value) or ele_data['data']['id'] in (value or []) :\n",
    "                res.append( {\"label\":ele_data['style']['label'],\"value\":ele_data['data']['id']})\n",
    "  \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "@app_tab.callback(\n",
    "    Output(\"searchpathto\", \"options\"),\n",
    "    [Input(\"searchpathto\", \"search_value\")],\n",
    "    [State(\"searchpathto\", \"value\"),\n",
    "     State('searchpathfrom', 'value'),\n",
    "    State('cytoscape', 'elements')],\n",
    ")\n",
    "def searchpathto (search_value, value,_from,elements):\n",
    "    \n",
    "    if not search_value:\n",
    "        raise PreventUpdate\n",
    "    \n",
    "\n",
    "    res = []\n",
    "    for ele_data in comention_graph_cyto_elements:\n",
    "        \n",
    "        if 'label' in ele_data['style']:\n",
    "            label =ele_data['style']['label']\n",
    "            if (search_value in label) or (label in search_value) or ele_data['data']['id'] in (value or []) :\n",
    "                if ele_data['data']['id'] != _from:\n",
    "                    res.append( {\"label\":ele_data['style']['label'],\"value\":ele_data['data']['id']})\n",
    "  \n",
    "    return res\n",
    "\n",
    "@app_tab.callback(\n",
    "    Output(\"searchnodetotraverse\", \"options\"),\n",
    "    [Input(\"searchnodetotraverse\", \"search_value\")],\n",
    "    [State(\"searchnodetotraverse\", \"value\"),\n",
    "    State('searchpathfrom', 'value'),\n",
    "    State('searchpathto', 'value'),\n",
    "    State('cytoscape', 'elements')],\n",
    ")\n",
    "def searchpathtraverse (search_value, value,_from,to,elements):\n",
    "    \n",
    "    if not search_value:\n",
    "        raise PreventUpdate\n",
    "    \n",
    "\n",
    "    res = []\n",
    "    for ele_data in comention_graph_cyto_elements:\n",
    "        \n",
    "        if 'label' in ele_data['style']:\n",
    "            label =ele_data['style']['label']\n",
    "            if (search_value in label) or (label in search_value) or ele_data['data']['id'] in (value or []) :\n",
    "                if ele_data['data']['id'] != _from and ele_data['data']['id'] != to:\n",
    "                    res.append( {\"label\":label,\"value\":ele_data['data']['id']})\n",
    "  \n",
    "    return res\n",
    "\n",
    "@app_tab.callback(\n",
    "    Output(\"searchpathfrom\", \"options\"),\n",
    "    [Input(\"searchpathfrom\", \"search_value\")],\n",
    "    [State(\"searchpathfrom\", \"value\"),\n",
    "    State('cytoscape', 'elements')],\n",
    ")\n",
    "def searchpathfrom(search_value, value,elements):\n",
    "    \n",
    "    if not search_value:\n",
    "        raise PreventUpdate\n",
    "    \n",
    "\n",
    "    res = []\n",
    "    for ele_data in comention_graph_cyto_elements:\n",
    "        if 'label' in ele_data['style']:\n",
    "            label =ele_data['style']['label']\n",
    "            if (search_value in label) or (label in search_value) or ele_data['data']['id'] in (value or []) :\n",
    "                res.append( {\"label\":ele_data['style']['label'],\"value\":ele_data['data']['id']})\n",
    "  \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "@app_tab.callback(Output('nodefreqslider', 'value'),\n",
    "              [Input('bt-reset', 'n_clicks')],[State('nodefreqslider', 'value')])\n",
    "def display_freq_node(resetbt, nodefreqslider):\n",
    "    \n",
    "    \n",
    "    ctx = dash.callback_context\n",
    "\n",
    "    if not ctx.triggered:\n",
    "        button_id = 'No clicks yet'\n",
    "    else:\n",
    "        button_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "        \n",
    "    if button_id == 'bt-reset':\n",
    "        return 1\n",
    "\n",
    "@app_tab.callback(\n",
    "    [\n",
    "        Output('cytoscape', 'generateImage')\n",
    "    ],\n",
    "    [\n",
    "        Input('jpg-menu', 'n_clicks'),\n",
    "        Input('svg-menu', 'n_clicks'),\n",
    "        Input('png-menu', 'n_clicks')\n",
    "    ]\n",
    ")\n",
    "def download_image(jpg_menu,svg_menu,png_menu):\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        button_id = 'No clicks yet'\n",
    "    else:\n",
    "        button_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "    ftype  = None\n",
    "    if button_id == \"png-menu\":\n",
    "        ftype = \"png\"\n",
    "    if button_id == \"jpg-menu\":\n",
    "        ftype = \"jpg\"\n",
    "    if button_id == \"svg-menu\":\n",
    "        ftype = \"svg\"\n",
    "    return [{\n",
    "        'type': ftype,\n",
    "        'action': \"download\"\n",
    "    }]\n",
    "\n",
    "removed = set()\n",
    "from sqlalchemy.sql import select\n",
    "from sqlalchemy.sql import and_, or_, not_\n",
    "\n",
    "def list_papers (papers):\n",
    "    META_DATA = sqlalchemy.MetaData(bind=engine, reflect=True)\n",
    "    articles = META_DATA.tables[\"articles\"]\n",
    "    clauses = or_( *[articles.c.article_id==x for x in papers] )\n",
    "    s = select([articles.c.title,articles.c.authors,articles.c.abstract,articles.c.doi,articles.c.url,articles.c.journal,articles.c.pmcid,articles.c.pubmed_id,articles.c.publish_time]).where(\n",
    "       clauses\n",
    "       )\n",
    "    result = engine.execute(s)\n",
    "    results = []\n",
    "    for row in result:\n",
    "        results.append(row)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app_tab.callback(\n",
    "    [\n",
    "        Output('cytoscape', 'zoom'),\n",
    "        Output('cytoscape', 'elements')\n",
    "    ],\n",
    "    [\n",
    "        Input('bt-reset', 'n_clicks'),\n",
    "        Input('remove-button', 'n_clicks'),\n",
    "        Input('showgraph', 'value'),\n",
    "        Input('nodefreqslider', 'value'),\n",
    "        Input('node-freq-filter', 'value'),\n",
    "        Input(\"searchdropdown\", \"value\"),\n",
    "        Input('bt-path', 'n_clicks')\n",
    "     ],\n",
    "     [\n",
    "        State('cytoscape', 'elements'),\n",
    "        State('cytoscape', 'selectedNodeData'),\n",
    "        State('cytoscape', 'selectedEdgeData'),\n",
    "        State('cytoscape', 'tapNodeData'),\n",
    "        State('cytoscape', 'zoom'),\n",
    "        State('nodefreqslider', 'value'),\n",
    "        State('searchpathfrom', 'value'),\n",
    "        State('searchpathto', 'value'),\n",
    "        State('searchnodetotraverse', 'value'),\n",
    "        State('searchpathlimit', 'value')\n",
    "      ]\n",
    ")\n",
    "\n",
    "def reset_layout(resetbt, removebt, val, nodefreqslider, node_freq_operator,searchvalues,pathbt,cytoelements, data, edge,tappednode,zoom,nodefreqsliderstate, \n",
    "                 searchpathfrom, searchpathto,searchnodetotraverse,searchpathlimit):\n",
    "    global removed \n",
    "    elements = cytoelements\n",
    "    elements_dict  = {elt['data']['id']:elt for elt in cytoelements}\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        button_id = 'No clicks yet'\n",
    "    else:\n",
    "        button_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "    if button_id == 'showgraph':\n",
    "        if val == 'Knowledge Graph':\n",
    "            elements = knowledge_graph_cyto_elements\n",
    "            elements_dict = knowledge_graph_cyto_elements_dict\n",
    "        if val == 'Co-mention Graph':\n",
    "            elements = comention_graph_cyto_elements\n",
    "            elements_dict = comention_graph_cyto_elements_dict\n",
    "        \n",
    "            \n",
    "\n",
    "    if searchvalues is not None:\n",
    "        for searchvalue in searchvalues:\n",
    "            search_node = elements_dict[searchvalue]\n",
    "            search_node[\"selected\"]=True\n",
    "    \n",
    "    if nodefreqslider == 1:\n",
    "        if val == 'Knowledge Graph':\n",
    "            elements = knowledge_graph_cyto_elements\n",
    "            elements_dict = knowledge_graph_cyto_elements_dict\n",
    "        if val == 'Co-mention Graph':\n",
    "            elements = comention_graph_cyto_elements\n",
    "            elements_dict = comention_graph_cyto_elements_dict\n",
    "        \n",
    "            \n",
    "        zoom =1\n",
    "        global removed\n",
    "        removed = set()\n",
    "\n",
    "    if button_id == 'remove-button':\n",
    "        if elements and data:\n",
    "            ids_to_remove = {ele_data['id'] for ele_data in data}\n",
    "        if elements and edge:\n",
    "            ids_to_remove = {ele_data['id'] for ele_data in edge}\n",
    "            \n",
    "        elements = [ele for ele in elements if ele['data']['id'] not in ids_to_remove]\n",
    "\n",
    "        removed.update(ids_to_remove)\n",
    "    \n",
    "    if button_id == 'bt-path':\n",
    "        \n",
    "        if searchpathfrom and searchpathto:\n",
    "            topN = searchpathlimit if searchpathlimit else 20\n",
    "            searchpathfrom_dict = comention_graph_cyto_elements_dict[searchpathfrom]\n",
    "            searchpathto_dict = comention_graph_cyto_elements_dict[searchpathto]\n",
    "            \n",
    "            \n",
    "            if searchnodetotraverse:\n",
    "                searchnodetotraverse_dict = comention_graph_cyto_elements_dict[searchnodetotraverse]\n",
    "                paths = top_n_tripaths(graphs[\"paper\"], searchpathfrom_dict['style']['label'],searchnodetotraverse_dict['style']['label'], searchpathto_dict['style']['label'], topN, pretty_print=False)\n",
    "                \n",
    "            else:\n",
    "                paths = top_n_paths(graphs[\"paper\"], searchpathfrom_dict['style']['label'], searchpathto_dict['style']['label'], topN, pretty_print=False)\n",
    "            elements = []\n",
    "            \n",
    "            if paths:\n",
    "                elements.append(searchpathfrom_dict) \n",
    "                elements.append(searchpathto_dict)\n",
    "            for path in paths:\n",
    "                if str(path[1]).lower() in comention_graph_cyto_elements_label_dict:\n",
    "                    path_element = comention_graph_cyto_elements_label_dict[str(path[1]).lower()]\n",
    "                    elements.append(path_element)\n",
    "                else:\n",
    "                   \n",
    "                    try:\n",
    "                        result_df = linked_mention_df_unique.loc[str(path[1]).lower()]\n",
    "                        \n",
    "                        if len(result_df) > 0:\n",
    "                            node = result_df.uid\n",
    "                            path_element = create_node(node, label=result_df.concept, definition=result_df.definition)\n",
    "                            elements.append(path_element)\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "                path_element_id = path_element['data']['id']\n",
    "                edge_from_id = str(searchpathfrom).lower().replace(\" \",\"_\")+\"_\"+str(path_element_id).lower()\n",
    "                edge_from = create_edge(edge_from_id, searchpathfrom, path_element_id)\n",
    "                edge_to_id = str(searchpathto).lower().replace(\" \",\"_\")+\"_\"+str(path_element_id).lower()\n",
    "                edge_to = create_edge(edge_to_id, path_element_id, searchpathto)\n",
    "                \n",
    "                elements.append(edge_to)\n",
    "                elements.append(edge_from)\n",
    "                \n",
    "           \n",
    "\n",
    "   \n",
    "    if elements and (nodefreqslider is not None and button_id == 'nodefreqslider') :\n",
    "        \n",
    "        if val == 'Knowledge Graph':\n",
    "            elements = knowledge_graph_cyto_elements\n",
    "        if val == 'Co-mention Graph':\n",
    "            elements = comention_graph_cyto_elements\n",
    "       \n",
    "        ids_to_remove = [ele_data['data']['id'] for ele_data in elements if 'source' not in ele_data[\"data\"] and ele_data[\"data\"][\"id\"] not in removed and 'frequency' in ele_data['data'] and ele_data['data']['frequency'] is not None and not eval(node_freq_operator)(int(ele_data['data']['frequency']), int(nodefreqslider))]\n",
    "       \n",
    "        elements = [ele for ele in elements if ele['data']['id'] not in ids_to_remove]\n",
    "  \n",
    "    return zoom, elements\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app_tab.callback([Output('item-card-body', 'children')],\n",
    "                  [Input('cytoscape', 'tapNode'),Input('cytoscape', 'tapEdge')],\n",
    "                  [State('cytoscape', 'selectedNodeData'),State('cytoscape', 'selectedEdgeData')])\n",
    "def display_tap_node(datanode, dataedge,statedatanode,statedataedge):\n",
    "        \n",
    "\n",
    "    papers = []\n",
    "    res = []\n",
    "    modal_button = None\n",
    "    if datanode and statedatanode:\n",
    "        definition = \"\"\n",
    "        if 'definition' in str(datanode['data']):\n",
    "            definition = str(datanode['data']['definition'])\n",
    "        label = str(datanode['style']['label'])\n",
    "        _type = str(datanode['data']['type'])\n",
    "        frequency = str(datanode['data']['frequency'])\n",
    "        res.append([\n",
    "            html.H5(label, className=\"card-title\"),\n",
    "            html.H6(_type, className=\"card-subtitle\"),\n",
    "            html.P(\n",
    "                definition,\n",
    "                className=\"card-text\"\n",
    "            )\n",
    "            \n",
    "        ])\n",
    "        label = \"'\"+label+\"' mentioned in \"+frequency+\" papers\"\n",
    "        modal_button = dbc.Button(label, id=\"open-body-scroll\",color=\"primary\")\n",
    "        \n",
    "        papers= datanode['data']['papers']\n",
    "\n",
    "        \n",
    "    if dataedge and statedataedge:\n",
    "        label = str(dataedge['style']['label'])\n",
    "        \n",
    "        source_node = comention_graph_cyto_elements_dict[ dataedge['data']['source']]\n",
    "        source_label = source_node['style']['label']\n",
    "        target_node = comention_graph_cyto_elements_dict[ dataedge['data']['target']]\n",
    "        target_label = target_node['style']['label']\n",
    "        frequency = str(dataedge['data']['frequency'])\n",
    "        mention_label= ''' '%s' mentioned in %s papers with '%s' ''' % (source_label, frequency, target_label) \n",
    "        label = mention_label if str(dataedge['style']['label']) == \"\" else str(dataedge['style']['label']) \n",
    "        modal_button= dbc.Button(label, id=\"open-body-scroll\",color=\"primary\")\n",
    "    \n",
    "        papers= dataedge['data']['papers']\n",
    "       \n",
    "    if len(papers) > 0:\n",
    "        papers_in_kg = list_papers(papers)\n",
    "\n",
    "       \n",
    "        rows = []\n",
    "        \n",
    "        if papers_in_kg:\n",
    "            for paper in papers_in_kg:\n",
    "                title = paper[0] if paper[0] else ''\n",
    "                authors = paper[1] if paper[1] else ''\n",
    "                abstract = paper[2] if paper[2] else ''\n",
    "                journal = paper[5] if paper[5] else ''\n",
    "                url = paper[4] if paper[4] else ''\n",
    "                publish_time = str(paper[8]) if paper[8] else ''\n",
    "\n",
    "                abstract = (abstract[:500] + '...') if abstract and len(abstract) > 500 else abstract\n",
    "                \n",
    "                paper_card = dbc.Card(\n",
    "                                    dbc.CardBody(\n",
    "                                        [\n",
    "                                            html.H4(title, className=\"card-title\"),\n",
    "                                            html.H5(authors, className=\"card-subtitle\"),\n",
    "                                            \n",
    "                                            html.H6(journal+\"( \"+publish_time+\" )\", className=\"card-subtitle\"),\n",
    "                                            html.P(\n",
    "                                                abstract,\n",
    "                                                className=\"card-text\"\n",
    "                                            ),\n",
    "                                            dbc.Button(\"View the paper\", href=url,target=\"_blank\",color=\"primary\"),\n",
    "                                        ]\n",
    "                                    )\n",
    "                                )\n",
    "                rows.append(paper_card)\n",
    "\n",
    "            cards = dbc.Row(rows)        \n",
    "\n",
    "            modal = html.Div(\n",
    "            [\n",
    "                modal_button,\n",
    "\n",
    "                dbc.Modal(\n",
    "                    [\n",
    "                        dbc.ModalHeader(label),\n",
    "                        dbc.ModalBody(cards),            \n",
    "                        dbc.ModalFooter(\n",
    "                            dbc.Button(\n",
    "                                \"Close\", id=\"close-body-scroll\", className=\"ml-auto\"\n",
    "                            )\n",
    "                        ),\n",
    "                    ],\n",
    "                    id=\"modal-body-scroll\",\n",
    "                    scrollable=True,\n",
    "                    size=\"lg\"\n",
    "                ),\n",
    "            ]\n",
    "            )\n",
    "            if len(res) > 0:\n",
    "                res[0].append(modal)\n",
    "            else:\n",
    "                res.append(modal)\n",
    "    else:\n",
    "        \n",
    "        res = [html.H5(\"Select an item for details\", className=\"card-title\")]\n",
    "    \n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "@app_tab.callback(\n",
    "                  Output('cytoscape', 'layout'),\n",
    "                  [Input('dropdown-layout', 'value')],\n",
    "                  [State('showgraph', 'value')]\n",
    "                 )\n",
    "def update_cytoscape_layout(layout,showgraph):\n",
    "    \n",
    "    if layout==\"cose\":\n",
    "        return {\n",
    "                'name': layout,\n",
    "                'showlegend':True,\n",
    "                'idealEdgeLength': 100,\n",
    "                'nodeOverlap': 0,\n",
    "                'refresh': 20,\n",
    "                'fit': True,\n",
    "                'padding': 30,\n",
    "                'randomize': False,\n",
    "                'componentSpacing': 100,\n",
    "                'nodeRepulsion': 400000,\n",
    "                'edgeElasticity': 100,\n",
    "                'nestingFactor': 5,\n",
    "                'gravity': 80,\n",
    "                'numIter': 1000,\n",
    "                'initialTemp': 200,\n",
    "                'coolingFactor': 0.95,\n",
    "                'minTemp': 1.0\n",
    "\n",
    "        }\n",
    "    elif layout ==\"cola\":\n",
    "        return {\n",
    "          'name': layout,\n",
    "          'animate': True,\n",
    "          'refresh': 1,\n",
    "          'maxSimulationTime': 4000,\n",
    "          'ungrabifyWhileSimulating': False,\n",
    "          'fit': True, \n",
    "          'padding': 30,\n",
    "          \"groups\":[{\"leaves\":['http://purl.obolibrary.org/obo/ncit_c2271',\n",
    "                              'http://purl.obolibrary.org/obo/ncit_c3333', \n",
    "                              'http://purl.obolibrary.org/obo/ncit_c3193', \n",
    "                              'http://purl.obolibrary.org/obo/ncit_c124113', \n",
    "                              'http://purl.obolibrary.org/obo/ncit_c20506']\n",
    "                   }],\n",
    "          'nodeDimensionsIncludeLabels': False,\n",
    "          'randomize': False,\n",
    "          'avoidOverlap': True,\n",
    "          'handleDisconnected': True,\n",
    "          'convergenceThreshold': 0.01,\n",
    "          'nodeSpacing': 50\n",
    "        }\n",
    "    elif layout ==\"cose-bilkent\":\n",
    "        return {\n",
    "          'name': layout,\n",
    "          \"quality\": 'default',\n",
    "          \"refresh\": 30,\n",
    "          \"fit\": True,\n",
    "          \"padding\": 10,\n",
    "          \"randomize\": True,\n",
    "          \"nodeRepulsion\": 34500,\n",
    "          \"idealEdgeLength\": 50,\n",
    "          \"edgeElasticity\": 0.45,\n",
    "          \"nestingFactor\": 0.1,\n",
    "          \"gravity\": 50.25,\n",
    "          \"numIter\": 2500,\n",
    "          \"tile\": True,\n",
    "          \"tilingPaddingVertical\": 50,\n",
    "          \"tilingPaddingHorizontal\": 50,\n",
    "          \"gravityRangeCompound\": 1.5,\n",
    "          \"gravityCompound\": 2.0,\n",
    "          \"gravityRange\": 23.8,\n",
    "          \"initialEnergyOnIncremental\": 50.5\n",
    "        }\n",
    "    \n",
    "    else:    \n",
    "        return {\n",
    "            'name': layout,\n",
    "            'showlegend':True\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "@app_tab.callback(Output('cytoscape', 'stylesheet'),\n",
    "                  [Input('cytoscape', 'tapNode'),\n",
    "                   Input('cytoscape', 'selectedNodeData'),\n",
    "                   Input('input-follower-color', 'value'),\n",
    "                   Input('dropdown-node-shape', 'value'),\n",
    "                   Input('showgraph', 'value'),\n",
    "                   Input('node_freq_type', 'value')],\n",
    "                   [State('cytoscape', 'stylesheet'),\n",
    "                   State('showgraph', 'value')])\n",
    "def generate_stylesheet(node, selectedNodes,follower_color, node_shape, graphtype, node_freq_type, original_stylesheet,showgraph):\n",
    "    stylesheet  = original_stylesheet    \n",
    "   \n",
    "    \n",
    "    focus_nodes = []\n",
    "    \n",
    "    if selectedNodes:\n",
    "        \n",
    "        for selectedNode in selectedNodes:\n",
    "            focus_nodes.append(selectedNode)\n",
    "    if node is not None:\n",
    "        focus_nodes.append(node)\n",
    "        \n",
    "    if node_freq_type or node:\n",
    "        \n",
    "        stylesheet= [style for style in stylesheet if not (style[\"selector\"] == 'node' and 'width' in style[\"style\"])]\n",
    "        stylesheet.append({\n",
    "                \"selector\": 'node',\n",
    "                'style': {\n",
    "                    'shape': node_shape,\n",
    "                    'width':'data('+node_freq_type+')',\n",
    "                    'height':'data('+node_freq_type+')'\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "     \n",
    "    for focus_node in focus_nodes:      \n",
    "        node_style = [\n",
    "            {\n",
    "              \"selector\": \"node:selected\",\n",
    "              \"style\": {\n",
    "                \"border-width\": \"5px\",\n",
    "                \"border-color\": \"#AAD8FF\",\n",
    "                \"border-opacity\": \"0.5\"\n",
    "              }\n",
    "            }, \n",
    "            {\n",
    "                \"selector\": 'edge',\n",
    "                \"style\": {\n",
    "                    'curve-style': 'bezier',\n",
    "                    'line-color': '#D5DAE6'\n",
    "                }\n",
    "            },{\n",
    "                    \"selector\": 'node[id = \"{}\"]'.format(focus_node['data']['id'] if \"data\" in focus_node else focus_node['id']),\n",
    "                    \"style\": {\n",
    "                        \"border-width\": \"5px\",\n",
    "                        \"border-color\": \"#AAD8FF\",\n",
    "                        \"border-opacity\": \"0.5\",\n",
    "                        \"text-opacity\": 1,\n",
    "                        'z-index': 9999\n",
    "                    }\n",
    "                }]\n",
    "        for style in node_style:\n",
    "            stylesheet.append(style)\n",
    "        \n",
    "        \n",
    "        if \"edgesData\" in focus_node:\n",
    "            for edge in focus_node['edgesData']:\n",
    "                if edge['source'] == focus_node['data']['id'] if \"data\" in focus_node else focus_node['id']:\n",
    "                    stylesheet.append({\n",
    "                        \"selector\": 'node[id = \"{}\"]'.format(edge['target']),\n",
    "                        \"style\": {\n",
    "                            'opacity': 0.9\n",
    "                        }\n",
    "                    })\n",
    "                    stylesheet.append({\n",
    "                        \"selector\": 'edge[id= \"{}\"]'.format(edge['id']),\n",
    "                        \"style\": {\n",
    "                            \"mid-target-arrow-color\": follower_color['hex'],\n",
    "                            \"line-color\": follower_color['hex'],\n",
    "                            'opacity': 0.9,\n",
    "                            'z-index': 5000\n",
    "                        }\n",
    "                    })\n",
    "                if edge['target'] == focus_node['data']['id'] if \"data\" in focus_node else focus_node['id']:\n",
    "                    stylesheet.append({\n",
    "                        \"selector\": 'node[id = \"{}\"]'.format(edge['source']),\n",
    "                        \"style\": {\n",
    "                            'opacity': 0.9,\n",
    "                            'z-index': 9999\n",
    "                        }\n",
    "                    })\n",
    "                    stylesheet.append({\n",
    "                        \"selector\": 'edge[id= \"{}\"]'.format(edge['id']),\n",
    "                        \"style\": {\n",
    "                            \"mid-target-arrow-color\": follower_color['hex'],\n",
    "                            \"line-color\": follower_color['hex'],\n",
    "                            'opacity': 1,\n",
    "                            'z-index': 5000\n",
    "                        }\n",
    "                    })\n",
    "    return stylesheet\n",
    "\n",
    "\n",
    "app_tab.config['suppress_callback_exceptions']=True\n",
    "width = \"100%\"\n",
    "app_tab.height = \"800px\"\n",
    "app_tab.run_server(mode=\"jupyterlab\",width=width, port=\"8072\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version the knowledge graph\n",
    "The user can save a knowledge graph with a version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Temporally save the knowledge graph locally\n",
    "kg_ttl = knowledge_graph.serialize(format=\"turtle\",auto_compact=True)\n",
    "kg_ttl_filename = \"./kg_%s.ttl\" % (timestr)\n",
    "with open(kg_ttl_filename, 'wb') as outfile:\n",
    "        outfile.write(kg_ttl)\n",
    "\n",
    "        \n",
    "# Temporally save the extracted entities csv file locally\n",
    "table_extractions_filename = \"./table_extractions_%s.csv\" % (timestr)\n",
    "table_extractions.to_csv(table_extractions_filename)\n",
    "\n",
    "\n",
    "# Temporally save the curated list of extracted entities csv file locally\n",
    "curated_table_extractions_filename = \"./curated_table_extractions_%s.csv\" % (timestr)\n",
    "curated_table_extractions.to_csv(curated_table_extractions_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwt\n",
    "from kgforge.core import Resource\n",
    "from kgforge.specializations.resources import Dataset\n",
    "\n",
    "agent = jwt.decode(TOKEN,  verify=False)\n",
    "\n",
    "agent = forge.reshape(forge.from_json(agent), keep=[\"name\",\"email\",\"sub\",\"preferred_username\"])\n",
    "agent.id = agent.sub\n",
    "agent.type = \"Person\"\n",
    "\n",
    "dataset = Dataset(forge,name=\"A dataset\", about=topic_resource.name)\n",
    "dataset.add_distribution(kg_ttl_filename, content_type=\"application/x-turtle\")\n",
    "dataset.add_distribution(table_extractions_filename, content_type=\"application/csv\")\n",
    "dataset.add_distribution(curated_table_extractions_filename, content_type=\"application/csv\")\n",
    "dataset.add_contribution(agent)\n",
    "dataset.contribution.hadRole= \"Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = agent.preferred_username+\"_\"+timestr\n",
    "\n",
    "def register_dataset(b):\n",
    "    output4.clear_output()\n",
    "    output5.clear_output()\n",
    "    dataset.name = t1.value\n",
    "    dataset.description = t2.value\n",
    "    forge.register(dataset)\n",
    "    if dataset._last_action.succeeded == True:\n",
    "        with output4:\n",
    "            print(\"Dataset registered!\")\n",
    "    else:\n",
    "        with output4:\n",
    "            print(dataset._last_action.message)\n",
    "\n",
    "def version_dataset(b):\n",
    "    output5.clear_output()\n",
    "    version = t3.value\n",
    "    forge.tag(dataset,version)\n",
    "    if dataset._last_action.succeeded == True:\n",
    "        with output5:\n",
    "            print(f\"Tagged with: {str(version)}\")\n",
    "    \n",
    "output4 = ipywidgets.Output()\n",
    "output5 = ipywidgets.Output()\n",
    "\n",
    "b1 = ipywidgets.Button(\n",
    "    description= '💾  Register Dataset',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "\n",
    "b2 = ipywidgets.Button(\n",
    "    description= '🔖 Tag Dataset',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "\n",
    "t1 = ipywidgets.Text(\n",
    "    placeholder='Add a name for your dataset',\n",
    "    description='Name:',\n",
    "    disabled=False)\n",
    "\n",
    "t2 = ipywidgets.Textarea(\n",
    "    placeholder='Add a description of your dataset',\n",
    "    description='Description:',\n",
    "    disabled=False)\n",
    "\n",
    "t3 = ipywidgets.Text(\n",
    "    description='Tag:',\n",
    "    value=version,\n",
    "    disabled=False)\n",
    "\n",
    "b1.on_click(register_dataset)\n",
    "b2.on_click(version_dataset)\n",
    "\n",
    "save_widget = ipywidgets.VBox(children=[t1, t2, b1, output4, t3, b2, output5])\n",
    "\n",
    "display(save_widget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BBS-BBG",
   "language": "python",
   "name": "devel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
