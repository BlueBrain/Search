{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODOs**\n",
    "- [ ] The trained SciBERT model `scibert_chemprot.tar.gz` stores inside itself \n",
    "  absolute paths to vocabulary text and weights! So it cannot be move around\n",
    "  without rewriting its metadata inside.\n",
    "- [ ] SciBERT can not be obtained with `pip install`, so currently one needs to \n",
    "    1. `git clone https://github.com/allenai/scibert.git`\n",
    "    2. `export PYTHONPATH=$PYTHONPATH:PATH_TO_SCIBERT`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import IPython\n",
    "import ipywidgets\n",
    "import pandas as pd\n",
    "import scispacy\n",
    "import spacy\n",
    "\n",
    "from bbsearch.mining import ChemProt, run_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BlueBrainSearch to BlueBrainGraph: POC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how from raw text we can apply BlueBrainSearch and then BlueBrainGraph tools in order to generate first a list of extracted objects of interest, and then a knowledge graph out of it.\n",
    "\n",
    "It is intended to be just a proof of concept of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BlueBrainSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first part of the pipeline starts with the raw text of a scientific paper as an input, and generates a CSV table out of it. The table contains all the extracted entities and relations that were identified in the text.\n",
    "- **input**: raw text\n",
    "- **output**: csv table of extracted entities/relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TEXT = \"\"\"Autophagy maintains tumour growth through circulating\n",
    "arginine. Autophagy captures intracellular components and delivers them to\n",
    "lysosomes, where they are degraded and recycled to sustain metabolism and to\n",
    "enable survival during starvation. Acute, whole-body deletion of the essential \n",
    "autophagy gene Atg7 in adult mice causes a systemic metabolic defect that \n",
    "manifests as starvation intolerance and gradual loss of white adipose tissue, \n",
    "liver glycogen and muscle mass.  Cancer cells also benefit from autophagy. \n",
    "Deletion of essential autophagy genes impairs the metabolism, proliferation, \n",
    "survival and malignancy of spontaneous tumours in models of autochthonous \n",
    "cancer. Acute, systemic deletion of Atg7 or acute, systemic expression of a \n",
    "dominant-negative ATG4b in mice induces greater regression of KRAS-driven \n",
    "cancers than does tumour-specific autophagy deletion, which suggests that host \n",
    "autophagy promotes tumour growth.\n",
    "\"\"\".replace('\\n', ' ').replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entities Extractors (EE)\n",
    "ee_model = spacy.load(\"en_ner_craft_md\")\n",
    "\n",
    "# Relations Extractors (RE)\n",
    "PATH_ASSETS = Path('/raid/covid_data/assets')\n",
    "PATH_CHEMPROT_TRAINED_MODEL = PATH_ASSETS / 'scibert_chemprot.tar.gz'\n",
    "re_models = {('CHEBI', 'GGP'): [ChemProt(PATH_CHEMPROT_TRAINED_MODEL)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Widgets\n",
    "bbs_widgets = OrderedDict()\n",
    "\n",
    "# \"Input Text\" Widget\n",
    "bbs_widgets['input_text'] = ipywidgets.Textarea(\n",
    "        value=DEFAULT_TEXT,\n",
    "        layout=ipywidgets.Layout(width='75%', height='300px')\n",
    "    )\n",
    "\n",
    "# \"Submit!\" Button\n",
    "bbs_widgets['submit_button'] = ipywidgets.Button(\n",
    "    description='Extract Entities & Properties!',\n",
    "    layout=ipywidgets.Layout(width='30%')\n",
    ")\n",
    "def cb(b):\n",
    "    bbs_widgets['out'].clear_output()\n",
    "    with bbs_widgets['out']:\n",
    "        text = bbs_widgets['input_text'].value\n",
    "        table_extractions = run_pipeline(text, ee_model, re_models, return_prob=True)\n",
    "        display(table_extractions)\n",
    "bbs_widgets['submit_button'].on_click(cb)\n",
    "\n",
    "# \"Output Area\" Widget\n",
    "bbs_widgets['out'] = ipywidgets.Output(layout={'border': '0.5px solid black'})\n",
    "\n",
    "# Finalize Widgets\n",
    "ordered_widgets = list(bbs_widgets.values())\n",
    "main_widget = ipywidgets.VBox(ordered_widgets)\n",
    "IPython.display.display(main_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BlueBrainGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second part of the pipeline starts with the extracted entities and relations in a CSV table, and generates a knowledge graph out of it.\n",
    "\n",
    "- **input**: csv table of extracted entities/relations\n",
    "- **output**: knowledge graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
