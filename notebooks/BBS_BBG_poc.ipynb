{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of the notebook\n",
    "End to end pipeline for searching articles of interest, extracting entities of interest, building, accessing and deploying a knowled graph and a co-mention graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import ipywidgets\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy.sql import select\n",
    "from sqlalchemy.sql import and_, or_, not_\n",
    "\n",
    "from bbsearch.widgets import ArticleSaver, MiningSchema, MiningWidget, SearchWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash.comms import _send_jupyter_config_comm_request, _jupyter_config\n",
    "from jupyter_dash import JupyterDash\n",
    "\n",
    "import dash_cytoscape as cyto\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JupyterDash configs\n",
    "_send_jupyter_config_comm_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "JupyterDash.infer_jupyter_proxy_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto.load_extra_layouts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash_core_components as dcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cord_analytics.utils import (generate_curation_table,\n",
    "                                  link_ontology,\n",
    "                                  generate_comention_analysis,\n",
    "                                  build_cytoscape_data,\n",
    "                                  merge_with_ontology_linking,\n",
    "                                  resolve_taxonomy_to_types)\n",
    "            \n",
    "from bbg_apps.curation_app import (curation_app)\n",
    "from bbg_apps.visualization_app import (visualization_app)\n",
    "\n",
    "from kganalytics.export import load_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set a Project\n",
    "\n",
    "The user chooses / creates a project to host a KG.\n",
    "\n",
    "* Use the [Nexus web application](https://bbp.epfl.ch/nexus/web) to get a token.\n",
    "* Once a token is obtained then proceed to paste it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "TOKEN = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kgforge.core import KnowledgeGraphForge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a 'forge' to manage (create, access and deploy) the knowledge graph within a given Blue Brain Nexus Project.\n",
    "FORGE_CONFIG_FILE = os.getenv(\"FORGE_CONFIG_FILE\") \n",
    "assert (FORGE_CONFIG_FILE is not None) \n",
    "forge = KnowledgeGraphForge(FORGE_CONFIG_FILE,token=TOKEN, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set topic\n",
    "The user defines a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwt\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_resource=None\n",
    "kg_resource=None\n",
    "agent_username = jwt.decode(TOKEN,  verify=False)['preferred_username']\n",
    "\n",
    "def save_topic(b):\n",
    "    output.clear_output()\n",
    "    output2.clear_output()\n",
    "    output3.clear_output()\n",
    "    topic_to_save = {\n",
    "        'id': str(widget.children[1].children[0].value).replace(' ', '_'),\n",
    "        'type': 'Topic',\n",
    "        'name': widget.children[1].children[0].value,\n",
    "        'field': widget.children[1].children[1].value,\n",
    "        'description': widget.children[1].children[2].value,\n",
    "        'keywords': widget.children[1].children[3].value,\n",
    "        'question':  [widget.children[1].children[i].value for i in range(5,9)]\n",
    "    }\n",
    "    global topic_resource\n",
    "    topic_resource = forge.from_json(topic_to_save)\n",
    "    forge.register(topic_resource)\n",
    "    with output2:\n",
    "        if w1.value == \"\":\n",
    "            print(\"Please provide a topic name\")\n",
    "        else:\n",
    "            print(\"Topic saved!\")\n",
    "            w1.value = \"\"\n",
    "            w2.value = \"\"\n",
    "            w3.value = \"\"\n",
    "            w4.value = \"\"\n",
    "            w5.value = \"\"\n",
    "            w6.value = \"\"\n",
    "            w7.value = \"\"\n",
    "            w8.value = \"\"\n",
    "\n",
    "def get_topics(b):\n",
    "    output.clear_output()\n",
    "    output2.clear_output()\n",
    "    output3.clear_output()\n",
    "    query = f\"\"\"\n",
    "    SELECT ?id ?name ?description ?keywords ?field ?question ?createdAt\n",
    "    WHERE {{\n",
    "        ?id a Topic ;\n",
    "            name ?name ;\n",
    "            description ?description ;\n",
    "            keywords ?keywords ;\n",
    "            field ?field ;\n",
    "            question ?question ;\n",
    "            <https://bluebrain.github.io/nexus/vocabulary/deprecated> false ;\n",
    "            <https://bluebrain.github.io/nexus/vocabulary/createdAt> ?createdAt ;\n",
    "            <https://bluebrain.github.io/nexus/vocabulary/createdBy> <{forge._store.endpoint}/realms/bbp/users/{agent_username}> .\n",
    "    }}\n",
    "    \"\"\"\n",
    "    resources = forge.sparql(query, limit=100)\n",
    "    if len(resources) >= 1:\n",
    "        global topics_df\n",
    "        topics_df = forge.as_dataframe(resources)\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            topics_list = list(set(topics_df.name))\n",
    "            topics_list.sort()\n",
    "            w0.options = [\"\"] + topics_list\n",
    "            w0.value = \"\"\n",
    "            w0.placeholder = \"Select topic\"\n",
    "            w0.observe(topics_change, names='value')\n",
    "            display(w0)\n",
    "            display(s12)\n",
    "    else:\n",
    "        with output:\n",
    "            print(\"No topics found!\")\n",
    "\n",
    "def topics_change(change):\n",
    "    output3.clear_output()\n",
    "    with output:\n",
    "        if len(output.outputs) >= 1:\n",
    "            output.outputs = (output.outputs[0],)\n",
    "        s5.value = \"\"\n",
    "        s6.value = \"\"\n",
    "        s7.value = \"\"\n",
    "        s8.value = \"\"\n",
    "        s9.value = \"\"\n",
    "        s10.value = \"\"\n",
    "        s11.value = \"\"\n",
    "        global topic_resource\n",
    "        if change['new'] != \"\":\n",
    "            topic_resource = forge.retrieve(list(set(topics_df[topics_df.name == change['new']].id))[0])\n",
    "            s5.value = topic_resource.field\n",
    "            s6.value = topic_resource.description\n",
    "            s7.value = topic_resource.keywords\n",
    "            question = topic_resource.question\n",
    "            if isinstance(question, str):\n",
    "                question = [question]\n",
    "            if isinstance(question, list):\n",
    "                for i in range(len(question)):\n",
    "                    sq.children[i].value = question[i]            \n",
    "        display(s12)\n",
    "\n",
    "def update_topic(b):\n",
    "    output2.clear_output()\n",
    "    if w0.value != \"\":\n",
    "        topic_resource.id = forge.as_jsonld(topic_resource, form=\"expanded\")['@id']\n",
    "        topic_resource.field = s5.value\n",
    "        topic_resource.description = s6.value\n",
    "        topic_resource.keywords = s7.value\n",
    "        topic_resource.question = [sq.children[i].value for i in range(0,4)]\n",
    "        forge.update(topic_resource)\n",
    "        with output:\n",
    "            print(\"topic updated!\")\n",
    "        \n",
    "def get_datasets(b):\n",
    "    output3.clear_output()\n",
    "    if w0.value != \"\":\n",
    "        topic_resource_id = forge.as_jsonld(topic_resource, form=\"expanded\")['@id']\n",
    "        query = f\"\"\"\n",
    "            SELECT ?id ?name ?description ?keywords ?field ?question ?createdAt\n",
    "            WHERE {{\n",
    "                ?id a Dataset ;\n",
    "                    name ?name ;\n",
    "                    about <{topic_resource_id}> ;\n",
    "                    <https://bluebrain.github.io/nexus/vocabulary/deprecated> false ;\n",
    "                    <https://bluebrain.github.io/nexus/vocabulary/createdAt> ?createdAt ;\n",
    "                    <https://bluebrain.github.io/nexus/vocabulary/createdBy> <{forge._store.endpoint}/realms/bbp/users/{agent_username}> .\n",
    "            }}\n",
    "            \"\"\"\n",
    "        global kg_resources\n",
    "        kg_resources = forge.sparql(query, limit=100, debug=True)\n",
    "        print(len(kg_resources))\n",
    "        if len(kg_resources) >= 1:\n",
    "            with output3:\n",
    "                display(s2)\n",
    "                s2.options = [r.name for r in kg_resources]\n",
    "                display(s3)\n",
    "        else:\n",
    "            with output3:\n",
    "                print(\"No datasets found!\")\n",
    "        \n",
    "def download_dataset(b):\n",
    "    resource_id = [r.id for r in kg_resources if r.name == s2.value][0]\n",
    "    global kg_resource\n",
    "    global table_extractions\n",
    "    kg_resource = forge.retrieve(resource_id)\n",
    "    forge.download(kg_resource, \"distribution.contentUrl\", \"/tmp/\", overwrite=True)\n",
    "    for r in kg_resource.distribution:\n",
    "        if \"curated\" in r.name:\n",
    "            table_extractions = pd.read_csv(f\"/tmp/{r.name}\")\n",
    "            if table_extractions is not None:\n",
    "                message = f\"Dataset '{r.name}' with {len(table_extractions)} entities ready to be reused. Its content has been assigned to the variable 'table_extractions'. Please continue with the interactive UI section to visualise this dataset.\"\n",
    "            else:\n",
    "                table_extractions = pd.DataFrame()\n",
    "                message = \"No dataset has been downloaded\"\n",
    "            with output3:\n",
    "                print(message)\n",
    "\n",
    "s0 = ipywidgets.Button(\n",
    "    description= 'ðŸ”¬ List all your topics',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s1 = ipywidgets.Button(\n",
    "    description= \"ðŸ“ƒ Show datasets for selected topic\",\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s2 = ipywidgets.RadioButtons(\n",
    "    description='Select:',\n",
    "    disabled=False)\n",
    "s3 = ipywidgets.Button(\n",
    "    description= 'ðŸ“ˆ Reuse selected dataset',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s4 = ipywidgets.Button(\n",
    "    description= 'âœï¸ Update topic',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s5 = ipywidgets.Text(\n",
    "    description='Field:',\n",
    "    disabled=False)\n",
    "s6 = ipywidgets.Textarea(\n",
    "    description='Description:',\n",
    "    disabled=False)\n",
    "s7 = ipywidgets.Textarea(\n",
    "    description='Keywords:',\n",
    "    disabled=False)\n",
    "s8 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "s9 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "s10 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "s11 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "\n",
    "sq = ipywidgets.VBox(children=[s8, s9, s10, s11])\n",
    "\n",
    "s12 = ipywidgets.VBox(children=[s5, s6, s7, ipywidgets.Label('Questions:'), sq, s4])\n",
    "\n",
    "w0 = ipywidgets.Dropdown(\n",
    "        description='Select topic:',\n",
    "        disabled=False)\n",
    "w1 = ipywidgets.Text(\n",
    "    placeholder='e.g. COVID-19',\n",
    "    description='Topic name:',\n",
    "    disabled=False)\n",
    "w2 = ipywidgets.Text(\n",
    "    placeholder='e.g. Neuroscience',\n",
    "    description='Field:',\n",
    "    disabled=False)\n",
    "w3 = ipywidgets.Textarea(\n",
    "    placeholder='Add a description of your topic',\n",
    "    description='Description:',\n",
    "    disabled=False)\n",
    "w4 = ipywidgets.Textarea(\n",
    "    placeholder='e.g. Coronavirus; COVID-19; SARS; risk factor; glycosylation; sugar; carbohydrates',\n",
    "    description='Keywords:',\n",
    "    disabled=False)\n",
    "w5 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w6 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w7 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w8 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w9 = ipywidgets.Button(\n",
    "    description='Create',\n",
    "    button_style='',\n",
    "    tooltip='Create new topic',\n",
    "    disabled=False)\n",
    "\n",
    "output = ipywidgets.Output()\n",
    "output2 = ipywidgets.Output()\n",
    "output3 = ipywidgets.Output()\n",
    "\n",
    "buttons = ipywidgets.HBox(children=[s0, s1])\n",
    "outputs = ipywidgets.HBox(children=[output, output3])\n",
    "tab1 = ipywidgets.VBox(children=[buttons, outputs])\n",
    "tab2 = ipywidgets.VBox(children=[w1, w2, w3, w4, ipywidgets.Label('Please express your research topic in a few questions:'), w5, w6, w7, w8, w9, output2])\n",
    "widget = ipywidgets.Tab(children=[tab1, tab2])\n",
    "widget.set_title(0, 'Select topic')\n",
    "widget.set_title(1, 'Create topic')\n",
    "\n",
    "w9.on_click(save_topic)\n",
    "s0.on_click(get_topics)\n",
    "s1.on_click(get_datasets)\n",
    "s3.on_click(download_dataset)\n",
    "s4.on_click(update_topic)\n",
    "\n",
    "display(widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import\n",
    "The user loads data from a data source (CORD-19). The loaded data forms the corpus. The user searches the CORPUS in Blue Brain Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search server URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_ENGINE_URL = os.getenv(\"SEARCH_ENGINE_URL\", \"http://dgx1.bbp.epfl.ch:8850\")\n",
    "assert SEARCH_ENGINE_URL is not None\n",
    "\n",
    "response = requests.post(\"{}/help\".format(SEARCH_ENGINE_URL))\n",
    "assert response.ok and response.json()['name'] == 'SearchServer', \"The server is not accessible\"\n",
    "print(f\"This server is using the database: {response.json()['database']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MySQL URL and engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYSQL_DB_URI = os.getenv(\"MYSQL_DB_URI\", \"dgx1.bbp.epfl.ch:8853\")\n",
    "bbs_mysql_engine = sqlalchemy.create_engine(f'mysql+pymysql://guest:guest@{MYSQL_DB_URI}/cord19_v47')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Article saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_saver = ArticleSaver(connection=bbs_mysql_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_widget = SearchWidget(\n",
    "    bbs_search_url=SEARCH_ENGINE_URL,\n",
    "    bbs_mysql_engine=bbs_mysql_engine,\n",
    "    article_saver=article_saver,\n",
    "    results_per_page=3)\n",
    "search_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show saved articles and paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = search_widget.saved_results()\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"For information: \\n \n",
    "      - The query showed {len(df_results['Article ID'].unique())} different articles.\n",
    "      - Saved {len(df_results[(df_results['Paragraph']=='âœ“') & (df_results['Article'] != 'âœ“')])} paragraph(s)\n",
    "      - Saved {len(df_results[df_results['Article']=='âœ“']['Article ID'].unique())} article(s)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set schemas\n",
    "The user defines the KG schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mining_schema = MiningSchema()\n",
    "\n",
    "mining_schema.add_entity(\"CELL_COMPARTMENT\")\n",
    "mining_schema.add_entity(\"CELL_TYPE\")\n",
    "mining_schema.add_entity(\"CHEMICAL\", ontology_source=\"NCIT\")\n",
    "mining_schema.add_entity(\"CONDITION\")\n",
    "mining_schema.add_entity(\"DISEASE\", ontology_source=\"NCIT\")\n",
    "mining_schema.add_entity(\"DRUG\")\n",
    "mining_schema.add_entity(\"ORGAN\", ontology_source=\"NCIT\")\n",
    "mining_schema.add_entity(\"ORGANISM\", ontology_source=\"NCIT\")\n",
    "mining_schema.add_entity(\"PATHWAY\", ontology_source=\"Reactome\")\n",
    "mining_schema.add_entity(\"PROTEIN\", ontology_source=\"NCIT\")\n",
    "\n",
    "mining_schema.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a knowledge graph according to schemas\n",
    "The user extracts data from the text of a set of papers using selected Named Entity Recognizers and Relation Extractors from Blue Brain Search.\n",
    "The user can preview the extracted data.\n",
    "The user curates extracted data.\n",
    "The user links the extracted entities and relations to ontologies.\n",
    "The user saves data into Knowledge Graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **input**: raw text\n",
    "- **output**: csv table of extracted entities/relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TEXT = \"\"\"Autophagy maintains tumour growth through circulating\n",
    "arginine. Autophagy captures intracellular components and delivers them to\n",
    "lysosomes, where they are degraded and recycled to sustain metabolism and to\n",
    "enable survival during starvation. Acute, whole-body deletion of the essential \n",
    "autophagy gene Atg7 in adult mice causes a systemic metabolic defect that \n",
    "manifests as starvation intolerance and gradual loss of white adipose tissue, \n",
    "liver glycogen and muscle mass. Cancer cells also benefit from autophagy. \n",
    "Deletion of essential autophagy genes impairs the metabolism, proliferation, \n",
    "survival and malignancy of spontaneous tumours in models of autochthonous \n",
    "cancer. Acute, systemic deletion of Atg7 or acute, systemic expression of a \n",
    "dominant-negative ATG4b in mice induces greater regression of KRAS-driven \n",
    "cancers than does tumour-specific autophagy deletion, which suggests that host \n",
    "autophagy promotes tumour growth.\n",
    "\"\"\".replace('\\n', ' ').replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_MINING_URL = os.getenv(\"TEXT_MINING_URL\", \"http://dgx1.bbp.epfl.ch:8852\")\n",
    "response = requests.post(TEXT_MINING_URL + \"/help\")\n",
    "assert response.ok and response.json()['name'] == 'MiningServer'\n",
    "print(f\"This server is using the database: {response.json()['database']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mining_widget = MiningWidget(\n",
    "    mining_server_url=TEXT_MINING_URL,\n",
    "    mining_schema=mining_schema,\n",
    "    article_saver=article_saver,\n",
    "    default_text=DEFAULT_TEXT)\n",
    "mining_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrame of extractions\n",
    "table_extractions = mining_widget.get_extracted_table()\n",
    "\n",
    "# Drop duplicates in DataFrame\n",
    "columns_duplicates = table_extractions.columns.tolist()\n",
    "columns_duplicates.remove('entity_type')\n",
    "table_extractions = table_extractions.drop_duplicates(subset=columns_duplicates, keep='first', ignore_index=True)\n",
    "table_extractions = table_extractions.dropna(subset=[\"entity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate the table with extracted entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **input**: csv table of extracted entities/relations\n",
    "- **output**: csv table with curated and ontology linked entities/relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The table has {table_extractions.shape[0]} rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Setting default term filters: the user can remove them later on in the UI if need be ...\")\n",
    "default_term_filters = 'Glucose; Covid-19; SARS-CoV-2; Diabetes; IL-1; ACE2; glycosylation; hyperglycemia; shock; fatigue; CVD; vasoconstriction; lactate; insulin; SP-D; HbA1c; LDH; glycolysis; GLUT; macrophage; lymphocytes; ventilation;SARS; ARDS; Cytokine Storm; pneumonia; multi-organs failure; thrombosis; inflammation; IL-6; CRP; D-Dimer; Ferritin; Lung Disease; Hypertension; Aging; COPD; angiotensin 2 (or angiotensin II or AngII); Obesity; ICU (intensive care unit); ventilation; ketogenic diet'.split(\"; \")\n",
    "filtered_table_extractions = table_extractions.copy()\n",
    "\n",
    "default_found_term_filters = set() \n",
    "for term_filter in default_term_filters:\n",
    "    entities_to_keep = filtered_table_extractions[\n",
    "        filtered_table_extractions[\"entity\"].apply(lambda x: x.lower() == term_filter.lower())][\"entity\"].unique()\n",
    "    if entities_to_keep is not None and len(entities_to_keep) > 0:\n",
    "        default_found_term_filters.add(tuple(entities_to_keep))\n",
    "term_filter_options = [term_filter[0] for term_filter in default_found_term_filters]\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Prepating curatation data...\")\n",
    "curation_input_table, factor_counts = generate_curation_table(filtered_table_extractions)\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Loading the ontology linking data...\")\n",
    "linking = pd.read_pickle(\"/gpfs/bbp.cscs.ch/project/proj116/network_analytics/data/cord_47_linking.pkl\")\n",
    "definitions = linking[[\"concept\", \"definition\"]].groupby(\"concept\").aggregate(lambda x: list(x)[0]).to_dict()[\"definition\"]\n",
    "\n",
    "print(\"Loading default ontology type mapping...\")\n",
    "with open('/gpfs/bbp.cscs.ch/project/proj116/bbg/ontology-linking/ncit_to_mltypes_mapping.json', \"rb\") as f:\n",
    "    default_type_mapping = json.load(f)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the curation app. In case of the error 'Address already in use', try specifying another port (for example, in the range 8072-8099)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_app.set_default_terms_to_include(term_filter_options)\n",
    "curation_app.set_table(curation_input_table.copy())\n",
    "curation_app.set_ontology_linking_callback(lambda x: link_ontology(linking, default_type_mapping, x))\n",
    "\n",
    "curation_app.run(port=8071)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a co-mention graph from curated entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **input**: csv table with curated and ontology linked entities/relations\n",
    "- **output**: graph objects with co-occurrence network and its spanning tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_table_extractions = curation_app.get_curated_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_table_extractions[\"paper\"] = curated_table_extractions[\"paper\"].apply(lambda x: set(x))\n",
    "curated_table_extractions[\"paragraph\"] = curated_table_extractions[\"paragraph\"].apply(lambda x: set(x))\n",
    "curated_table_extractions[\"section\"] = curated_table_extractions[\"section\"].apply(lambda x: set(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a co-mention network from curated table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_data = curated_table_extractions[[\"entity_type\"]].rename(columns={\"entity_type\": \"type\"})\n",
    "n_most_frequent = curation_app.n_most_frequent if curation_app.n_most_frequent else 100\n",
    "graphs, trees = generate_comention_analysis(\n",
    "    curated_table_extractions, factor_counts, n_most_frequent=n_most_frequent, type_data=type_data, factors=[\"paper\", \"paragraph\"], cores=10)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cytoscape_graphs = dict()\n",
    "for f in [\"paper\", \"paragraph\"]:\n",
    "    cytoscape_graphs[f] = {\n",
    "        \"tree\": build_cytoscape_data(trees[f]),\n",
    "        \"graph\": build_cytoscape_data(graphs[f])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "prefix = \"/gpfs/bbp.cscs.ch/project/proj116/network_analytics/data/graphs/cord_47/full_3000\"\n",
    "\n",
    "print(\"Loading pre-generated graphs with 3'000 entities...\")\n",
    "print(\"\\t - paper-based network\")\n",
    "paper_graph = load_network(\"{}_paper_edge_list.pkl\".format(prefix), \"{}_paper_node_list.pkl\".format(prefix))\n",
    "paper_spanning_tree = load_network(\"{}_paper_tree_edge_list.pkl\".format(prefix), \"{}_paper_tree_node_list.pkl\".format(prefix))\n",
    "nx.set_node_attributes(\n",
    "    paper_spanning_tree, {\n",
    "        n: len(paper_spanning_tree.nodes[n][\"paper\"])\n",
    "        for n in paper_spanning_tree.nodes()\n",
    "    },\n",
    "    \"paper_frequency\")\n",
    "\n",
    "print(\"\\t - paragraph-based network\")\n",
    "paragraph_graph = load_network(\"{}_paragraph_edge_list.pkl\".format(prefix), \"{}_paragraph_node_list.pkl\".format(prefix))\n",
    "paragraph_spanning_tree = load_network(\"{}_paragraph_tree_edge_list.pkl\".format(prefix), \"{}_paragraph_node_list.pkl\".format(prefix))\n",
    "nx.set_node_attributes(\n",
    "    paragraph_spanning_tree, {\n",
    "        n: len(paragraph_spanning_tree.nodes[n][\"paper\"])\n",
    "        for n in paragraph_spanning_tree.nodes()\n",
    "    },\n",
    "    \"paper_frequency\")\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Loading pre-computed node positions...\")\n",
    "with open(\"/gpfs/bbp.cscs.ch/project/proj116/network_analytics/data/positions/paper_3000.json\", \"r\") as f:\n",
    "    paper_positions = json.load(f)\n",
    "\n",
    "with open(\"/gpfs/bbp.cscs.ch/project/proj116/network_analytics/data/positions/paragraph_3000.json\", \"r\") as f:\n",
    "    paragraph_positions = json.load(f)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert pre-computed graphs to a cytoscape format + add node positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_3000_cyto = build_cytoscape_data(paper_spanning_tree, positions=paper_positions)\n",
    "paragraph_3000_cyto = build_cytoscape_data(paragraph_spanning_tree, positions=paragraph_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_3000_cyto = build_cytoscape_data(paper_spanning_tree, positions=paper_positions)\n",
    "paragraph_3000_cyto = build_cytoscape_data(paragraph_spanning_tree, positions=paragraph_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_papers(papers, limit=200):\n",
    "    META_DATA = sqlalchemy.MetaData(bind=bbs_mysql_engine, reflect=True)\n",
    "    articles = META_DATA.tables[\"articles\"]\n",
    "    clauses = or_( *[articles.c.article_id == x for x in papers[:limit]] )\n",
    "    s = select([\n",
    "        articles.c.title,\n",
    "        articles.c.authors,\n",
    "        articles.c.abstract,\n",
    "        articles.c.doi,\n",
    "        articles.c.url,\n",
    "        articles.c.journal,\n",
    "        articles.c.pmcid,\n",
    "        articles.c.pubmed_id,\n",
    "        articles.c.publish_time\n",
    "    ]).where(clauses)\n",
    "    result = bbs_mysql_engine.execute(s)\n",
    "    results = []\n",
    "    for row in result:\n",
    "        results.append(row)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH_OBJECTS = {\n",
    "    \"Topic-centered network (paper-based)\": {\n",
    "        \"graph\": graphs[\"paper\"],\n",
    "        \"tree\": trees[\"paper\"],\n",
    "        \"default_top_n\": 100\n",
    "    },\n",
    "    \"Topic-centered network (paragraph-based)\": {\n",
    "        \"graph\": graphs[\"paragraph\"],\n",
    "        \"tree\": trees[\"paragraph\"],\n",
    "        \"default_top_n\": 100\n",
    "    },\n",
    "    \"Naive pre-computed network (paper-based, 3000)\": {\n",
    "        \"graph\": paper_graph,\n",
    "        \"tree\": paper_spanning_tree,\n",
    "        \"positions\": paper_positions\n",
    "    },\n",
    "    \"Naive pre-computed network (paragraph-based, 3000)\": {\n",
    "        \"graph\": paragraph_graph,\n",
    "        \"tree\": paragraph_spanning_tree,\n",
    "        \"positions\": paragraph_positions,\n",
    "    }\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in GRAPH_OBJECTS.items():\n",
    "    tree = v[\"tree\"] if \"tree\" in v else None\n",
    "    positions = v[\"positions\"] if \"positions\" in v else None  \n",
    "    default_top_n = v[\"default_top_n\"] if \"default_top_n\" in v else None\n",
    "    visualization_app.set_graph(\n",
    "        k, v[\"graph\"], tree_object=tree, positions=positions, default_top_n=default_top_n)\n",
    "\n",
    "visualization_app.set_current_graph(\"Topic-centered network (paper-based)\")\n",
    "visualization_app.set_list_papers_callback(list_papers)\n",
    "visualization_app.set_entity_definitons(definitions)\n",
    "visualization_app._db_error_message = \"Failed to retreive papers (check if the variable 'bbs_mysql_engine' was initialized or check the DB connection)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the app will display only top-50 most frequent nodes, you can then choose to show all the nodes in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_app.run(port=\"8076\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the knowledge graph\n",
    "Content of the Knowledge Graph is validated. In this version, syntactic validation (i.e. are the identifiers correct, ...) is performed when building the knowledge graph. If the knowledge graph is successfully built then the validation passes. In case of warning (i.e because of a weird character (+,...) in an extracted entity), the user can go back to the curation step and further curate extracted entities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct knowledge graph\n",
    "Correction involves going back to the extraction and/or curation steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access the knowledge graph\n",
    "The user can search, visualize, and export the knowledge graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version the knowledge graph\n",
    "The user can save a knowledge graph with a version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        \n",
    "# Temporally save the extracted entities csv file locally\n",
    "table_extractions_filename = \"./table_extractions_%s.csv\" % (timestr)\n",
    "table_extractions.to_csv(table_extractions_filename)\n",
    "\n",
    "\n",
    "# Temporally save the curated list of extracted entities csv file locally\n",
    "curated_table_extractions_filename = \"./curated_table_extractions_%s.csv\" % (timestr)\n",
    "curated_table_extractions.to_csv(curated_table_extractions_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwt\n",
    "from kgforge.core import Resource\n",
    "from kgforge.specializations.resources import Dataset\n",
    "\n",
    "agent = jwt.decode(TOKEN,  verify=False)\n",
    "\n",
    "agent = forge.reshape(forge.from_json(agent), keep=[\"name\",\"email\",\"sub\",\"preferred_username\"])\n",
    "agent.id = agent.sub\n",
    "agent.type = \"Person\"\n",
    "\n",
    "dataset = Dataset(forge,name=\"A dataset\", about=topic_resource.name)\n",
    "dataset.add_distribution(table_extractions_filename, content_type=\"application/csv\")\n",
    "dataset.add_distribution(curated_table_extractions_filename, content_type=\"application/csv\")\n",
    "dataset.add_contribution(agent)\n",
    "dataset.contribution.hadRole= \"Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = agent.preferred_username+\"_\"+timestr\n",
    "\n",
    "def register_dataset(b):\n",
    "    output4.clear_output()\n",
    "    output5.clear_output()\n",
    "    dataset.name = t1.value\n",
    "    dataset.description = t2.value\n",
    "    forge.register(dataset)\n",
    "    if dataset._last_action.succeeded == True:\n",
    "        with output4:\n",
    "            print(\"Dataset registered!\")\n",
    "    else:\n",
    "        with output4:\n",
    "            print(dataset._last_action.message)\n",
    "\n",
    "def version_dataset(b):\n",
    "    output5.clear_output()\n",
    "    version = t3.value\n",
    "    forge.tag(dataset,version)\n",
    "    if dataset._last_action.succeeded == True:\n",
    "        with output5:\n",
    "            print(f\"Tagged with: {str(version)}\")\n",
    "    \n",
    "output4 = ipywidgets.Output()\n",
    "output5 = ipywidgets.Output()\n",
    "\n",
    "b1 = ipywidgets.Button(\n",
    "    description= 'ðŸ’¾  Register Dataset',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "\n",
    "b2 = ipywidgets.Button(\n",
    "    description= 'ðŸ”– Tag Dataset',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "\n",
    "t1 = ipywidgets.Text(\n",
    "    placeholder='Add a name for your dataset',\n",
    "    description='Name:',\n",
    "    disabled=False)\n",
    "\n",
    "t2 = ipywidgets.Textarea(\n",
    "    placeholder='Add a description of your dataset',\n",
    "    description='Description:',\n",
    "    disabled=False)\n",
    "\n",
    "t3 = ipywidgets.Text(\n",
    "    description='Tag:',\n",
    "    value=version,\n",
    "    disabled=False)\n",
    "\n",
    "b1.on_click(register_dataset)\n",
    "b2.on_click(version_dataset)\n",
    "\n",
    "save_widget = ipywidgets.VBox(children=[t1, t2, b1, output4, t3, b2, output5])\n",
    "\n",
    "display(save_widget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BBS-BBG",
   "language": "python",
   "name": "devel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
