{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of the notebook\n",
    "(to be completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import logging\n",
    "import io\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "\n",
    "import IPython\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import scispacy\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "from bbsearch.article_saver import ArticleSaver\n",
    "from bbsearch.remote_searcher import RemoteSearcher\n",
    "from bbsearch.widget import Widget\n",
    "from bbsearch.utils import Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set a Project\n",
    "The User choses/creates a project to host a KG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set topic\n",
    "The user defines its topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import\n",
    "The user loads data from a data source (CORD-19).\n",
    "The loaded data forms the corpus.\n",
    "The user searches the CORPUS in Blue Brain Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_ENGINE_URL = os.getenv(\"SEARCH_ENGINE_URL\")\n",
    "BBS_DATA_PATH = os.getenv(\"BBS_DATA_PATH\") or '/raid/bbs_data/'\n",
    "BBS_DATA_PATH = Path(BBS_DATA_PATH)\n",
    "\n",
    "CORD19_VERSION = 'v7'\n",
    "\n",
    "cord_path = BBS_DATA_PATH / f'cord19_{CORD19_VERSION}'\n",
    "db_path = cord_path / 'databases' / 'cord19.db'\n",
    "trained_models_path = BBS_DATA_PATH / 'trained_models'\n",
    "\n",
    "assert db_path.is_file()\n",
    "assert SEARCH_ENGINE_URL is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\"{}/help\".format(SEARCH_ENGINE_URL))\n",
    "assert response.ok and response.json()['name'] == 'SearchServer', \"The server is not accessible\"\n",
    "\n",
    "searcher = RemoteSearcher(SEARCH_ENGINE_URL)\n",
    "\n",
    "database = sqlite3.connect(str(db_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_saver = ArticleSaver(database=database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs_widget = Widget(searcher, database, article_saver=article_saver)\n",
    "bbs_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status of the Article Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = article_saver.summary_table()\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set schemas\n",
    "The user defines the KG schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a knowledge graph according to schemas\n",
    "The user extracts data from the text of a set of papers using selected Named Entity Recognizers and Relation Extractors from Blue Brain Search.\n",
    "The user can preview the extracted data.\n",
    "The user curates extracted data.\n",
    "The user links the extracted entities and relations to ontologies.\n",
    "The user saves data into Knowledge Graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **input**: raw text\n",
    "- **output**: csv table of extracted entities/relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TEXT = \"\"\"Autophagy maintains tumour growth through circulating\n",
    "arginine. Autophagy captures intracellular components and delivers them to\n",
    "lysosomes, where they are degraded and recycled to sustain metabolism and to\n",
    "enable survival during starvation. Acute, whole-body deletion of the essential \n",
    "autophagy gene Atg7 in adult mice causes a systemic metabolic defect that \n",
    "manifests as starvation intolerance and gradual loss of white adipose tissue, \n",
    "liver glycogen and muscle mass.  Cancer cells also benefit from autophagy. \n",
    "Deletion of essential autophagy genes impairs the metabolism, proliferation, \n",
    "survival and malignancy of spontaneous tumours in models of autochthonous \n",
    "cancer. Acute, systemic deletion of Atg7 or acute, systemic expression of a \n",
    "dominant-negative ATG4b in mice induces greater regression of KRAS-driven \n",
    "cancers than does tumour-specific autophagy deletion, which suggests that host \n",
    "autophagy promotes tumour growth.\n",
    "\"\"\".replace('\\n', ' ').replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_MINING_URL = os.getenv(\"TEXT_MINING_URL\")\n",
    "assert TEXT_MINING_URL is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(TEXT_MINING_URL + \"/help\")\n",
    "\n",
    "assert response.ok and response.json()['name'] == 'MiningServer'\n",
    "\n",
    "def textmining_pipeline(information, debug=False):\n",
    "    \"\"\"Handle text mining server requests depending on the type of information.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    information: str or list.\n",
    "        Information can be either a raw string text, either a list of tuples \n",
    "        (article_id, paragraph_id) related to the database.\n",
    "    debug : bool\n",
    "        If True, columns are not necessarily matching the specification. However, they\n",
    "        contain debugging information. If False, then matching exactly the specification.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    table_extractions: pd.DataFrame\n",
    "        The final table. If `debug=True` then it contains all the metadata. If False then it\n",
    "        only contains columns in the official specification.\n",
    "    \"\"\"\n",
    "    if isinstance(information, list):\n",
    "        request_json = {\n",
    "            \"identifiers\": information}\n",
    "        response = requests.post(TEXT_MINING_URL + '/database', json=request_json)\n",
    "    elif isinstance(information, str):\n",
    "        request_json = {\n",
    "            \"text\": information,\n",
    "            \"debug\": debug}\n",
    "        response = requests.post(TEXT_MINING_URL + '/text', json=request_json)\n",
    "    else:\n",
    "        raise TypeError('Wrong type for the information!')\n",
    "\n",
    "    if response.headers[\"Content-Type\"] == \"text/csv\":\n",
    "        with io.StringIO(response.text) as f:\n",
    "            table_extractions = pd.read_csv(f)\n",
    "    else:\n",
    "        print(\"Response content type is not text/csv.\")\n",
    "\n",
    "    return table_extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the output: csv table of extracted entities/relations.\n",
    "table_extractions = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Widgets\n",
    "bbs_widgets = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs_widgets['articles_button'] = ipywidgets.Button(\n",
    "    description='Mine Selected Articles!',\n",
    "    layout=ipywidgets.Layout(width='60%')\n",
    ")\n",
    "\n",
    "def article_button(b):\n",
    "    global table_extractions\n",
    "    bbs_widgets['out'].clear_output()\n",
    "    complete_text = ''\n",
    "    with bbs_widgets['out']:\n",
    "        timer = Timer(verbose=True)\n",
    "        with timer('text retrieve'):\n",
    "            article_saver.retrieve_text()\n",
    "        with timer('casting to list'):\n",
    "            chosen_text = article_saver.df_chosen_texts\n",
    "            identifiers = [(row['article_id'], row['paragraph_id']) for _, row in chosen_text.iterrows()]\n",
    "            print(len(identifiers))\n",
    "        with timer('server part'):\n",
    "            table_extractions = textmining_pipeline(information=identifiers)\n",
    "            display(table_extractions)\n",
    "        \n",
    "bbs_widgets['articles_button'].on_click(article_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# \"Input Text\" Widget\n",
    "bbs_widgets['input_text'] = ipywidgets.Textarea(\n",
    "        value=DEFAULT_TEXT,\n",
    "        layout=ipywidgets.Layout(width='75%', height='300px')\n",
    "    )\n",
    "\n",
    "# \"Submit!\" Button\n",
    "bbs_widgets['submit_button'] = ipywidgets.Button(\n",
    "    description='Mine This Text!',\n",
    "    layout=ipywidgets.Layout(width='30%')\n",
    ")\n",
    "def cb(b):\n",
    "    global table_extractions\n",
    "    bbs_widgets['out'].clear_output()\n",
    "    with bbs_widgets['out']:\n",
    "        text = bbs_widgets['input_text'].value\n",
    "        table_extractions = textmining_pipeline(text)\n",
    "        display(table_extractions)\n",
    "bbs_widgets['submit_button'].on_click(cb)\n",
    "\n",
    "# \"Output Area\" Widget\n",
    "bbs_widgets['out'] = ipywidgets.Output(layout={'border': '0.5px solid black'})\n",
    "\n",
    "# Finalize Widgets\n",
    "ordered_widgets = list(bbs_widgets.values())\n",
    "main_widget = ipywidgets.VBox(ordered_widgets)\n",
    "IPython.display.display(main_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **input**: csv table of extracted entities/relations\n",
    "- **output**: knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if globals().get('table_extractions') is None:\n",
    "    ! wget -O extractions_example.csv 'https://drive.google.com/uc?export=download&id=11BBtkKsamru4kjUNev8lO_ulNMf7m3Ta'\n",
    "    table_extractions = pd.read_csv('extractions_example.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The table has {table_extractions.shape[0]} rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_server_proxy\n",
    "import jupyter_dash\n",
    "\n",
    "import base64\n",
    "import io\n",
    "import dash\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_table\n",
    "import pandas as pd\n",
    "#from jupyter_plotly_dash import JupyterDash\n",
    "from jupyter_dash import JupyterDash\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash.comms import _send_jupyter_config_comm_request\n",
    "_send_jupyter_config_comm_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JupyterDash.infer_jupyter_proxy_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_table_extractions = None\n",
    "data= table_extractions.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = JupyterDash('SimpleExample')\n",
    "\n",
    "# Create server variable with Flask server object for use with gunicorn\n",
    "server = app.server\n",
    "\n",
    "app.layout = html.Div(\n",
    "    [\n",
    "       \n",
    "    dcc.Store(id='memory', data=data),\n",
    "\n",
    "    dash_table.DataTable(\n",
    "        id='datatable-upload-container',\n",
    "        # fixed_rows={ 'headers': True, 'data': 0 },\n",
    "        style_cell={\n",
    "            'whiteSpace': 'normal'\n",
    "        },\n",
    "       \n",
    "        style_data_conditional=[\n",
    "            {\n",
    "                'if': {'row_index': 'odd'},\n",
    "                'backgroundColor': 'rgb(248, 248, 248)'\n",
    "            }\n",
    "        ],\n",
    "        style_header={\n",
    "            'backgroundColor': 'rgb(230, 230, 230)',\n",
    "            'fontWeight': 'bold'\n",
    "        },\n",
    "        css=[\n",
    "            {\n",
    "                'selector': 'dash-fixed-content',\n",
    "                'rule': 'height: 800;'\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        #style_table={'height': '700px'},\n",
    "        # data = table.to_dict('records'),\n",
    "        virtualization=True,\n",
    "        sort_action=\"native\",\n",
    "        sort_mode=\"multi\",\n",
    "        column_selectable=\"multi\",\n",
    "        filter_action=\"native\",\n",
    "        selected_columns=[],\n",
    "\n",
    "        page_action=\"native\",\n",
    "        selected_rows=[],\n",
    "        page_current=0,\n",
    "        page_size=30)\n",
    "    \n",
    "]\n",
    ")\n",
    "\n",
    "@app.callback(\n",
    "    Output('datatable-upload-container', 'style_data_conditional'),\n",
    "    [Input('datatable-upload-container', 'selected_columns')]\n",
    ")\n",
    "def update_styles(selected_columns):\n",
    "    return [{\n",
    "        'if': {'column_id': i},\n",
    "        'background_color': '#D2F3FF'\n",
    "    } for i in selected_columns]\n",
    "\n",
    "\n",
    "@app.callback([Output('memory', 'data'),\n",
    "               Output('datatable-upload-container', 'data'),\n",
    "               Output('datatable-upload-container', 'columns'),\n",
    "               Output('datatable-upload-container', 'editable'),\n",
    "               Output('datatable-upload-container', 'row_deletable')],\n",
    "\n",
    "              [Input('datatable-upload-container', 'page_size'),\n",
    "               Input('datatable-upload-container', 'page_current'),\n",
    "               Input('datatable-upload-container','data_timestamp')],\n",
    "\n",
    "              [State(\"datatable-upload-container\", \"data\"),\n",
    "               State(\"datatable-upload-container\", \"columns\"),\n",
    "              State(\"memory\", \"data\")])\n",
    "\n",
    "def update_output(page_size, page_current, ts,data,columns,memory_data):\n",
    "   \n",
    "    if ts is None:\n",
    "        data = table_extractions.to_dict('records')\n",
    "        columns= [{\"name\": i, \"id\": i, \"clearable\": True, \"selectable\": True, \"renamable\": True, \"hideable\": True, \"deletable\": True} for i in table_extractions.columns]\n",
    "    global curated_table_extractions\n",
    "    curated_table_extractions = pd.DataFrame(list(data))\n",
    "    \n",
    "    return data, data, columns, True, True\n",
    "\n",
    "app.width = \"100%\"\n",
    "app.height = \"800\"\n",
    "app.run_server(mode=\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pygments import highlight\n",
    "from pygments.lexers import JsonLdLexer, TurtleLexer\n",
    "from pygments.formatters import TerminalFormatter, TerminalTrueColorFormatter\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def pretty_print(a_json):\n",
    "    print(highlight(json.dumps(a_json, indent=2), JsonLdLexer(), TerminalFormatter()))\n",
    "    \n",
    "def represent_as_annotations(df: pd.DataFrame) -> Iterator[Dict]:\n",
    "    def _(row):\n",
    "        mention = row.entity\n",
    "        if not pd.isnull(row.property):\n",
    "        \n",
    "            value_triple = {\n",
    "                \"@id\":row.entity.replace(' ', '_'),\n",
    "                \"label\":row.entity,\n",
    "                row.property:{\n",
    "                 \"@id\":row.property_value.replace(' ', '_')\n",
    "                }\n",
    "            }\n",
    "            mention = row.property\n",
    "        else:\n",
    "            value_triple={\n",
    "                \"@id\":row.entity.replace(' ', '_'),\n",
    "                \"label\":row.entity,\n",
    "                \"@type\":row.entity_type\n",
    "            }\n",
    "            \n",
    "        result = {\n",
    "            '@context': [\n",
    "                    {\n",
    "                        \"@vocab\":\"https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/vocab/\",\n",
    "                        \"oa\":\"http://www.w3.org/ns/anno.jsonld\",\n",
    "                        \"value\":\"rdf:value\",\n",
    "                        \"source\":\"oa:source\",\n",
    "                        \"target\":\"oa:target\",\n",
    "                        \"selector\":\"oa:selector\",\n",
    "                        \"start\":\"oa:start\",\n",
    "                        \"end\":\"oa:end\",\n",
    "                        \"exact\":\"oa:exact\",\n",
    "                        \"label\":\"rdfs:label\",\n",
    "                        \"rdf\":\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "                        \"rdfs\":\"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "                        \"@base\":\"https://bbp.epfl.ch/nexus/v1/resources/covid19-kg/data/entity/\"\n",
    "                    }\n",
    "            ],\n",
    "            \n",
    "                '@id': f'https://bbp.epfl.ch/covid19/{row.Index}',\n",
    "                '@type': 'Annotation',\n",
    "                'target': {\n",
    "                    'source': str(row.paper_id).split(\":\")[0],\n",
    "                    'selector': {\n",
    "                        '@type': 'TextPositionSelector',\n",
    "                        'start': row.start_char,\n",
    "                        'end': row.end_char,\n",
    "                        'exact':mention,\n",
    "                        'value': value_triple\n",
    "                    },\n",
    "                }\n",
    "              \n",
    "\n",
    "        }\n",
    "    \n",
    "        #pretty_print(result)\n",
    "        return result\n",
    "    return (_(x) for x in tqdm(df.itertuples()))\n",
    "\n",
    "annotations = list(represent_as_annotations(curated_table_extractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(annotations)} annotations created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Note: The file is around 26 MB.\n",
    "! wget -O entity_linking-terms.pkl 'https://drive.google.com/uc?export=download&id=1DyA9WL1YpEBO37KkDSCY3f1LWFfscO7F'\n",
    "\n",
    "with open('entity_linking-terms.pkl', 'rb') as f:\n",
    "    ontology = pickle.load(f)\n",
    "\n",
    "ontologies = ['ChEBI', 'SO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The entity linking considers {len(ontology)} terms from:', *ontologies, sep='\\n - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class Candidate:\n",
    "    \n",
    "    def __init__(self, identifier, term, definition, score):\n",
    "        self.score = score\n",
    "        self.identifier = identifier\n",
    "        self.term = term\n",
    "        self.definition = definition\n",
    "    \n",
    "    def __repr__(self):\n",
    "        attrs = (f\"{k}={v!r}\" for k, v in self.__dict__.items())\n",
    "        return f\"Candidate({', '.join(attrs)})\"\n",
    "\n",
    "class EntityLinker:\n",
    "    \n",
    "    def __init__(self, ontology, nlp):\n",
    "        self.terms = None\n",
    "        self.model = None\n",
    "        self.index = None\n",
    "        self.ontology = [(k, v[0], v[1]) for k, v in ontology.items()]\n",
    "        self.nlp = nlp\n",
    "    \n",
    "    def link(self, mentions):\n",
    "        selections = self.candidates(mentions)\n",
    "        return [self.disambiguate(mention, candidates)\n",
    "                for mention, candidates in zip(mentions, selections)]\n",
    "    \n",
    "    def disambiguate(self, mention, candidates, threshold=0.6):\n",
    "        def _(cands):\n",
    "            # FIXME Used as a proxy until this is done during the other NLP operations.\n",
    "            doc = self.nlp(mention)\n",
    "            similarities = [(doc.similarity(self.nlp(x.definition.replace(mention, ''))), x)\n",
    "                            for x in cands if x.definition]\n",
    "            ranked = sorted(similarities, key=lambda x: x[0], reverse=True)\n",
    "            return ranked[0]\n",
    "        zeros = [x for x in candidates if x.score == 0]\n",
    "        if zeros:\n",
    "            chosen = _(zeros)\n",
    "            return chosen\n",
    "        else:\n",
    "            chosen = _(candidates)\n",
    "            return chosen if chosen[0] >= threshold else None\n",
    "    \n",
    "    def candidates(self, mentions, limit=3):\n",
    "        embeddings = self.model.transform(mentions)\n",
    "        distances, indexes = self.index.search(embeddings.toarray(), limit)\n",
    "        return [[Candidate(*self.terms[i], d) for i, d in zip(indexes[k], distances[k])]\n",
    "                for k in range(len(mentions))]\n",
    "    \n",
    "    def train(self):\n",
    "        self.model = TfidfVectorizer(analyzer='char', ngram_range=(3, 3), max_df=0.95,\n",
    "                                     max_features=int(len(self.ontology)*0.1),\n",
    "                                     dtype=np.float32, norm='l2')\n",
    "        terms = [x for _, x, _ in self.ontology]\n",
    "        embeddings = self.model.fit_transform(terms)\n",
    "        flags = np.array(embeddings.sum(axis=1) != 0).reshape(-1)\n",
    "        filtered_embeddings = embeddings[flags]\n",
    "        self.terms = [term for term, flag in zip(self.ontology, flags) if flag]\n",
    "        self.index = faiss.IndexFlatL2(filtered_embeddings.shape[1])\n",
    "        self.index.add(filtered_embeddings.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nlp = ee_model\n",
    "except NameError:\n",
    "    import spacy\n",
    "    nlp = spacy.load('en_ner_craft_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "linker = EntityLinker(ontology, nlp)\n",
    "linker.train()\n",
    "# Note: Takes around 45 secs on a BBP issued MacBook Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Dict, Iterator\n",
    "from copy import deepcopy\n",
    "\n",
    "def enrich_annotations(annotations: Iterable[Dict], linker: EntityLinker) -> Iterator[Dict]:\n",
    "    def _(ann, can):\n",
    "        new = deepcopy(ann)\n",
    "        if can:\n",
    "            new['body'] = {\n",
    "                '@id': can[1].identifier,\n",
    "                'label': can[1].term,\n",
    "            }\n",
    "        return new\n",
    "    mentions = [x['target']['selector']['value'] for x in annotations]\n",
    "    linked_mentions = linker.link(mentions)\n",
    "    return (_(ann, can) for ann, can in zip(annotations, linked_mentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "enriched_annotations = list(enrich_annotations(annotations, linker))\n",
    "# Note: Takes around 20 secs on a BBP issued MacBook Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Iterable, Dict\n",
    "from rdflib import Graph\n",
    "\n",
    "def load_knowledge_graph(jsonlds: Iterable[Dict]) -> Graph:\n",
    "    g = Graph()\n",
    "    for x in tqdm(jsonlds):\n",
    "        g.parse(data=json.dumps(x), format='json-ld')\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Build knowledge graph from enriched annotations\n",
    "knowledge_graph = load_knowledge_graph(enriched_annotations)\n",
    "# Note: Takes around 8 secs on a BBP issued MacBook Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Build knowledge graph from original annotations\n",
    "knowledge_graph = load_knowledge_graph(annotations)\n",
    "# Note: Takes around 8 secs on a BBP issued MacBook Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The knowledge graph has {len(knowledge_graph)} triples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_graph= Graph()\n",
    "for s,p,o in knowledge_graph.triples((None,None,None)):\n",
    "    if p == rdflib.term.URIRef(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#value\"):\n",
    "        for ss, pp, oo in knowledge_graph.triples((rdflib.term.URIRef(o),None,None)):\n",
    "            content_graph.add((ss,pp,oo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the knowledge graph\n",
    "Thee User reviews content of Knowledge Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct knowledge graph\n",
    "The correct the Knowledge Graph is errors occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access the knowledge graph\n",
    "The user can search, visualize, and export the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_digraph\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _freequency(colunm, df, distinct_papers=True, debug=False):\n",
    "    \n",
    "    if debug:\n",
    "        display(df.head(100))\n",
    "    if distinct_papers:\n",
    "        \n",
    "        colunm_stats = df[[colunm, \"paper_id\"]].groupby(colunm).str(paper_id).split(\":\")[0].nunique()\n",
    "    else:\n",
    "        colunm_stats = df[[colunm, \"paper_id\"]].groupby(colunm).paper_id.count()\n",
    "    if debug:\n",
    "        display(colunm_stats)\n",
    "\n",
    "    \n",
    "    return colunm_stats\n",
    "        \n",
    "entity_stats = _freequency(colunm=\"entity\",df=curated_table_extractions,distinct_papers=False, debug=False)\n",
    "relation_stats = _freequency(colunm=\"property\",df=curated_table_extractions,distinct_papers=False)\n",
    "\n",
    "#display(entity_stats)\n",
    "#display(relation_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_digraph\n",
    "import base64\n",
    "import io\n",
    "import dash\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_table\n",
    "import pandas as pd\n",
    "import dash_cytoscape as cyto\n",
    "def visualize_the_knowledgegraph_cytoscape(graph):\n",
    "    # Will contain the element to send to Cytoscape.\n",
    "    # Don't use it directly, use the functions addNode() and addEdge() instead.\n",
    "    elements = []\n",
    "    def addNode(id, label=None, label_size=10, label_color=\"black\", radius=30, node_color='grey'):\n",
    "        \"\"\"\n",
    "        Adds a node to the list of object to display in Cytoscape.\n",
    "        Must have an id, the rest is optional.\n",
    "        \"\"\"\n",
    "        actualLabel = None\n",
    "        if label is not None:\n",
    "            actualLabel = label.lower()\n",
    "        else:\n",
    "            actualLabel = str(id).lower().split(\"/\")[-1].split(\"#\")[-1]\n",
    "            \n",
    "        if radius == 0:\n",
    "            radius = 30\n",
    "            \n",
    "        \n",
    "        elements.append({\n",
    "            \"data\": { \n",
    "                \"id\": str(id).lower(),\n",
    "            },\n",
    "            \"style\": {\n",
    "                \"label\": actualLabel,\n",
    "                \"width\": radius,\n",
    "                \"height\": radius,\n",
    "                \"background-color\": node_color,\n",
    "                \"font-size\": f\"{label_size}px\",\n",
    "                \"color\": label_color\n",
    "            }\n",
    "        })\n",
    "    def addEdge(id, from_id, to_id, label=None, label_size=10, label_color=\"black\", thickness=2, edge_color=\"grey\", edge_style=\"solid\"):\n",
    "        \"\"\"\n",
    "        Adds an edge to the list of object to display in Cytoscape.\n",
    "        Must have an id, the id of the node the link comes from (from_id) and the id of the node it going towards (to_id).\n",
    "        \"\"\"\n",
    "        actualLabel = None\n",
    "        if label is not None:\n",
    "            actualLabel = label.lower()\n",
    "        else:\n",
    "            actualLabel = str(id).lower().split(\"/\")[-1].split(\"#\")[-1]\n",
    "        \n",
    "        if thickness == 0:\n",
    "            thickness = 2\n",
    "        elements.append({\n",
    "            \"data\": { \n",
    "                \"id\": str(id),\n",
    "                \"source\": str(from_id).lower(),\n",
    "                \"target\": str(to_id).lower(),\n",
    "            },\n",
    "            \"style\": {\n",
    "                \"label\": actualLabel,\n",
    "                \"font-size\": f\"{label_size}px\",\n",
    "                \"width\": thickness,\n",
    "                \"color\": label_color,\n",
    "                \"line-color\": edge_color,\n",
    "                \"line-style\": edge_style\n",
    "            }\n",
    "        })\n",
    "    # only the first param is mandatory, rest are options\n",
    "\n",
    "    G = rdflib_to_networkx_digraph(graph)\n",
    "    \n",
    "    for node, node_attrs in G.nodes(data=True):\n",
    "        if (str(node).startswith(\"http\")):\n",
    "            node_label = str(node).split(\"/\")[-1].split(\"#\")[-1]\n",
    "            node_radius = 5\n",
    "\n",
    "            for x in entity_stats.iteritems():\n",
    "                if x[0] == node_label:\n",
    "                    node_radius = int(x[1]) * node_radius\n",
    "\n",
    "            addNode(str(node), node_color=\"pink\", label_color='#ed87e0', radius=node_radius)\n",
    "       \n",
    "\n",
    "    for source, target, edge_attrs in G.edges(data=True):\n",
    "        if not 'value' in edge_attrs and not 'width' in edge_attrs and 'weight' in edge_attrs:\n",
    "            edge_attrs['value'] = edge_attrs['weight']\n",
    "        if 'triples' in edge_attrs:\n",
    "            edge_attrs['title'] = edge_attrs['triples'][0][1]\n",
    "        edge_id = str(source).lower().replace(\" \",\"_\")+\"_\"+str(target).lower()\n",
    "        edge_label = str(edge_attrs['title']).split(\"/\")[-1].split(\"#\")[-1]\n",
    "        \n",
    "        if edge_label != \"label\":\n",
    "            \n",
    "            thickness = 2\n",
    "            for x in relation_stats.iteritems():\n",
    "                if x[0] == edge_label:\n",
    "                    thickness = int(x[1]) * thickness\n",
    "            addEdge(id = edge_id, from_id = str(source), to_id = str(target), label=edge_label,label_size=6, thickness=thickness, edge_color=\"#DDDDDD\" )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    app = JupyterDash(\"YourAppExample\")\n",
    "    \n",
    "    app.layout = html.Div([\n",
    "        cyto.Cytoscape(\n",
    "            id=\"cytoscape\",\n",
    "            elements=elements,\n",
    "            layout={\"name\": \"cose\"}, # \"cose\" is nice because it rearanges the nodes spatially in a smart way\n",
    "            style={\"height\": \"800px\", \"width\": \"100%\"}, # to have a larger cell for the graph\n",
    "            stylesheet=[\n",
    "                \n",
    "                {\n",
    "                    'selector': 'edge',\n",
    "                    'style': {\n",
    "                        # The default curve style does not work with certain arrows\n",
    "                        'curve-style': 'bezier'\n",
    "                    }\n",
    "                },{\n",
    "                    'selector': 'edge',\n",
    "                    'style': {\n",
    "                        'source-arrow-color': 'black',\n",
    "                        'target-arrow-shape': 'triangle',\n",
    "                        'line-color': '#DDDDDD'\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "          )\n",
    "    ])\n",
    "    \n",
    "    app.width = \"800px\"\n",
    "    app.height = \"800px\"\n",
    "    return app, elements, G\n",
    "\n",
    "\n",
    "app_vis, cyto_elements, G = visualize_the_knowledgegraph_cytoscape(content_graph)\n",
    "app_vis.run_server(mode=\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "def randomString(stringLength=8):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(stringLength))\n",
    "\n",
    "\n",
    "def show_graph(G):\n",
    "    # Don't use it directly, use the functions addNode() and addEdge() instead.\n",
    "    elements = []\n",
    "    \n",
    "    \n",
    "    def addNode(id, label=None, label_size=10, label_color=\"black\", radius=30, node_color='grey'):\n",
    "        \"\"\"\n",
    "        Adds a node to the list of object to display in Cytoscape.\n",
    "        Must have an id, the rest is optional.\n",
    "        \"\"\"\n",
    "        actualLabel = None\n",
    "        \n",
    "        if label is not None:\n",
    "            actualLabel = label\n",
    "        else:\n",
    "            actualLabel = str(id).split(\"/\")[-1].split(\"#\")[-1]\n",
    "            \n",
    "        if radius == 0:\n",
    "            radius = 5\n",
    "        elements.append({\n",
    "            \"data\": { \n",
    "                \"id\": str(id),\n",
    "            },\n",
    "            \"style\": {\n",
    "                \"label\": actualLabel,\n",
    "                \"width\": radius,\n",
    "                \"height\": radius,\n",
    "                # \"background-color\": node_color,\n",
    "                \"font-size\": f\"{label_size}px\",\n",
    "                \"color\": label_color\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        \n",
    "    def addEdge(id, from_id, to_id, label=None, label_size=10, label_color=\"black\", thickness=2, edge_color=\"grey\", edge_style=\"solid\"):\n",
    "        \"\"\"\n",
    "        Adds an edge to the list of object to display in Cytoscape.\n",
    "        Must have an id, the id of the node the link comes from (from_id) and the id of the node it going towards (to_id).\n",
    "        \"\"\"\n",
    "        actualLabel = None\n",
    "        \n",
    "        if label is not None:\n",
    "            actualLabel = label\n",
    "        else:\n",
    "            actualLabel = str(id).split(\"/\")[-1].split(\"#\")[-1]\n",
    "        \n",
    "        if thickness == 0:\n",
    "            thickness = 2\n",
    "            \n",
    "        elements.append({\n",
    "            \"data\": { \n",
    "                \"id\": str(id),\n",
    "                \n",
    "                \"source\": str(from_id),\n",
    "                \"target\": str(to_id),\n",
    "            },\n",
    "            \"style\": {\n",
    "                \"label\": actualLabel,\n",
    "                \"font-size\": f\"{label_size}px\",\n",
    "                \"width\": thickness,\n",
    "                \"color\": label_color,\n",
    "                \"line-color\": edge_color,\n",
    "                \"line-style\": edge_style,\n",
    "                \"curve-style\": \"bezier\",\n",
    "                \"target-arrow-shape\": \"triangle\",\n",
    "                \"target-arrow-color\": edge_color,\n",
    "                \"arrow-scale\": thickness * 0.5,\n",
    "            }\n",
    "        })\n",
    "\n",
    "    nb_nodes = 100\n",
    "    nb_edges = 250\n",
    "    nodes = []\n",
    "    \n",
    "\n",
    "    for node, node_attrs in G.nodes(data=True):\n",
    "        \n",
    "        if (str(node).startswith(\"http\")):\n",
    "            node_label = str(node).split(\"/\")[-1].split(\"#\")[-1]\n",
    "            node_radius = 5\n",
    "\n",
    "            for x in entity_stats.iteritems():\n",
    "                if x[0] == node_label:\n",
    "                    node_radius = int(x[1]) * node_radius\n",
    "\n",
    "            addNode(str(node), label_size=2, radius=node_radius)\n",
    "       \n",
    "    for source, target, edge_attrs in G.edges(data=True):\n",
    "        \n",
    "        if not 'value' in edge_attrs and not 'width' in edge_attrs and 'weight' in edge_attrs:\n",
    "            edge_attrs['value'] = edge_attrs['weight']\n",
    "        if 'triples' in edge_attrs:\n",
    "            edge_attrs['title'] = edge_attrs['triples'][0][1]\n",
    "        edge_id = str(source).lower().replace(\" \",\"_\")+\"_\"+str(target).lower()\n",
    "        edge_label = str(edge_attrs['title']).split(\"/\")[-1].split(\"#\")[-1]\n",
    "        \n",
    "        if edge_label != \"label\":\n",
    "            \n",
    "            thickness = 2\n",
    "            for x in relation_stats.iteritems():\n",
    "                if x[0] == edge_label:\n",
    "                    thickness = int(x[1]) * thickness\n",
    "            addEdge(id = edge_id, from_id = str(source), to_id = str(target), label=edge_label,label_size=6, thickness=thickness, edge_color=\"#DDDDDD\" )\n",
    "\n",
    "    \n",
    "\n",
    "    options = {\n",
    "        \"labelProperty\": \"style.label\",      # Name of the property that contains the label. If not provided, the full id wil be used for display\n",
    "        \"nodeRadiusProperty\": \"style.width\", # if provided, this prevails on \"minNodeRadius\" and \"maxNodeRadius\"\n",
    "        \"minNodeRadius\": 14,                  # default: 10 : When computed automatically based on number of links (unused if nodeRadiusProperty is provided)\n",
    "        \"maxNodeRadius\": 20,                 # default: 50 : When computed automatically based on number of links (unused if nodeRadiusProperty is provided)\n",
    "        \"minEdgeThickness\": 1,               # default: 1.5 : When computed automatically basesd on number of links \n",
    "        \"maxEdgeThickness\": 20,              # default: 100 : When computed automatically based on number of links \n",
    "        \"edgeThicknessProperty\": \"style.width\", # if provided, it forces each edges to be of a given thickness. This prevails on \"minEdgeThickness\" and \"maxEdgeThickness\"\n",
    "        #\"nodePadding\": 10,                 # default: (minNodeRadius + maxNodeRadius) : two nodes cannot get closer than this distance\n",
    "        \"graphPadding\": 100,                  # default: minNodeRadius : blank space left around the graph. Make it bigger if labels are stepping outside\n",
    "        \"mode\": \"mono\",                      # default: 'mono' (aggregate inbound and outbound link), can be 'directional' (differentiate inbound and outbout links)\n",
    "        \"defaultNodeColor\": \"orange\",          # default: \"grey\" : color of links per default\n",
    "        #\"nodeColorProperty\": \"style.background-color\", # if provided, this prevails on \"defaultNodeColor\". Convenient to give each node a different color\n",
    "        \"linkColor\": \"#00bef2\",                 # default: \"grey\" : color of nodes per default\n",
    "        #\"inboundLinkColor\": \"blue\",         # default: \"#076dd9\" : applies only with graphMode = \"mono\", color of inbound links when hovered (will have the color of the option \"linkColor\" whnen not hovered)\n",
    "        #\"outboundLinkColor\": \"red\",         # default: \"#db2612\" : applies only with graphMode = \"mono\", color of outbound links when hovered (will have the color of the option \"linkColor\" whnen not hovered)\n",
    "        \"centerGravity\": 0.3,                # default: 0.3 : Makes links being more attracted by the center of the graph when close to 1. \n",
    "        \"smoothTransition\": False,           # default: true : if True, the elements will transition-fade when hovered. If too many data, better put False for performance\n",
    "    }\n",
    "   \n",
    "    # Creating the webapp to embed\n",
    "    core_js = open('radialgraph/core.js').read()\n",
    "    panzoom_js = open('radialgraph/panzoom.js').read()\n",
    "    html = open('radialgraph/master.html').read()\n",
    "    html = html.replace(\"SHARED_DATASET\", json.dumps(cyto_elements))\n",
    "    html = html.replace(\"SHARED_OPTIONS\", json.dumps(options))\n",
    "    html = html.replace(\"CORE_JS\", core_js)\n",
    "    html = html.replace(\"PANZOOM\", panzoom_js)\n",
    "    index_copy_filename = os.path.join(\"tmp\", f\"{randomString()}.html\")\n",
    "    local_html_copy = open(index_copy_filename,\"w\")\n",
    "    local_html_copy.write(html)\n",
    "    local_html_copy.close()\n",
    "    \n",
    "    # Display the webapp\n",
    "    display(IFrame(src=index_copy_filename, width='1000px', height='3000px'))\n",
    "    \n",
    "\n",
    "show_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version the knowledge graph\n",
    "The user can save a knowledge graph with a version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
