{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of the notebook\n",
    "End to end pipeline for searching articles of interest, extracting entities of interest, building, accessing and deploying a knowled graph and a co-mention graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import requests\n",
    "import sqlalchemy\n",
    "import ipywidgets\n",
    "\n",
    "from bbsearch.widgets import ArticleSaver, SearchWidget, MiningWidget, SchemaRequest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash.comms import _send_jupyter_config_comm_request, _jupyter_config\n",
    "from jupyter_dash import JupyterDash\n",
    "\n",
    "import dash_cytoscape as cyto\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JupyterDash configs\n",
    "_send_jupyter_config_comm_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "JupyterDash.infer_jupyter_proxy_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto.load_extra_layouts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cord_analytics.utils import (generate_curation_table,\n",
    "                                  link_ontology,\n",
    "                                  generate_comention_analysis,\n",
    "                                  build_cytoscape_data,\n",
    "                                  merge_with_ontology_linking,\n",
    "                                  resolve_taxonomy_to_types)\n",
    "            \n",
    "from bbg_apps.curation_app import (curation_app)\n",
    "from bbg_apps.visualization_app import (visualization_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_extractions = pd.read_csv(\"table_extract.csv\")\n",
    "curated_table_extractions = pd.read_csv(\"curated_table.csv\")\n",
    "curated_table_extractions = curated_table_extractions.set_index(\"entity\")\n",
    "factor_counts = {'paper': 18, 'section': 1870, 'paragraph': 8512}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set a Project\n",
    "\n",
    "The user chooses / creates a project to host a KG.\n",
    "\n",
    "* Use the [Nexus web application](https://bbp.epfl.ch/nexus/web) to get a token.\n",
    "* Once a token is obtained then proceed to paste it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยทยท\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "TOKEN = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kgforge.core import KnowledgeGraphForge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a 'forge' to manage (create, access and deploy) the knowledge graph within a given Blue Brain Nexus Project.\n",
    "FORGE_CONFIG_FILE = os.getenv(\"FORGE_CONFIG_FILE\") \n",
    "assert (FORGE_CONFIG_FILE is not None) \n",
    "forge = KnowledgeGraphForge(FORGE_CONFIG_FILE,token=TOKEN, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set topic\n",
    "The user defines a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwt\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702e6eb84a964e388c12ce12b98ebe94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HBox(children=(Button(description='๐ฌ List all your topics', layout=Layout(height=โฆ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_resource=None\n",
    "kg_resource=None\n",
    "agent_username = jwt.decode(TOKEN,  verify=False)['preferred_username']\n",
    "\n",
    "def save_topic(b):\n",
    "    output.clear_output()\n",
    "    output2.clear_output()\n",
    "    output3.clear_output()\n",
    "    topic_to_save = {\n",
    "        'id': str(widget.children[1].children[0].value).replace(' ', '_'),\n",
    "        'type': 'Topic',\n",
    "        'name': widget.children[1].children[0].value,\n",
    "        'field': widget.children[1].children[1].value,\n",
    "        'description': widget.children[1].children[2].value,\n",
    "        'keywords': widget.children[1].children[3].value,\n",
    "        'question':  [widget.children[1].children[i].value for i in range(5,9)]\n",
    "    }\n",
    "    global topic_resource\n",
    "    topic_resource = forge.from_json(topic_to_save)\n",
    "    forge.register(topic_resource)\n",
    "    with output2:\n",
    "        if w1.value == \"\":\n",
    "            print(\"Please provide a topic name\")\n",
    "        else:\n",
    "            print(\"Topic saved!\")\n",
    "            w1.value = \"\"\n",
    "            w2.value = \"\"\n",
    "            w3.value = \"\"\n",
    "            w4.value = \"\"\n",
    "            w5.value = \"\"\n",
    "            w6.value = \"\"\n",
    "            w7.value = \"\"\n",
    "            w8.value = \"\"\n",
    "\n",
    "def get_topics(b):\n",
    "    output.clear_output()\n",
    "    output2.clear_output()\n",
    "    output3.clear_output()\n",
    "    query = f\"\"\"\n",
    "    SELECT ?id ?name ?description ?keywords ?field ?question ?createdAt\n",
    "    WHERE {{\n",
    "        ?id a Topic ;\n",
    "            name ?name ;\n",
    "            description ?description ;\n",
    "            keywords ?keywords ;\n",
    "            field ?field ;\n",
    "            question ?question ;\n",
    "            <https://bluebrain.github.io/nexus/vocabulary/deprecated> false ;\n",
    "            <https://bluebrain.github.io/nexus/vocabulary/createdAt> ?createdAt ;\n",
    "            <https://bluebrain.github.io/nexus/vocabulary/createdBy> <{forge._store.endpoint}/realms/bbp/users/{agent_username}> .\n",
    "    }}\n",
    "    \"\"\"\n",
    "    resources = forge.sparql(query, limit=100)\n",
    "    if len(resources) >= 1:\n",
    "        global topics_df\n",
    "        topics_df = forge.as_dataframe(resources)\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            topics_list = list(set(topics_df.name))\n",
    "            topics_list.sort()\n",
    "            w0.options = [\"\"] + topics_list\n",
    "            w0.value = \"\"\n",
    "            w0.placeholder = \"Select topic\"\n",
    "            w0.observe(topics_change, names='value')\n",
    "            display(w0)\n",
    "            display(s12)\n",
    "    else:\n",
    "        with output:\n",
    "            print(\"No topics found!\")\n",
    "\n",
    "def topics_change(change):\n",
    "    output3.clear_output()\n",
    "    with output:\n",
    "        if len(output.outputs) >= 1:\n",
    "            output.outputs = (output.outputs[0],)\n",
    "        s5.value = \"\"\n",
    "        s6.value = \"\"\n",
    "        s7.value = \"\"\n",
    "        s8.value = \"\"\n",
    "        s9.value = \"\"\n",
    "        s10.value = \"\"\n",
    "        s11.value = \"\"\n",
    "        global topic_resource\n",
    "        if change['new'] != \"\":\n",
    "            topic_resource = forge.retrieve(list(set(topics_df[topics_df.name == change['new']].id))[0])\n",
    "            s5.value = topic_resource.field\n",
    "            s6.value = topic_resource.description\n",
    "            s7.value = topic_resource.keywords\n",
    "            question = topic_resource.question\n",
    "            if isinstance(question, str):\n",
    "                question = [question]\n",
    "            if isinstance(question, list):\n",
    "                for i in range(len(question)):\n",
    "                    sq.children[i].value = question[i]            \n",
    "        display(s12)\n",
    "\n",
    "def update_topic(b):\n",
    "    output2.clear_output()\n",
    "    if w0.value != \"\":\n",
    "        topic_resource.id = forge.as_jsonld(topic_resource, form=\"expanded\")['@id']\n",
    "        topic_resource.field = s5.value\n",
    "        topic_resource.description = s6.value\n",
    "        topic_resource.keywords = s7.value\n",
    "        topic_resource.question = [sq.children[i].value for i in range(0,4)]\n",
    "        forge.update(topic_resource)\n",
    "        with output:\n",
    "            print(\"topic updated!\")\n",
    "        \n",
    "def get_datasets(b):\n",
    "    output3.clear_output()\n",
    "    if w0.value != \"\":\n",
    "        topic_resource_id = forge.as_jsonld(topic_resource, form=\"expanded\")['@id']\n",
    "        query = f\"\"\"\n",
    "            SELECT ?id ?name ?description ?keywords ?field ?question ?createdAt\n",
    "            WHERE {{\n",
    "                ?id a Dataset ;\n",
    "                    name ?name ;\n",
    "                    about <{topic_resource_id}> ;\n",
    "                    <https://bluebrain.github.io/nexus/vocabulary/deprecated> false ;\n",
    "                    <https://bluebrain.github.io/nexus/vocabulary/createdAt> ?createdAt ;\n",
    "                    <https://bluebrain.github.io/nexus/vocabulary/createdBy> <{forge._store.endpoint}/realms/bbp/users/{agent_username}> .\n",
    "            }}\n",
    "            \"\"\"\n",
    "        global kg_resources\n",
    "        kg_resources = forge.sparql(query, limit=100, debug=True)\n",
    "        print(len(kg_resources))\n",
    "        if len(kg_resources) >= 1:\n",
    "            with output3:\n",
    "                display(s2)\n",
    "                s2.options = [r.name for r in kg_resources]\n",
    "                display(s3)\n",
    "        else:\n",
    "            with output3:\n",
    "                print(\"No datasets found!\")\n",
    "        \n",
    "def download_dataset(b):\n",
    "    resource_id = [r.id for r in kg_resources if r.name == s2.value][0]\n",
    "    global kg_resource\n",
    "    global table_extractions\n",
    "    kg_resource = forge.retrieve(resource_id)\n",
    "    forge.download(kg_resource, \"distribution.contentUrl\", \"/tmp/\", overwrite=True)\n",
    "    for r in kg_resource.distribution:\n",
    "        if \"curated\" in r.name:\n",
    "            table_extractions = pd.read_csv(f\"/tmp/{r.name}\")\n",
    "            if table_extractions is not None:\n",
    "                message = f\"Dataset '{r.name}' with {len(table_extractions)} entities ready to be reused. Its content has been assigned to the variable 'table_extractions'. Please continue with the interactive UI section to visualise this dataset.\"\n",
    "            else:\n",
    "                table_extractions = pd.DataFrame()\n",
    "                message = \"No dataset has been downloaded\"\n",
    "            with output3:\n",
    "                print(message)\n",
    "\n",
    "s0 = ipywidgets.Button(\n",
    "    description= '๐ฌ List all your topics',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s1 = ipywidgets.Button(\n",
    "    description= \"๐ Show datasets for selected topic\",\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s2 = ipywidgets.RadioButtons(\n",
    "    description='Select:',\n",
    "    disabled=False)\n",
    "s3 = ipywidgets.Button(\n",
    "    description= '๐ Reuse selected dataset',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s4 = ipywidgets.Button(\n",
    "    description= 'โ๏ธ Update topic',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "s5 = ipywidgets.Text(\n",
    "    description='Field:',\n",
    "    disabled=False)\n",
    "s6 = ipywidgets.Textarea(\n",
    "    description='Description:',\n",
    "    disabled=False)\n",
    "s7 = ipywidgets.Textarea(\n",
    "    description='Keywords:',\n",
    "    disabled=False)\n",
    "s8 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "s9 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "s10 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "s11 = ipywidgets.Text(\n",
    "    disabled=False)\n",
    "\n",
    "sq = ipywidgets.VBox(children=[s8, s9, s10, s11])\n",
    "\n",
    "s12 = ipywidgets.VBox(children=[s5, s6, s7, ipywidgets.Label('Questions:'), sq, s4])\n",
    "\n",
    "w0 = ipywidgets.Dropdown(\n",
    "        description='Select topic:',\n",
    "        disabled=False)\n",
    "w1 = ipywidgets.Text(\n",
    "    placeholder='e.g. COVID-19',\n",
    "    description='Topic name:',\n",
    "    disabled=False)\n",
    "w2 = ipywidgets.Text(\n",
    "    placeholder='e.g. Neuroscience',\n",
    "    description='Field:',\n",
    "    disabled=False)\n",
    "w3 = ipywidgets.Textarea(\n",
    "    placeholder='Add a description of your topic',\n",
    "    description='Description:',\n",
    "    disabled=False)\n",
    "w4 = ipywidgets.Textarea(\n",
    "    placeholder='e.g. Coronavirus; COVID-19; SARS; risk factor; glycosylation; sugar; carbohydrates',\n",
    "    description='Keywords:',\n",
    "    disabled=False)\n",
    "w5 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w6 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w7 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w8 = ipywidgets.Text(\n",
    "    placeholder='Add a question about your research topic',\n",
    "    disabled=False)\n",
    "w9 = ipywidgets.Button(\n",
    "    description='Create',\n",
    "    button_style='',\n",
    "    tooltip='Create new topic',\n",
    "    disabled=False)\n",
    "\n",
    "output = ipywidgets.Output()\n",
    "output2 = ipywidgets.Output()\n",
    "output3 = ipywidgets.Output()\n",
    "\n",
    "buttons = ipywidgets.HBox(children=[s0, s1])\n",
    "outputs = ipywidgets.HBox(children=[output, output3])\n",
    "tab1 = ipywidgets.VBox(children=[buttons, outputs])\n",
    "tab2 = ipywidgets.VBox(children=[w1, w2, w3, w4, ipywidgets.Label('Please express your research topic in a few questions:'), w5, w6, w7, w8, w9, output2])\n",
    "widget = ipywidgets.Tab(children=[tab1, tab2])\n",
    "widget.set_title(0, 'Select topic')\n",
    "widget.set_title(1, 'Create topic')\n",
    "\n",
    "w9.on_click(save_topic)\n",
    "s0.on_click(get_topics)\n",
    "s1.on_click(get_datasets)\n",
    "s3.on_click(download_dataset)\n",
    "s4.on_click(update_topic)\n",
    "\n",
    "display(widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import\n",
    "The user loads data from a data source (CORD-19). The loaded data forms the corpus. The user searches the CORPUS in Blue Brain Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search server URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This server is using the database: cord19_v47\n"
     ]
    }
   ],
   "source": [
    "SEARCH_ENGINE_URL = os.getenv(\"SEARCH_ENGINE_URL\", \"http://dgx1.bbp.epfl.ch:8850\")\n",
    "assert SEARCH_ENGINE_URL is not None\n",
    "\n",
    "response = requests.post(\"{}/help\".format(SEARCH_ENGINE_URL))\n",
    "assert response.ok and response.json()['name'] == 'SearchServer', \"The server is not accessible\"\n",
    "print(f\"This server is using the database: {response.json()['database']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MySQL URL and engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYSQL_DB_URI = os.getenv(\"MYSQL_DB_URI\", \"dgx1.bbp.epfl.ch:8853\")\n",
    "bbs_mysql_engine = sqlalchemy.create_engine(f'mysql+pymysql://guest:guest@{MYSQL_DB_URI}/cord19_v47')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Article saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_saver = ArticleSaver(connection=bbs_mysql_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> /* search engine */\n",
       "\n",
       ".article_title {\n",
       "    font-size: 17px;\n",
       "    color: #1A0DAB;\n",
       "}\n",
       ".paragraph {\n",
       "    font-size: 13px;\n",
       "    color: #222;\n",
       "}\n",
       ".paragraph_emph {\n",
       "    font-weight: bold;\n",
       "    color: #000;\n",
       "}\n",
       ".metadata {\n",
       "    font-size: 13px;\n",
       "    color: #006621;\n",
       "}\n",
       "\n",
       "\n",
       "/* widgets buttons */\n",
       "\n",
       ".bbs_button {\n",
       "    background-color: #3c96f3;\n",
       "    color: #FFF;\n",
       "    font-size: 150%;\n",
       "    transition-duration: 0.2s;\n",
       "}\n",
       ".bbs_button:hover {\n",
       "    background-color: #3176d2;\n",
       "}\n",
       "\n",
       "\n",
       "/* attribute extraction */\n",
       "\n",
       ".number  {\n",
       "    display: inline-block;\n",
       "    background: lightgreen;\n",
       "    padding: 0.2em 0.5em;\n",
       "    border-radius: 7px;\n",
       "}\n",
       ".unit {\n",
       "    display: inline-block;\n",
       "    background: pink;\n",
       "    padding: 0.2em 0.5em;\n",
       "    border-radius: 7px;\n",
       "}\n",
       ".quantityType {\n",
       "    display: inline-block;\n",
       "    background: yellow;\n",
       "    font-variant:small-caps;\n",
       "    padding: 0.2em 0.5em;\n",
       "    border-radius: 7px;\n",
       "}\n",
       ".fixedWidth {\n",
       "    width: 4px;\n",
       "    text-align: justify;\n",
       "} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3710cd22d14fe894d5a310a7b3c2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SearchWidget(children=(RadioButtons(description='Model for Sentence Embedding', options=('BSV', 'Sent2Vec'), sโฆ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_widget = SearchWidget(\n",
    "    bbs_search_url=SEARCH_ENGINE_URL,\n",
    "    bbs_mysql_engine=bbs_mysql_engine,\n",
    "    article_saver=article_saver,\n",
    "    results_per_page=3)\n",
    "search_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status of the Article Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>paragraph_pos_in_article</th>\n",
       "      <th>option</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146170</td>\n",
       "      <td>-1</td>\n",
       "      <td>Save full article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>182010</td>\n",
       "      <td>-1</td>\n",
       "      <td>Save full article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>227099</td>\n",
       "      <td>-1</td>\n",
       "      <td>Save full article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202464</td>\n",
       "      <td>-1</td>\n",
       "      <td>Save full article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228228</td>\n",
       "      <td>-1</td>\n",
       "      <td>Save full article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>214754</td>\n",
       "      <td>-1</td>\n",
       "      <td>Save full article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>187782</td>\n",
       "      <td>-1</td>\n",
       "      <td>Save full article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>16072</td>\n",
       "      <td>-1</td>\n",
       "      <td>Save full article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>139943</td>\n",
       "      <td>-1</td>\n",
       "      <td>Save full article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>175649</td>\n",
       "      <td>-1</td>\n",
       "      <td>Save full article</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows ร 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id  paragraph_pos_in_article             option\n",
       "0       146170                        -1  Save full article\n",
       "1       182010                        -1  Save full article\n",
       "2       227099                        -1  Save full article\n",
       "3       202464                        -1  Save full article\n",
       "4       228228                        -1  Save full article\n",
       "..         ...                       ...                ...\n",
       "95      214754                        -1  Save full article\n",
       "96      187782                        -1  Save full article\n",
       "97       16072                        -1  Save full article\n",
       "98      139943                        -1  Save full article\n",
       "99      175649                        -1  Save full article\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_saver.summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set schemas\n",
    "The user defines the KG schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_request = SchemaRequest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_type</th>\n",
       "      <th>property</th>\n",
       "      <th>property_type</th>\n",
       "      <th>property_value_type</th>\n",
       "      <th>ontology_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CELL_COMPARTMENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CELL_TYPE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMICAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONDITION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DISEASE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DRUG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORGAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ORGANISM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PATHWAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reactome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PROTEIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity_type  property  property_type  property_value_type  \\\n",
       "0  CELL_COMPARTMENT       NaN            NaN                  NaN   \n",
       "1         CELL_TYPE       NaN            NaN                  NaN   \n",
       "2          CHEMICAL       NaN            NaN                  NaN   \n",
       "3         CONDITION       NaN            NaN                  NaN   \n",
       "4           DISEASE       NaN            NaN                  NaN   \n",
       "5              DRUG       NaN            NaN                  NaN   \n",
       "6             ORGAN       NaN            NaN                  NaN   \n",
       "7          ORGANISM       NaN            NaN                  NaN   \n",
       "8           PATHWAY       NaN            NaN                  NaN   \n",
       "9           PROTEIN       NaN            NaN                  NaN   \n",
       "\n",
       "  ontology_source  \n",
       "0            None  \n",
       "1            None  \n",
       "2            NCIT  \n",
       "3            None  \n",
       "4            NCIT  \n",
       "5            None  \n",
       "6            NCIT  \n",
       "7            NCIT  \n",
       "8        Reactome  \n",
       "9            NCIT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = ['entity_type', 'property', 'property_type', 'property_value_type', 'ontology_source']\n",
    "\n",
    "etypes_sources = [('CELL_COMPARTMENT', None),\n",
    "                  ('CELL_TYPE', None),\n",
    "                  ('CHEMICAL', 'NCIT'), \n",
    "                  ('CONDITION', None),\n",
    "                  ('DISEASE', 'NCIT'),\n",
    "                  ('DRUG', None),\n",
    "                  ('ORGAN', 'NCIT'),\n",
    "                  ('ORGANISM', 'NCIT'),\n",
    "                  ('PATHWAY', 'Reactome'),\n",
    "                  ('PROTEIN', 'NCIT')\n",
    "                 ]\n",
    "schema_request_data = [{'entity_type': etype, 'ontology_source': source} \n",
    "                       for etype, source in etypes_sources]\n",
    "\n",
    "schema_request.schema = pd.DataFrame(schema_request_data, columns=columns)\n",
    "display(schema_request.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a knowledge graph according to schemas\n",
    "The user extracts data from the text of a set of papers using selected Named Entity Recognizers and Relation Extractors from Blue Brain Search.\n",
    "The user can preview the extracted data.\n",
    "The user curates extracted data.\n",
    "The user links the extracted entities and relations to ontologies.\n",
    "The user saves data into Knowledge Graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **input**: raw text\n",
    "- **output**: csv table of extracted entities/relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TEXT = \"\"\"Autophagy maintains tumour growth through circulating\n",
    "arginine. Autophagy captures intracellular components and delivers them to\n",
    "lysosomes, where they are degraded and recycled to sustain metabolism and to\n",
    "enable survival during starvation. Acute, whole-body deletion of the essential \n",
    "autophagy gene Atg7 in adult mice causes a systemic metabolic defect that \n",
    "manifests as starvation intolerance and gradual loss of white adipose tissue, \n",
    "liver glycogen and muscle mass.  Cancer cells also benefit from autophagy. \n",
    "Deletion of essential autophagy genes impairs the metabolism, proliferation, \n",
    "survival and malignancy of spontaneous tumours in models of autochthonous \n",
    "cancer. Acute, systemic deletion of Atg7 or acute, systemic expression of a \n",
    "dominant-negative ATG4b in mice induces greater regression of KRAS-driven \n",
    "cancers than does tumour-specific autophagy deletion, which suggests that host \n",
    "autophagy promotes tumour growth.\n",
    "\"\"\".replace('\\n', ' ').replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This server is using the database: cord19_v47\n"
     ]
    }
   ],
   "source": [
    "TEXT_MINING_URL = os.getenv(\"TEXT_MINING_URL\", \"http://dgx1.bbp.epfl.ch:8852\")\n",
    "response = requests.post(TEXT_MINING_URL + \"/help\")\n",
    "assert response.ok and response.json()['name'] == 'MiningServer'\n",
    "print(f\"This server is using the database: {response.json()['database']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> /* search engine */\n",
       "\n",
       ".article_title {\n",
       "    font-size: 17px;\n",
       "    color: #1A0DAB;\n",
       "}\n",
       ".paragraph {\n",
       "    font-size: 13px;\n",
       "    color: #222;\n",
       "}\n",
       ".paragraph_emph {\n",
       "    font-weight: bold;\n",
       "    color: #000;\n",
       "}\n",
       ".metadata {\n",
       "    font-size: 13px;\n",
       "    color: #006621;\n",
       "}\n",
       "\n",
       "\n",
       "/* widgets buttons */\n",
       "\n",
       ".bbs_button {\n",
       "    background-color: #3c96f3;\n",
       "    color: #FFF;\n",
       "    font-size: 150%;\n",
       "    transition-duration: 0.2s;\n",
       "}\n",
       ".bbs_button:hover {\n",
       "    background-color: #3176d2;\n",
       "}\n",
       "\n",
       "\n",
       "/* attribute extraction */\n",
       "\n",
       ".number  {\n",
       "    display: inline-block;\n",
       "    background: lightgreen;\n",
       "    padding: 0.2em 0.5em;\n",
       "    border-radius: 7px;\n",
       "}\n",
       ".unit {\n",
       "    display: inline-block;\n",
       "    background: pink;\n",
       "    padding: 0.2em 0.5em;\n",
       "    border-radius: 7px;\n",
       "}\n",
       ".quantityType {\n",
       "    display: inline-block;\n",
       "    background: yellow;\n",
       "    font-variant:small-caps;\n",
       "    padding: 0.2em 0.5em;\n",
       "    border-radius: 7px;\n",
       "}\n",
       ".fixedWidth {\n",
       "    width: 4px;\n",
       "    text-align: justify;\n",
       "} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ded82444a26432888dfbfc99811c56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MiningWidget(children=(Textarea(value='Autophagy maintains tumour growth through circulating arginine. Autophaโฆ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mining_widget = MiningWidget(\n",
    "    mining_server_url=TEXT_MINING_URL,\n",
    "    schema_request=schema_request,\n",
    "    article_saver=article_saver,\n",
    "    default_text=DEFAULT_TEXT)\n",
    "mining_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **input**: csv table of extracted entities/relations\n",
    "- **output**: knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrame of extractions\n",
    "table_extractions = mining_widget.get_extracted_table()\n",
    "\n",
    "# Drop duplicates in DataFrame\n",
    "columns_duplicates = table_extractions.columns.tolist()\n",
    "columns_duplicates.remove('entity_type')\n",
    "table_extractions = table_extractions.drop_duplicates(subset=columns_duplicates, keep='first', ignore_index=True)\n",
    "table_extractions = table_extractions.dropna(subset=[\"entity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate the table with extracted entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table has 56655 rows.\n"
     ]
    }
   ],
   "source": [
    "print(f'The table has {table_extractions.shape[0]} rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import json\n",
    "# import uuid\n",
    "\n",
    "# import operator\n",
    "\n",
    "# from typing import Iterator, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jupyter_server_proxy\n",
    "# import jupyter_dash\n",
    "# import dash\n",
    "# from dash.dependencies import Input, Output, State\n",
    "# import dash_core_components as dcc\n",
    "# import dash_table\n",
    "# import plotly.express as px\n",
    "\n",
    "\n",
    "# from pygments import highlight\n",
    "# from pygments.lexers import JsonLdLexer, TurtleLexer\n",
    "# from pygments.formatters import TerminalFormatter, TerminalTrueColorFormatter\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "# from dash.exceptions import PreventUpdate\n",
    "\n",
    "\n",
    "# def pretty_print(a_json):\n",
    "#     print(highlight(json.dumps(a_json, indent=2), JsonLdLexer(), TerminalFormatter()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting default term filters: the user can remove them later on in the UI if need be ...\n",
      "Done.\n",
      "Prepating curatation data...\n",
      "Cleaning up the entities...\n",
      "Aggregating occurrences of entities....\n",
      "Done.\n",
      "Loading the ontology linking data...\n",
      "Loading default ontology types...\n",
      "Done.\n",
      "CPU times: user 12.1 s, sys: 1.46 s, total: 13.5 s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Setting default term filters: the user can remove them later on in the UI if need be ...\")\n",
    "default_term_filters = 'Glucose; Covid-19; SARS-CoV-2; Diabetes; IL-1; ACE2; glycosylation; hyperglycemia; shock; fatigue; CVD; vasoconstriction; lactate; insulin; SP-D; HbA1c; LDH; glycolysis; GLUT; macrophage; lymphocytes; ventilation;SARS; ARDS; Cytokine Storm; pneumonia; multi-organs failure; thrombosis; inflammation; IL-6; CRP; D-Dimer; Ferritin; Lung Disease; Hypertension; Aging; COPD; angiotensin 2 (or angiotensin II or AngII); Obesity; ICU (intensive care unit); ventilation; ketogenic diet'.split(\"; \")\n",
    "filtered_table_extractions = table_extractions.copy()\n",
    "\n",
    "default_found_term_filters = set() \n",
    "for term_filter in default_term_filters:\n",
    "    entities_to_keep = filtered_table_extractions[\n",
    "        filtered_table_extractions[\"entity\"].apply(lambda x: x.lower() == term_filter.lower())][\"entity\"].unique()\n",
    "    if entities_to_keep is not None and len(entities_to_keep) > 0:\n",
    "        default_found_term_filters.add(tuple(entities_to_keep))\n",
    "term_filter_options = [term_filter[0] for term_filter in default_found_term_filters]\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Prepating curatation data...\")\n",
    "curation_input_table, factor_counts = generate_curation_table(filtered_table_extractions)\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Loading the ontology linking data...\")\n",
    "linking = pd.read_pickle(\"/gpfs/bbp.cscs.ch/project/proj116/network_analytics/data/cord_47_linking.pkl\")\n",
    "\n",
    "print(\"Loading default ontology type mapping...\")\n",
    "with open('/gpfs/bbp.cscs.ch/project/proj116/bbg/ontology-linking/ncit_to_mltypes_mapping.json', \"rb\") as f:\n",
    "    default_type_mapping = json.load(f)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the curation app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging the occurrence data with the ontology linking...\n"
     ]
    }
   ],
   "source": [
    "curation_app.set_default_terms_to_include(term_filter_options)\n",
    "curation_app.set_table(curation_input_table.copy())\n",
    "curation_app.set_ontology_linking_callback(lambda x: link_ontology(linking, default_type_mapping, x))\n",
    "\n",
    "curation_app.run(port=8077)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a co-mention graph from curated entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_table_extractions = curation_app.get_curated_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Factor: paper\n",
      "-------------------------------\n",
      "Fitering data.....\n",
      "Selected 100 most frequent terms\n",
      "Examining 4950 pairs of terms for co-occurrence...\n",
      "Generated 4941 edges                    \n",
      "Created a co-occurrence graph:\n",
      "\tnumber of nodes:  100\n",
      "\tnumber of edges:  4941\n",
      "Saving the edges...\n",
      "Creating a graph object...\n",
      "Computing degree centrality statistics....\n",
      "Top n nodes by frequency:\n",
      "\tinfectious disorder (1732)\n",
      "\tvirus (1656)\n",
      "\tlung (1651)\n",
      "\theart (1495)\n",
      "\tblood (1479)\n",
      "\tdead (1461)\n",
      "\tcardiovascular (1456)\n",
      "\tdiabetes mellitus (1431)\n",
      "\thypertension (1377)\n",
      "\tpulmonary (1365)\n",
      "\n",
      "Computing PageRank centrality statistics....\n",
      "Top n nodes by frequency:\n",
      "\tinfectious disorder (0.02)\n",
      "\tvirus (0.02)\n",
      "\tlung (0.02)\n",
      "\theart (0.02)\n",
      "\tblood (0.02)\n",
      "\tdead (0.02)\n",
      "\tcardiovascular (0.02)\n",
      "\tdiabetes mellitus (0.02)\n",
      "\thypertension (0.02)\n",
      "\tpulmonary (0.02)\n",
      "\n",
      "Computing betweenness centrality statistics....\n",
      "Detecting communities...\n",
      "Best network partition:\n",
      "\t Number of communities: 3\n",
      "\t Modularity: 0.04399845979465248\n",
      "Detecting communities...\n",
      "Best network partition:\n",
      "\t Number of communities: 3\n",
      "\t Modularity: 0.06253589467613996\n",
      "Computing the minimum spanning tree...\n"
     ]
    }
   ],
   "source": [
    "curated_table_extractions[\"paper\"] = curated_table_extractions[\"paper\"].transform(lambda x: set(x))\n",
    "curated_table_extractions[\"paragraph\"] = curated_table_extractions[\"paragraph\"].transform(lambda x: set(x))\n",
    "curated_table_extractions[\"section\"] = curated_table_extractions[\"section\"].transform(lambda x: set(x))\n",
    "\n",
    "type_data = curated_table_extractions[[\"entity_type\"]].rename(columns={\"entity_type\": \"type\"})\n",
    "\n",
    "graphs, trees = generate_comention_analysis(\n",
    "    curated_table_extractions, factor_counts, type_data=type_data, min_occurrences=5, n_most_frequent=100, factors=[\"paper\"], cores=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in graphs[\"paper\"].nodes():\n",
    "#     print(graphs[\"paper\"].nodes[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cytoscape_graphs = dict()\n",
    "for f in [\"paper\"]:\n",
    "    cytoscape_graphs[f] = {\n",
    "        \"tree\": build_cytoscape_data(trees[f]),\n",
    "        \"graph\": build_cytoscape_data(graphs[f])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build knowledge graph from enriched annotations\n",
    "# import json\n",
    "# from typing import Iterable, Dict\n",
    "# from rdflib import Graph\n",
    "# from rdflib.extras.external_graph_libs import rdflib_to_networkx_digraph\n",
    "# import networkx as nx\n",
    "# from rdflib.namespace import RDF, RDFS, SKOS\n",
    "\n",
    "\n",
    "# from kganalytics_utils import generate_comention_analysis\n",
    "# # Generate a paper-based network from a mentions data frame:\n",
    "# # - we select entities that are mentioned at least 5 times\n",
    "# # - and we then take only 100 most frequent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curated_table_extractions_grouped = curated_table_extractions.rename(columns={\"entity\": \"entity_raw\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the knowledge graph\n",
    "Content of the Knowledge Graph is validated. In this version, syntactic validation (i.e. are the identifiers correct, ...) is performed when building the knowledge graph. If the knowledge graph is successfully built then the validation passes. In case of warning (i.e because of a weird character (+,...) in an extracted entity), the user can go back to the curation step and further curate extracted entities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct knowledge graph\n",
    "Correction involves going back to the extraction and/or curation steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access the knowledge graph\n",
    "The user can search, visualize, and export the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-generated 3000 graphs...\n",
      "Done.\n",
      "Loading pre-generated 3000 styles...\n",
      "Done.\n",
      "CPU times: user 104 ms, sys: 28.1 ms, total: 132 ms\n",
      "Wall time: 131 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Loading pre-generated 3000 graphs...\")\n",
    "with open(\"/gpfs/bbp.cscs.ch/project/proj116/cytoscape_3000/paper_spanning_tree_3000.cyjs\") as f:\n",
    "    paper_spanning_tree = json.load(f)\n",
    "    \n",
    "paper_spanning_tree_list = paper_spanning_tree[\"elements\"][\"nodes\"] + paper_spanning_tree[\"elements\"][\"edges\"]\n",
    "paper_spanning_tree_dict = {elt['data']['uid']:elt for elt in paper_spanning_tree_list  if \"uid\" in elt['data']}\n",
    "\n",
    "with open(\"/gpfs/bbp.cscs.ch/project/proj116/cytoscape_3000/paper_clusters_3000.cyjs\",\"r\") as f:\n",
    "    paper_spanning_clusters = json.load(f)\n",
    "    \n",
    "paper_spanning_clusters_list = paper_spanning_clusters[\"elements\"][\"nodes\"] + paper_spanning_clusters[\"elements\"][\"edges\"]\n",
    "paper_spanning_clusters_dict = {elt['data']['uid']:elt for elt in paper_spanning_clusters_list  if \"uid\" in elt['data']}\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Loading pre-generated 3000 styles...\")\n",
    "with open(\"/gpfs/bbp.cscs.ch/project/proj116/cytoscape_3000/paper_spanning_tree_3000_styles.json\",\"r\") as f:\n",
    "    paper_spanning_tree_styles = json.load(f)\n",
    "paper_spanning_tree_styles = paper_spanning_tree_styles[0]['style']\n",
    "\n",
    "with open(\"/gpfs/bbp.cscs.ch/project/proj116/cytoscape_3000/paper_clusters_3000_styles.json\",\"r\") as f:\n",
    "    paper_spanning_clusters_styles = json.load(f)\n",
    "paper_spanning_clusters_styles = paper_spanning_clusters_styles[0]['style']\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_app.set_graph(\n",
    "    \"Full co-mention graph\", cytoscape_graphs[\"paper\"][\"graph\"][0], cytoscape_graphs[\"paper\"][\"graph\"][1])\n",
    "visualization_app.set_graph(\n",
    "    \"Co-mention spanning tree\", cytoscape_graphs[\"paper\"][\"tree\"][0], cytoscape_graphs[\"paper\"][\"tree\"][1])\n",
    "visualization_app.set_graph(\n",
    "    \"Pre-computed spanning tree (3000)\", paper_spanning_tree_list,\n",
    "    paper_spanning_tree_dict, paper_spanning_tree_styles)\n",
    "visualization_app.set_graph(\n",
    "    \"Pre-computed clustered spanning tree (3000)\", paper_spanning_clusters_list,\n",
    "    paper_spanning_clusters_dict, paper_spanning_clusters_styles)\n",
    "\n",
    "visualization_app.set_current_graph(\"Full co-mention graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_app.run(port=\"8072\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Full knowledge graph'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualization_app._current_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import pickle\n",
    "# print(\"Loading precomputed co-mention graphs for 3000 extracted entities...\")\n",
    "\n",
    "# factors = [\"paper\", \"section\", \"paragraph\"]\n",
    "# weights = [\"npmi\", \"ppmi\"]\n",
    "# trees = {}\n",
    "\n",
    "# precomputed_nodes_df = {}\n",
    "# precomputed_edges_df = {}\n",
    "# # open graphs if they where already generated\n",
    "# graphs = {}\n",
    "# for factor in tqdm(factors):\n",
    "#     with open(\"/gpfs/bbp.cscs.ch/project/proj116/network_analytics/data/graphs/cord_47/full_{}_3000_edge_list.pkl\".format(factor), \"rb\") as f:\n",
    "#         edges = pickle.load(f)\n",
    "#     precomputed_edges_df[factor] = edges\n",
    "\n",
    "#     graph = nx.from_pandas_edgelist(\n",
    "#         edges,\n",
    "#          edge_attr=[\n",
    "#             \"frequency\",\n",
    "#             \"ppmi\",\n",
    "#             \"npmi\",\n",
    "#             \"distance_ppmi\",\n",
    "#             \"distance_npmi\"\n",
    "\n",
    "#          ])\n",
    "#     with open(\"/gpfs/bbp.cscs.ch/project/proj116/network_analytics/data/graphs/cord_47/full_{}_3000_node_list.pkl\".format(factor), \"rb\") as f:\n",
    "#         nodes = pickle.load(f)\n",
    "#     nx.set_node_attributes(graph, nodes.to_dict(\"index\"))\n",
    "#     precomputed_nodes_df[factor] = nodes\n",
    "#     graphs[factor] = graph\n",
    "    \n",
    "#     trees[factor] = {}\n",
    "#     with open(\"/gpfs/bbp.cscs.ch/project/proj116/network_analytics/data/graphs/cord_47/full_{}_3000_edge_list.pkl\".format(factor), \"rb\") as f:\n",
    "#         tree_edges = pickle.load(f)\n",
    "#         tree_edges = tree_edges.rename(columns={\"Source\": \"source\", \"Target\": \"target\"})\n",
    "#         tree = nx.from_pandas_edgelist(tree_edges)\n",
    "#         trees[factor] = tree\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge(id, from_id, to_id, label=None, label_size=10, label_color=\"black\", thickness=2, edge_color=\"grey\", edge_style=\"solid\",frequency=1,papers=[]):\n",
    "\n",
    "        if thickness == 0:\n",
    "            thickness = 2\n",
    "        return {\n",
    "            \"data\": { \n",
    "                \"id\": str(id),\n",
    "                \"source\": str(from_id).lower(),\n",
    "                \"target\": str(to_id).lower(),\n",
    "                \"frequency\":frequency,\n",
    "                \"papers\":papers\n",
    "            },\n",
    "            \"style\": {\n",
    "               \"label\": label if label else '',\n",
    "                \"width\": thickness\n",
    "            }\n",
    "        }\n",
    "\n",
    "def create_node(id, node_type=None,label=None, label_size=10, label_color=\"black\", radius=30, node_color='grey',frequency={}, definition=\"\",papers=[]):\n",
    "\n",
    "        actualLabel = None\n",
    "        if label is not None:\n",
    "            actualLabel = label.lower()\n",
    "        else:\n",
    "            actualLabel = str(id).lower().split(\"/\")[-1].split(\"#\")[-1]\n",
    "        frequency_raw = frequency['frequency'] if 'frequency' in frequency else 1\n",
    "        return {\n",
    "            \"data\": { \n",
    "                \"id\": str(id).lower(),\n",
    "                \"frequency\":frequency_raw,\n",
    "                \"degree_frequency\":frequency['degree_frequency'] if 'degree_frequency' in frequency else frequency_raw,\n",
    "                \"pagerank_frequency\":frequency['pagerank_frequency'] if 'pagerank_frequency' in frequency else frequency_raw,\n",
    "                \"definition\":definition,\n",
    "                \"papers\":papers,\n",
    "                \"type\":node_type\n",
    "            },\n",
    "            \"style\": {\n",
    "                \"label\": actualLabel\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import dash\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_html_components as html\n",
    "import dash_bootstrap_components as dbc\n",
    "from kganalytics.paths import top_n_paths, top_n_tripaths\n",
    "from collections import OrderedDict\n",
    "from networkx.readwrite.json_graph.cytoscape import cytoscape_data\n",
    "\n",
    "import dash_cytoscape as cyto\n",
    "\n",
    "from dash.exceptions import PreventUpdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(st):\n",
    "    if 'http' in st:\n",
    "        return requests.get(st).json()\n",
    "    else:\n",
    "        with open(st, 'rb') as f:\n",
    "            x = json.load(f)\n",
    "        return x\n",
    "    \n",
    "# Load extra layouts\n",
    "\n",
    "\n",
    "# app_tab.config['suppress_callback_exceptions']=True\n",
    "# width = \n",
    "# app_tab.height = \"800px\"\n",
    "# app_tab.run_server(mode=\"jupyterlab\", width=\"100%\", port=\"8072\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version the knowledge graph\n",
    "The user can save a knowledge graph with a version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        \n",
    "# Temporally save the extracted entities csv file locally\n",
    "table_extractions_filename = \"./table_extractions_%s.csv\" % (timestr)\n",
    "table_extractions.to_csv(table_extractions_filename)\n",
    "\n",
    "\n",
    "# Temporally save the curated list of extracted entities csv file locally\n",
    "curated_table_extractions_filename = \"./curated_table_extractions_%s.csv\" % (timestr)\n",
    "curated_table_extractions.to_csv(curated_table_extractions_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwt\n",
    "from kgforge.core import Resource\n",
    "from kgforge.specializations.resources import Dataset\n",
    "\n",
    "agent = jwt.decode(TOKEN,  verify=False)\n",
    "\n",
    "agent = forge.reshape(forge.from_json(agent), keep=[\"name\",\"email\",\"sub\",\"preferred_username\"])\n",
    "agent.id = agent.sub\n",
    "agent.type = \"Person\"\n",
    "\n",
    "dataset = Dataset(forge,name=\"A dataset\", about=topic_resource.name)\n",
    "dataset.add_distribution(table_extractions_filename, content_type=\"application/csv\")\n",
    "dataset.add_distribution(curated_table_extractions_filename, content_type=\"application/csv\")\n",
    "dataset.add_contribution(agent)\n",
    "dataset.contribution.hadRole= \"Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = agent.preferred_username+\"_\"+timestr\n",
    "\n",
    "def register_dataset(b):\n",
    "    output4.clear_output()\n",
    "    output5.clear_output()\n",
    "    dataset.name = t1.value\n",
    "    dataset.description = t2.value\n",
    "    forge.register(dataset)\n",
    "    if dataset._last_action.succeeded == True:\n",
    "        with output4:\n",
    "            print(\"Dataset registered!\")\n",
    "    else:\n",
    "        with output4:\n",
    "            print(dataset._last_action.message)\n",
    "\n",
    "def version_dataset(b):\n",
    "    output5.clear_output()\n",
    "    version = t3.value\n",
    "    forge.tag(dataset,version)\n",
    "    if dataset._last_action.succeeded == True:\n",
    "        with output5:\n",
    "            print(f\"Tagged with: {str(version)}\")\n",
    "    \n",
    "output4 = ipywidgets.Output()\n",
    "output5 = ipywidgets.Output()\n",
    "\n",
    "b1 = ipywidgets.Button(\n",
    "    description= '๐พ  Register Dataset',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "\n",
    "b2 = ipywidgets.Button(\n",
    "    description= '๐ Tag Dataset',\n",
    "    button_style='',\n",
    "    layout=ipywidgets.Layout(width='300px', height='30px'),\n",
    "    disabled=False)\n",
    "\n",
    "t1 = ipywidgets.Text(\n",
    "    placeholder='Add a name for your dataset',\n",
    "    description='Name:',\n",
    "    disabled=False)\n",
    "\n",
    "t2 = ipywidgets.Textarea(\n",
    "    placeholder='Add a description of your dataset',\n",
    "    description='Description:',\n",
    "    disabled=False)\n",
    "\n",
    "t3 = ipywidgets.Text(\n",
    "    description='Tag:',\n",
    "    value=version,\n",
    "    disabled=False)\n",
    "\n",
    "b1.on_click(register_dataset)\n",
    "b2.on_click(version_dataset)\n",
    "\n",
    "save_widget = ipywidgets.VBox(children=[t1, t2, b1, output4, t3, b2, output5])\n",
    "\n",
    "display(save_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BBS-BBG",
   "language": "python",
   "name": "devel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
