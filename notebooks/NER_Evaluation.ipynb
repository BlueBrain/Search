{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "Blue Brain Search is a text mining toolbox focused on scientific use cases.\n",
    "\n",
    "Copyright (C) 2020  Blue Brain Project, EPFL.\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU Lesser General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU Lesser General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU Lesser General Public License\n",
    "along with this program. If not, see <https://www.gnu.org/licenses/>.\n",
    "-->\n",
    "\n",
    "# Evaluation of NER Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_ner_craft_md-0.2.5.tar.gz \\\n",
    "    https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_ner_jnlpba_md-0.2.5.tar.gz \\\n",
    "    https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_ner_bc5cdr_md-0.2.5.tar.gz \\\n",
    "    https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_ner_bionlp13cg_md-0.2.5.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "\n",
    "from bluesearch.mining.eval import (annotations2df, spacy2df, unique_etypes, plot_ner_confusion_matrix, \n",
    "                                  ner_report, ner_errors, remove_punctuation)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCISPACY_MODELS = ['en_ner_craft_md',\n",
    "                   'en_ner_jnlpba_md',\n",
    "                   'en_ner_bc5cdr_md',\n",
    "                   'en_ner_bionlp13cg_md']\n",
    "\n",
    "ANNOTATIONS_JSONL_PATH = Path('../data_and_models/annotations/ner/')\n",
    "\n",
    "# prodigy_dataset_name: annotator_name\n",
    "DATASETS_2_ANNOTATORS = OrderedDict([('annotations3_EmmanuelleLogette_2020-07-06_raw1_8FirstLabels.jsonl', 'EmmanuelleLogette'),\n",
    "                                     ('annotations4_CharlotteLorin_2020-07-02_raw1_8FirstLabels.jsonl', 'CharlotteLorin')])\n",
    "\n",
    "annotators = list(DATASETS_2_ANNOTATORS.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import annotations from experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = OrderedDict([(annotator, annotations2df(ANNOTATIONS_JSONL_PATH / annotations_file)) \n",
    "                  for annotations_file, annotator in DATASETS_2_ANNOTATORS.items()])\n",
    "\n",
    "# Inner join: look at annotations for the same tokens (id) of the same sentences (source)\n",
    "df = df[annotators[1]].merge(df[annotators[0]], \n",
    "                                 on=['source', 'id', 'text', 'start_char', 'end_char'], \n",
    "                                 suffixes=(f'_{annotators[1]}', f'_{annotators[0]}'),\n",
    "                                 how='inner')\n",
    "\n",
    "annotators_names = '\\n - '.join(annotators)\n",
    "print(f'Loaded annotations for {len(df):,d} tokens, provided by the following expert annotators:\\n - {annotators_names}.')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations predicted by SciSpaCy models\n",
    "\n",
    "<div>\n",
    "<strong> Attention! (1) </strong> \n",
    "<br>\n",
    "    Predicted annotations must be generated like here by calling the SciSpaCy models on the text, sentence by sentence. Doing a batch inference on the whole <code>df['text']</code> column would allow the models to look outside of the boundaries of sentences, so that the predictions would be affected by the order of the sentence in the dataframe.\n",
    "    </div>\n",
    "    \n",
    "    \n",
    "<div>\n",
    "<strong> Attention! (2) </strong>\n",
    "<br>\n",
    "    In many cases the entity type names in the predicted annotations do not match the ones in the ground truth. To fix that, most evaluation function support a dictionary parameter <code>etypes_map</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_models = {model_name: spacy.load(model_name) for model_name in SCISPACY_MODELS}\n",
    "\n",
    "# Add columns with predictions of NER models\n",
    "for ner_model_name, ner_model in ner_models.items():\n",
    "    model_df = []\n",
    "\n",
    "    for source, df_ in df.groupby('source'):\n",
    "        df_ = df_.sort_values(by='id', ignore_index=True)\n",
    "        df_sentence = spacy2df(spacy_model=ner_model, ground_truth_tokenization=df_['text'].to_list())\n",
    "        df_sentence['id'] = df_['id'].values\n",
    "        df_sentence['source'] = source\n",
    "        model_df.append(df_sentence)\n",
    "\n",
    "    model_df = pd.concat(model_df, ignore_index=True).rename(columns={'class': f'class_{ner_model_name}'})\n",
    "    \n",
    "    df = df.merge(model_df, \n",
    "         on=['source', 'id', 'text'], \n",
    "         how='inner')\n",
    "    \n",
    "scispacy_models_names = \"\\n - \".join(SCISPACY_MODELS)\n",
    "print(f'Added annotations for {len(df):,d} tokens, predicted by' \\\n",
    "      f'the following NER models: \\n - {scispacy_models_names}.')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER Evaluation\n",
    "\n",
    "The following NER evaluation functions have a parameter <code>mode</code> which can take one of the two following values.\n",
    "<ul>\n",
    "    <li><code>\"token\"</code>: Each token is considered separately, and only the enity type (e.g. <code>\"DISEASE\"</code>) of annotations is considered, without considering the full IOB annotations (e.g. <code>\"B-DISEASE\"</code>).</li>\n",
    "    <li><code>\"entity\"</code>: Entities are considered as units, even if they cover a span of several tokens. A True Positive is defined as two entity annotations matching exactly from the first to the last token of the span.</li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "<div>\n",
    "<strong>Note.</strong> For the purpose of the evaluations shown in this section, we will consider the evaluations of <code>EmmanuelleLogette</code> as the ground truth. The resports are therefore produced with respect to the labels used by this annoator.\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<strong>Note.</strong> Annotation of punctuation elements as parts of an entity can orginiate from small mistakes in the manual labeling process. For this reason, we can remove all punctuation elements by calling <code>remove_punctuation()</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_punctuation(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>unique_etypes</code>: analyze distribution annotations per entity type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in ('token', 'entity'):\n",
    "    f, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    for ax_, annotator in zip(ax, (annotators[0], SCISPACY_MODELS[0])):\n",
    "        iob_annotations = df[f'class_{annotator}']\n",
    "        etypes, counts = unique_etypes(iob_annotations, mode=mode, return_counts=True)\n",
    "        ax_.bar(etypes, counts)\n",
    "        for x, y in enumerate(counts):\n",
    "            ax_.text(x, y, f'{y:,d}', ha='center', va='bottom')\n",
    "        ax_.set_xticklabels(etypes, rotation=45)\n",
    "        ax_.set_ylabel('Count')\n",
    "        ax_.grid()\n",
    "        ax_.set_title(f'Annotations {annotator} [mode = {mode}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>ner_report</code>: summarize ner scores\n",
    "\n",
    "<strong>Note.</strong> If one needs to access exact numeric values of the report, it is possible to call the function with <code>return_dict=True</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iob_true = df[f'class_{annotators[0]}']\n",
    "\n",
    "for mode in ('token', 'entity'):\n",
    "    for annotator_pred in (annotators[1], SCISPACY_MODELS[0]):\n",
    "        print(f'Annotations {annotator_pred} [mode = {mode}]')\n",
    "        iob_pred = df[f'class_{annotator_pred}']\n",
    "        if annotator_pred in SCISPACY_MODELS:\n",
    "            print(ner_report(iob_true, iob_pred, mode=mode, return_dict=False, \n",
    "                             etypes_map={'CHEMICAL': 'CHEBI',\n",
    "                                         'CELL_TYPE': 'CL',\n",
    "                                         'ORGANISM': 'TAXON',\n",
    "                                         'PROTEIN': 'GGP'}))\n",
    "        else:\n",
    "            print(ner_report(iob_true, iob_pred, mode=mode, return_dict=False))      \n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>ner_errors</code>: show false negatives and false positives\n",
    "\n",
    "<strong>Note.</strong> For reasons of space, we only print results relative to one entity type, but you can change the value of <code>\"ETYPE\"</code> to see the other results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETYPE = 'CELL_TYPE'\n",
    "\n",
    "iob_true = df[f'class_{annotators[0]}']\n",
    "\n",
    "for mode in ('token', 'entity'):\n",
    "    for annotator_pred in (annotators[1], SCISPACY_MODELS[0]):\n",
    "        print(f'Annotations {annotator_pred} [mode = {mode}]')\n",
    "        iob_pred = df[f'class_{annotator_pred}']\n",
    "        if annotator_pred in SCISPACY_MODELS:\n",
    "            results_dict = ner_errors(iob_true, iob_pred, mode=mode, return_dict=True, \n",
    "                             etypes_map={'CHEMICAL': 'CHEBI',\n",
    "                                         'CELL_TYPE': 'CL',\n",
    "                                         'ORGANISM': 'TAXON',\n",
    "                                         'PROTEIN': 'GGP'},\n",
    "                            tokens=df.text)\n",
    "        else:\n",
    "            results_dict = ner_errors(iob_true, iob_pred, mode=mode, return_dict=True, tokens=df.text)\n",
    "        print(f'------Entity type: {ETYPE}------')\n",
    "        print(f'--- False Negatives ---')\n",
    "        print(' '.join(repr(s) for s in results_dict[ETYPE]['false_neg']))\n",
    "        print(f'--- False Positives ---')\n",
    "        print(' '.join(repr(s) for s in results_dict[ETYPE]['false_pos']))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>ner_confusion_matrix</code>: breakdown ner predictions against ground truth\n",
    "\n",
    "<div>\n",
    "<strong>Note.</strong> The function <code>plot_ner_confusion_matrix</code> is just a wrapper around <code>ner_confusion_matrix</code>.\n",
    "</div>\n",
    "<div>\n",
    "<strong>Note.</strong> The normalization parameter <code>normalize</code> can take 4 possible values: <code>None, \"true\", \"pred\", \"all\"</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iob_true = df[f'class_{annotators[0]}']\n",
    "\n",
    "for annotator_pred in (annotators[1], *SCISPACY_MODELS):\n",
    "    iob_pred = df[f'class_{annotator_pred}']\n",
    "\n",
    "    f, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    for ax_, mode in zip(ax, ('token', 'entity')):\n",
    "        plot_ner_confusion_matrix(iob_true, iob_pred, mode=mode, ax=ax_, normalize=None)\n",
    "        ax_.set_title(f'{annotator_pred} [mode = {mode}]')\n",
    "    f.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
