{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data: `metadata.csv` and find `json` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_VERSION = 'v7'\n",
    "\n",
    "p = Path('/raid/covid_data/data') / DATASET_VERSION\n",
    "\n",
    "n_json_files = len(list(p.glob('**/*json')))\n",
    "\n",
    "print(f'Found {n_json_files:,d} JSON files for the CORD-19 (version {DATASET_VERSION}).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(p / 'metadata.csv')\n",
    "\n",
    "print(f'Found {len(df):,d} article entries for the CORD-19 (version {DATASET_VERSION})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create associative table `article_id_2_sha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(data=df[['cord_uid', 'sha']])\n",
    "df2 = df2.set_index(['cord_uid']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "df2.rename(columns={'cord_uid':'article_id', 'sha':'sha'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(f'cord19_{DATASET_VERSION}.db') as db:\n",
    "    conn = db.cursor()\n",
    "\n",
    "    db.execute(\n",
    "        \"\"\"CREATE TABLE IF NOT EXISTS article_id_2_sha\n",
    "        (\n",
    "            article_id TEXT,\n",
    "            sha TEXT\n",
    "        );\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "    df2.to_sql(name='article_id_2_sha', con=db, index=False, if_exists='append')\n",
    "    \n",
    "    display(pd.read_sql('SELECT * FROM article_id_2_sha LIMIT 5;', db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `articles` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'cord_uid':'article_id', \n",
    "    'sha':'sha',\n",
    "    'source_x':'publisher', \n",
    "    'title':'title', \n",
    "    'doi':'doi', \n",
    "    'pmcid':'pmc_id', \n",
    "    'pubmed_id':'pm_id', \n",
    "    'license':'licence',\n",
    "    'abstract':'abstract', \n",
    "    'publish_time':'date', \n",
    "    'authors':'authors', \n",
    "    'journal':'journal',\n",
    "    'Microsoft Academic Paper ID':'microsoft_id', \n",
    "    'WHO #Covidence':'covidence_id', \n",
    "    'has_pdf_parse':'has_pdf_parse',\n",
    "    'has_pmc_xml_parse':'has_pmc_xml_parse', \n",
    "    'full_text_file':'fulltext_directory', \n",
    "    'url':'url'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_ in df.columns:\n",
    "    print(f'column {repr(c_):>20s} has {df[c_].isna().sum():>15,d} NULL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop column `sha`, for which we have the associative table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('sha', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some `article_id` appear twice, so drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates('article_id', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(f'cord19_{DATASET_VERSION}.db') as db:\n",
    "    db.execute(\n",
    "        \"\"\"CREATE TABLE IF NOT EXISTS articles\n",
    "        (\n",
    "            article_id TEXT PRIMARY KEY, \n",
    "            publisher TEXT, \n",
    "            title TEXT, \n",
    "            doi TEXT, \n",
    "            pmc_id TEXT, \n",
    "            pm_id INTEGER, \n",
    "            licence TEXT,\n",
    "            abstract TEXT, \n",
    "            date DATETIME, \n",
    "            authors TEXT, \n",
    "            journal TEXT,\n",
    "            microsoft_id INTEGER, \n",
    "            covidence_id TEXT, \n",
    "            has_pdf_parse BOOLEAN,\n",
    "            has_pmc_xml_parse BOOLEAN, \n",
    "            fulltext_directory TEXT, \n",
    "            url TEXT\n",
    "        );\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "    df.to_sql(name='articles', con=db, index=False, if_exists='append')\n",
    "\n",
    "    display(pd.read_sql('SELECT * FROM articles LIMIT 3', db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `sentences` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
